# Unified Data Model — Raw Pipe Architecture

## Design Principle

The sensor is a **dumb pipe**. It reads local files, wraps each record in a thin envelope with source metadata, and POSTs raw JSON to the API. **All parsing, normalization, and structuring happens server-side.** This means:

- New tools → add a server parser, no app update
- Tool changes format → update server parser, no app update
- Normalization bug → server hotfix, no app update
- Re-process historical data → re-run parser on stored `raw` field

---

## 1. Wire Format (Sensor → API)

Every event the sensor sends:

```json
{
  "event_id": "0193a1b2-c3d4-7e5f-8a9b-0c1d2e3f4a5b",
  "timestamp": "2026-02-07T18:30:00.000Z",
  "type": "local_session",
  "device_id": "device-uuid-from-oximy",
  "source": "claude_code",
  "source_version": "2.1.4",
  "source_file": "~/.claude/projects/-Users-.../abc123.jsonl",
  "file_type": "session_transcript",
  "project_key": "-Users-name-Desktop-project",
  "session_id": "abc123",
  "line_number": 847,
  "raw": { ... original JSON object exactly as found in the file ... }
}
```

### Envelope Fields (set by sensor)

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `event_id` | string (UUIDv7) | Yes | Generated by sensor |
| `timestamp` | string (ISO 8601) | Yes | Extracted from raw record if available, else file mtime |
| `type` | string | Yes | Always `"local_session"` |
| `device_id` | string | Yes | From `~/.oximy/device-token` |
| `source` | string (enum) | Yes | `claude_code`, `cursor`, `codex`, `openclaw`, `antigravity` |
| `source_version` | string | No | Tool version if detectable |
| `source_file` | string | Yes | Relative path from `~` (e.g., `~/.claude/projects/.../file.jsonl`) |
| `file_type` | string | Yes | Hint for server parser (see below) |
| `project_key` | string | No | Project identifier extracted from path |
| `session_id` | string | No | Session UUID extracted from filename |
| `line_number` | int | No | Line number within the source file |
| `raw` | object | Yes | **Untouched** original record from the source file |

### `source` Values

| Value | Tool |
|-------|------|
| `claude_code` | Claude Code CLI |
| `cursor` | Cursor IDE |
| `codex` | OpenAI Codex CLI |
| `openclaw` | OpenClaw |
| `antigravity` | Antigravity (Google Gemini) |

### `file_type` Values

| Value | Sources | Description |
|-------|---------|-------------|
| `session_transcript` | All | Main conversation JSONL line |
| `subagent_transcript` | claude_code | Subagent conversation JSONL line |
| `session_index` | claude_code, openclaw | Session metadata index |
| `prompt_history` | claude_code, codex | Cross-session prompt entry |
| `stats` | claude_code | Usage statistics |
| `agent_transcript` | cursor | Agent conversation (full JSON array) |
| `sqlite_composer` | cursor | composerData row from state.vscdb |
| `sqlite_bubble` | cursor | bubbleId row from state.vscdb |
| `sqlite_code_tracking` | cursor | ai_code_hashes row |
| `sqlite_daily_stats` | cursor | Daily usage stats row |
| `cron_run` | openclaw | Cron job execution log |
| `config` | codex, openclaw | Tool configuration snapshot |
| `memory` | claude_code, openclaw | Agent memory file |

---

## 2. What the Sensor Extracts vs Leaves Raw

### Sensor DOES Extract (for envelope)

These are cheap to extract without understanding the schema:

| Field | How Sensor Gets It |
|-------|-------------------|
| `source` | Which glob pattern matched the file |
| `source_file` | The file path being read |
| `file_type` | Mapped from glob pattern in sensor-config |
| `session_id` | From filename (UUID before `.jsonl`) |
| `project_key` | From directory name under `projects/` |
| `timestamp` | `raw.timestamp` if present, else file mtime |
| `line_number` | Counter during file read |

### Sensor Does NOT Do

- Parse `message.content` blocks
- Extract tool names or tool inputs
- Normalize field names across tools
- Flatten nested structures
- Compute token totals
- Build conversation threading trees
- Differentiate user prompts from tool results

**All of that is the API's job.**

---

## 3. Batching

Events are batched into **gzipped JSONL** and POSTed:

```http
POST /api/v1/ingest/local-sessions HTTP/1.1
Content-Type: application/jsonl
Content-Encoding: gzip
Authorization: Bearer <device-token>
X-Oximy-Batch-Size: 47
X-Oximy-Sources: claude_code,cursor

{"event_id":"...","type":"local_session","source":"claude_code","raw":{...}}\n
{"event_id":"...","type":"local_session","source":"cursor","raw":{...}}\n
```

**Constraints:**
- Max 5 MB compressed per batch
- Max 200 events per batch
- Upload every 30 seconds or when batch is full
- Mixed sources allowed in same batch (server routes by `source` field)

---

## 4. Client-Side Redaction (The One Exception)

Before wrapping in the envelope, the sensor **strips sensitive data** from the raw string. This happens as a regex pass on the raw JSON string, NOT structural parsing:

```python
REDACT_PATTERNS = [
    r'"(sk-[a-zA-Z0-9]{20,})"',           # OpenAI API keys
    r'"(anthropic-[a-zA-Z0-9]{20,})"',     # Anthropic keys
    r'"(ghp_[a-zA-Z0-9]{36,})"',           # GitHub tokens
    r'"(Bearer\s+[a-zA-Z0-9._-]{20,})"',   # Bearer tokens
    r'"(ya29\.[a-zA-Z0-9._-]+)"',          # Google OAuth tokens
    r'"(eyJ[a-zA-Z0-9._-]+)"',             # JWTs
]

def redact_sensitive(raw_line: str) -> str:
    for pattern in REDACT_PATTERNS:
        raw_line = re.sub(pattern, '"[REDACTED]"', raw_line)
    return raw_line
```

This is the **only** processing the sensor does on the data. Everything else is forwarded as-is.
