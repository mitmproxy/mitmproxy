# OISP Model Registry
# Auto-generated from models.dev - DO NOT EDIT MANUALLY
# Source: https://models.dev/api.json
# Generated: 2026-01-12T03:56:52.139784+00:00
#
# To regenerate: python scripts/sync-models.py

version: '0.1'
generated_at: '2026-01-12T03:56:52.139800+00:00'
source: models.dev
source_url: 'https://models.dev/api.json'

providers:
  abacus:
    name: 'Abacus'
    api_endpoint: 'https://routellm.abacus.ai/v1/chat/completions'
    logo_url: 'https://models.dev/logos/abacus.svg'
    model_count: 52
    models:
      'Qwen-QwQ-32B':
        name: 'QwQ 32B'
        family: 'qwq'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'Qwen-Qwen2.5-72B-Instruct':
        name: 'Qwen 2.5 72B Instruct'
        family: 'qwen-2.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00038
        capabilities: [function_calling, temperature]
        open_weights: true
      'Qwen-Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen3 235B A22B Instruct'
        family: 'qwen-3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 8192
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'Qwen-Qwen3-32B':
        name: 'Qwen3 32B'
        family: 'qwen-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00029
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'claude-3-7-sonnet-20250219':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'claude-haiku-4-5-20251001':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-opus-4-1-20250805':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
      'claude-opus-4-20250514':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
      'claude-opus-4-5-20251101':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-20250514':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
      'claude-sonnet-4-5-20250929':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'deepseek-ai-DeepSeek-R1':
        name: 'DeepSeek R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.007
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'deepseek-ai-DeepSeek-V3.1-Terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'deepseek-ai-DeepSeek-V3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'deepseek-deepseek-v3.1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00166
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'gemini-2.0-flash-001':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
      'gemini-2.0-pro-exp-02-05':
        name: 'Gemini 2.0 Pro Exp'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 8192
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
      'gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 65000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        capabilities: [audio_input, function_calling, reasoning, temperature, video_input, vision]
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-mini':
        name: 'GPT-4.1 Mini'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-nano':
        name: 'GPT-4.1 Nano'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4o-2024-11-20':
        name: 'GPT-4o (2024-11-20)'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'gpt-4o-mini':
        name: 'GPT-4o Mini'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-chat-latest':
        name: 'GPT-5.1 Chat Latest'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'grok-4-0709':
        name: 'Grok 4'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 16384
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature, vision]
      'grok-4-1-fast-non-reasoning':
        name: 'Grok 4.1 Fast (Non-Reasoning)'
        family: 'grok-4.1'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
      'grok-4-fast-non-reasoning':
        name: 'Grok 4 Fast (Non-Reasoning)'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok-code'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature, vision]
      'kimi-k2-turbo-preview':
        name: 'Kimi K2 Turbo Preview'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.008
        capabilities: [function_calling, temperature]
      'llama-3.3-70b-versatile':
        name: 'Llama 3.3 70B Versatile'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        open_weights: true
      'meta-llama-Llama-4-Maverick-17B-128E-Instruct-FP8':
        name: 'Llama 4 Maverick 17B 128E Instruct FP8'
        family: 'llama-4'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'meta-llama-Meta-Llama-3.1-405B-Instruct-Turbo':
        name: 'Llama 3.1 405B Instruct Turbo'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0035
        output_cost_per_1k: 0.0035
        capabilities: [function_calling, temperature]
        open_weights: true
      'meta-llama-Meta-Llama-3.1-70B-Instruct':
        name: 'Llama 3.1 70B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, temperature]
        open_weights: true
      'meta-llama-Meta-Llama-3.1-8B-Instruct':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature]
        open_weights: true
      'o3':
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o3-mini':
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2024-05'
      'o3-pro':
        family: 'o3-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.02
        output_cost_per_1k: 0.08
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o4-mini':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'openai-gpt-oss-120b':
        name: 'GPT-OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00044
        capabilities: [function_calling, reasoning, temperature, vision]
        open_weights: true
      'qwen-2.5-coder-32b':
        name: 'Qwen 2.5 Coder 32B'
        family: 'qwen-2.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00079
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        open_weights: true
      'qwen-qwen3-Max':
        name: 'Qwen3 Max'
        family: 'qwen-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.006
        capabilities: [function_calling, reasoning, temperature]
      'qwen-qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen-3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'zai-org-glm-4.5':
        name: 'GLM-4.5'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'zai-org-glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        open_weights: true
  aihubmix:
    name: 'AIHubMix'
    logo_url: 'https://models.dev/logos/aihubmix.svg'
    model_count: 33
    models:
      'Kimi-K2-0905':
        name: 'Kimi K2 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'claude-haiku-4-5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0055
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'claude-opus-4-1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0165
        output_cost_per_1k: 0.0825
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5':
        name: 'Claude Opus 4.5'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03'
      'claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0033
        output_cost_per_1k: 0.0165
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'coding-glm-4.7-free':
        name: 'Coding GLM-4.7 Free'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'deepseek-v3.2':
        name: 'DeepSeek-V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.2-think':
        name: 'DeepSeek-V3.2-Think'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 65000
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        cache_read_cost_per_1k: 2e-05
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 65000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 65000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0005
        capabilities: [audio_input, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-11'
      'glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.0011
        cache_read_cost_per_1k: 0.000548
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-mini':
        name: 'GPT-4.1 mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-nano':
        name: 'GPT-4.1 nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-2024-11-20':
        name: 'GPT-4o (2024-11-20)'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.02
        cache_read_cost_per_1k: 0.0025
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5-Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-nano':
        name: 'GPT-5-Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 0.00025
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-pro':
        name: 'GPT-5-Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.007
        output_cost_per_1k: 0.028
        cache_read_cost_per_1k: 0.0035
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'gpt-5.1-codex-max':
        name: 'GPT-5.1-Codex-Max'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1 Codex Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'minimax-m2.1':
        name: 'MiniMax M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00115
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'minimax-m2.1-free':
        name: 'MiniMax M2.1 Free'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'o4-mini':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.00075
        capabilities: [reasoning]
        knowledge_cutoff: '2024-09'
      'qwen3-235b-a22b-instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00112
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-235b-a22b-thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131000
        input_cost_per_1k: 0.00082
        output_cost_per_1k: 0.00329
        capabilities: [function_calling, temperature]
  alibaba:
    name: 'Alibaba'
    api_endpoint: 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1'
    logo_url: 'https://models.dev/logos/alibaba.svg'
    model_count: 39
    models:
      'qvq-max':
        name: 'QVQ Max'
        family: 'qvq-max'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.0048
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-flash':
        name: 'Qwen Flash'
        family: 'qwen-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-max':
        name: 'Qwen Max'
        family: 'qwen-max'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0016
        output_cost_per_1k: 0.0064
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-mt-plus':
        name: 'Qwen-MT Plus'
        family: 'qwen-mt'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 8192
        input_cost_per_1k: 0.00246
        output_cost_per_1k: 0.00737
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
      'qwen-mt-turbo':
        name: 'Qwen-MT Turbo'
        family: 'qwen-mt'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 8192
        input_cost_per_1k: 0.00016
        output_cost_per_1k: 0.00049
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
      'qwen-omni-turbo':
        name: 'Qwen-Omni Turbo'
        family: 'qwen-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00027
        capabilities: [audio_input, audio_output, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen-omni-turbo-realtime':
        name: 'Qwen-Omni Turbo Realtime'
        family: 'qwen-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00107
        capabilities: [audio_input, audio_output, function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-plus':
        name: 'Qwen Plus'
        family: 'qwen-plus'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-plus-character-ja':
        name: 'Qwen Plus Character (Japanese)'
        family: 'qwen-plus'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 512
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-turbo':
        name: 'Qwen Turbo'
        family: 'qwen-turbo'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 16384
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-vl-max':
        name: 'Qwen-VL Max'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0032
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-vl-ocr':
        name: 'Qwen-VL OCR'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 34096
        max_output_tokens: 4096
        input_cost_per_1k: 0.00072
        output_cost_per_1k: 0.00072
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-vl-plus':
        name: 'Qwen-VL Plus'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.00063
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen2-5-14b-instruct':
        name: 'Qwen2.5 14B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-32b-instruct':
        name: 'Qwen2.5 32B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-72b-instruct':
        name: 'Qwen2.5 72B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0014
        output_cost_per_1k: 0.0056
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-7b-instruct':
        name: 'Qwen2.5 7B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000175
        output_cost_per_1k: 0.0007
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-omni-7b':
        name: 'Qwen2.5-Omni 7B'
        family: 'qwen2.5-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, audio_output, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-vl-72b-instruct':
        name: 'Qwen2.5-VL 72B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0028
        output_cost_per_1k: 0.0084
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-vl-7b-instruct':
        name: 'Qwen2.5-VL 7B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00105
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen3-14b':
        name: 'Qwen3 14B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-235b-a22b':
        name: 'Qwen3 235B-A22B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-32b':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-8b':
        name: 'Qwen3 8B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.0007
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-asr-flash':
        name: 'Qwen3-ASR Flash'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 53248
        max_output_tokens: 4096
        input_cost_per_1k: 3.5e-05
        output_cost_per_1k: 3.5e-05
        capabilities: [audio_input]
        knowledge_cutoff: '2024-04'
      'qwen3-coder-30b-a3b-instruct':
        name: 'Qwen3-Coder 30B-A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.00225
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3-Coder 480B-A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.0075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-flash':
        name: 'Qwen3 Coder Flash'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen3-coder-plus':
        name: 'Qwen3 Coder Plus'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-livetranslate-flash-realtime':
        name: 'Qwen3-LiveTranslate Flash Realtime'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 53248
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.01
        capabilities: [audio_input, audio_output, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-max':
        name: 'Qwen3 Max'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen3-next-80b-a3b-instruct':
        name: 'Qwen3-Next 80B-A3B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-next-80b-a3b-thinking':
        name: 'Qwen3-Next 80B-A3B (Thinking)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-omni-flash':
        name: 'Qwen3-Omni Flash'
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 16384
        input_cost_per_1k: 0.00043
        output_cost_per_1k: 0.00166
        capabilities: [audio_input, audio_output, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-omni-flash-realtime':
        name: 'Qwen3-Omni Flash Realtime'
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 16384
        input_cost_per_1k: 0.00052
        output_cost_per_1k: 0.00199
        capabilities: [audio_input, audio_output, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-vl-235b-a22b':
        name: 'Qwen3-VL 235B-A22B'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-vl-30b-a3b':
        name: 'Qwen3-VL 30B-A3B'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-vl-plus':
        name: 'Qwen3-VL Plus'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0016
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
      'qwq-plus':
        name: 'QwQ Plus'
        family: 'qwq'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0024
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
  alibaba_cn:
    name: 'Alibaba (China)'
    api_endpoint: 'https://dashscope.aliyuncs.com/compatible-mode/v1'
    logo_url: 'https://models.dev/logos/alibaba-cn.svg'
    model_count: 61
    models:
      'deepseek-r1':
        name: 'DeepSeek R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.002294
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-0528':
        name: 'DeepSeek R1 0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.002294
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-llama-8b':
        name: 'DeepSeek R1 Distill Llama 8B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-qwen-1-5b':
        name: 'DeepSeek R1 Distill Qwen 1.5B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-qwen-14b':
        name: 'DeepSeek R1 Distill Qwen 14B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000431
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-qwen-32b':
        name: 'DeepSeek R1 Distill Qwen 32B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-r1-distill-qwen-7b':
        name: 'DeepSeek R1 Distill Qwen 7B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 16384
        input_cost_per_1k: 7.2e-05
        output_cost_per_1k: 0.000144
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-v3':
        name: 'DeepSeek V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 8192
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.001147
        capabilities: [function_calling, temperature]
      'deepseek-v3-1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.001721
        capabilities: [function_calling, temperature]
      'deepseek-v3-2-exp':
        name: 'DeepSeek V3.2 Exp'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000431
        capabilities: [function_calling, temperature]
      'moonshot-kimi-k2-instruct':
        name: 'Moonshot Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.002294
        capabilities: [function_calling, temperature]
      'qvq-max':
        name: 'QVQ Max'
        family: 'qvq-max'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001147
        output_cost_per_1k: 0.004588
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-deep-research':
        name: 'Qwen Deep Research'
        family: 'qwen-deep-research'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 0.007742
        output_cost_per_1k: 0.023367
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-doc-turbo':
        name: 'Qwen Doc Turbo'
        family: 'qwen-doc'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 8.7e-05
        output_cost_per_1k: 0.000144
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-flash':
        name: 'Qwen Flash'
        family: 'qwen-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 2.2e-05
        output_cost_per_1k: 0.000216
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-long':
        name: 'Qwen Long'
        family: 'qwen-long'
        mode: chat
        max_input_tokens: 10000000
        max_output_tokens: 8192
        input_cost_per_1k: 7.2e-05
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-math-plus':
        name: 'Qwen Math Plus'
        family: 'qwen-math'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 3072
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.001721
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-math-turbo':
        name: 'Qwen Math Turbo'
        family: 'qwen-math'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 3072
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-max':
        name: 'Qwen Max'
        family: 'qwen-max'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000345
        output_cost_per_1k: 0.001377
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-mt-plus':
        name: 'Qwen-MT Plus'
        family: 'qwen-mt'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 8192
        input_cost_per_1k: 0.000259
        output_cost_per_1k: 0.000775
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
      'qwen-mt-turbo':
        name: 'Qwen-MT Turbo'
        family: 'qwen-mt'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 8192
        input_cost_per_1k: 0.000101
        output_cost_per_1k: 0.00028
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
      'qwen-omni-turbo':
        name: 'Qwen-Omni Turbo'
        family: 'qwen-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 5.8e-05
        output_cost_per_1k: 0.00023
        capabilities: [audio_input, audio_output, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen-omni-turbo-realtime':
        name: 'Qwen-Omni Turbo Realtime'
        family: 'qwen-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 0.00023
        output_cost_per_1k: 0.000918
        capabilities: [audio_input, audio_output, function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-plus':
        name: 'Qwen Plus'
        family: 'qwen-plus'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 32768
        input_cost_per_1k: 0.000115
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-plus-character':
        name: 'Qwen Plus Character'
        family: 'qwen-plus'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 4096
        input_cost_per_1k: 0.000115
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-turbo':
        name: 'Qwen Turbo'
        family: 'qwen-turbo'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 16384
        input_cost_per_1k: 4.4e-05
        output_cost_per_1k: 8.7e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'qwen-vl-max':
        name: 'Qwen-VL Max'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00023
        output_cost_per_1k: 0.000574
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-vl-ocr':
        name: 'Qwen-VL OCR'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 34096
        max_output_tokens: 4096
        input_cost_per_1k: 0.000717
        output_cost_per_1k: 0.000717
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen-vl-plus':
        name: 'Qwen-VL Plus'
        family: 'qwen-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000115
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen2-5-14b-instruct':
        name: 'Qwen2.5 14B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000431
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-32b-instruct':
        name: 'Qwen2.5 32B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-72b-instruct':
        name: 'Qwen2.5 72B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.001721
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-7b-instruct':
        name: 'Qwen2.5 7B Instruct'
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 7.2e-05
        output_cost_per_1k: 0.000144
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-coder-32b-instruct':
        name: 'Qwen2.5-Coder 32B Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-coder-7b-instruct':
        name: 'Qwen2.5-Coder 7B Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-math-72b-instruct':
        name: 'Qwen2.5-Math 72B Instruct'
        family: 'qwen2.5-math'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 3072
        input_cost_per_1k: 0.000574
        output_cost_per_1k: 0.001721
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-math-7b-instruct':
        name: 'Qwen2.5-Math 7B Instruct'
        family: 'qwen2.5-math'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 3072
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-omni-7b':
        name: 'Qwen2.5-Omni 7B'
        family: 'qwen2.5-omni'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 8.7e-05
        output_cost_per_1k: 0.000345
        capabilities: [audio_input, audio_output, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-vl-72b-instruct':
        name: 'Qwen2.5-VL 72B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.002294
        output_cost_per_1k: 0.006881
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen2-5-vl-7b-instruct':
        name: 'Qwen2.5-VL 7B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000717
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen3-14b':
        name: 'Qwen3 14B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000574
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-235b-a22b':
        name: 'Qwen3 235B-A22B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.001147
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-32b':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.001147
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-8b':
        name: 'Qwen3 8B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 7.2e-05
        output_cost_per_1k: 0.000287
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-asr-flash':
        name: 'Qwen3-ASR Flash'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 53248
        max_output_tokens: 4096
        input_cost_per_1k: 3.2e-05
        output_cost_per_1k: 3.2e-05
        capabilities: [audio_input]
        knowledge_cutoff: '2024-04'
      'qwen3-coder-30b-a3b-instruct':
        name: 'Qwen3-Coder 30B-A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.000216
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3-Coder 480B-A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.000861
        output_cost_per_1k: 0.003441
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-flash':
        name: 'Qwen3 Coder Flash'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 65536
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000574
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen3-coder-plus':
        name: 'Qwen3 Coder Plus'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-max':
        name: 'Qwen3 Max'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.000861
        output_cost_per_1k: 0.003441
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen3-next-80b-a3b-instruct':
        name: 'Qwen3-Next 80B-A3B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.000574
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-next-80b-a3b-thinking':
        name: 'Qwen3-Next 80B-A3B (Thinking)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.000144
        output_cost_per_1k: 0.001434
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-omni-flash':
        name: 'Qwen3-Omni Flash'
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 16384
        input_cost_per_1k: 5.8e-05
        output_cost_per_1k: 0.00023
        capabilities: [audio_input, audio_output, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-omni-flash-realtime':
        name: 'Qwen3-Omni Flash Realtime'
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 16384
        input_cost_per_1k: 0.00023
        output_cost_per_1k: 0.000918
        capabilities: [audio_input, audio_output, function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-vl-235b-a22b':
        name: 'Qwen3-VL 235B-A22B'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00028671
        output_cost_per_1k: 0.00114682
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-vl-30b-a3b':
        name: 'Qwen3-VL 30B-A3B'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.000108
        output_cost_per_1k: 0.000431
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-vl-plus':
        name: 'Qwen3-VL Plus'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.00014335
        output_cost_per_1k: 0.00143352
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-04'
      'qwq-32b':
        name: 'QwQ 32B'
        family: 'qwq'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.000287
        output_cost_per_1k: 0.000861
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwq-plus':
        name: 'QwQ Plus'
        family: 'qwq'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00023
        output_cost_per_1k: 0.000574
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'tongyi-intent-detect-v3':
        name: 'Tongyi Intent Detect V3'
        family: 'yi'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 1024
        input_cost_per_1k: 5.8e-05
        output_cost_per_1k: 0.000144
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
  anthropic:
    name: 'Anthropic'
    api_endpoint: 'https://api.anthropic.com/v1'
    logo_url: 'https://models.dev/logos/anthropic.svg'
    model_count: 21
    models:
      'claude-3-5-haiku-20241022':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'claude-3-5-haiku-latest':
        name: 'Claude Haiku 3.5 (latest)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'claude-3-5-sonnet-20240620':
        name: 'Claude Sonnet 3.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'claude-3-5-sonnet-20241022':
        name: 'Claude Sonnet 3.5 v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'claude-3-7-sonnet-20250219':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'claude-3-7-sonnet-latest':
        name: 'Claude Sonnet 3.7 (latest)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'claude-3-haiku-20240307':
        name: 'Claude Haiku 3'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'claude-3-opus-20240229':
        name: 'Claude Opus 3'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'claude-3-sonnet-20240229':
        name: 'Claude Sonnet 3'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'claude-haiku-4-5':
        name: 'Claude Haiku 4.5 (latest)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-haiku-4-5-20251001':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-opus-4-0':
        name: 'Claude Opus 4 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-1':
        name: 'Claude Opus 4.1 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-1-20250805':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-20250514':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5':
        name: 'Claude Opus 4.5 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5-20251101':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-0':
        name: 'Claude Sonnet 4 (latest)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-20250514':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5 (latest)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'claude-sonnet-4-5-20250929':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
  aws_bedrock:
    name: 'Amazon Bedrock'
    api_endpoint: 'https://bedrock-runtime.*.amazonaws.com'
    logo_url: 'https://models.dev/logos/amazon-bedrock.svg'
    model_count: 67
    models:
      'ai21.jamba-1-5-large-v1:0':
        name: 'Jamba 1.5 Large'
        family: 'jamba-1.5-large'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'ai21.jamba-1-5-mini-v1:0':
        name: 'Jamba 1.5 Mini'
        family: 'jamba-1.5-mini'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'amazon.nova-2-lite-v1:0':
        name: 'Nova 2 Lite'
        family: 'nova'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00033
        output_cost_per_1k: 0.00275
        capabilities: [function_calling, temperature, video_input, vision]
      'amazon.nova-lite-v1:0':
        name: 'Nova Lite'
        family: 'nova-lite'
        mode: chat
        max_input_tokens: 300000
        max_output_tokens: 8192
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00024
        cache_read_cost_per_1k: 1.5e-05
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-10'
      'amazon.nova-micro-v1:0':
        name: 'Nova Micro'
        family: 'nova-micro'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 3.5e-05
        output_cost_per_1k: 0.00014
        cache_read_cost_per_1k: 8.75e-06
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
      'amazon.nova-premier-v1:0':
        name: 'Nova Premier'
        family: 'nova'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.0125
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2024-10'
      'amazon.nova-pro-v1:0':
        name: 'Nova Pro'
        family: 'nova-pro'
        mode: chat
        max_input_tokens: 300000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0032
        cache_read_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-10'
      'amazon.titan-text-express-v1':
        name: 'Titan Text G1 - Express'
        family: 'titan-text-express'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
      'amazon.titan-text-express-v1:0:8k':
        name: 'Titan Text G1 - Express'
        family: 'titan-text-express'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
      'anthropic.claude-3-5-haiku-20241022-v1:0':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07'
      'anthropic.claude-3-5-sonnet-20240620-v1:0':
        name: 'Claude Sonnet 3.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04'
      'anthropic.claude-3-5-sonnet-20241022-v2:0':
        name: 'Claude Sonnet 3.5 v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04'
      'anthropic.claude-3-7-sonnet-20250219-v1:0':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04'
      'anthropic.claude-3-haiku-20240307-v1:0':
        name: 'Claude Haiku 3'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-02'
      'anthropic.claude-3-opus-20240229-v1:0':
        name: 'Claude Opus 3'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08'
      'anthropic.claude-3-sonnet-20240229-v1:0':
        name: 'Claude Sonnet 3'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08'
      'anthropic.claude-haiku-4-5-20251001-v1:0':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic.claude-instant-v1':
        name: 'Claude Instant'
        family: 'claude'
        mode: chat
        max_input_tokens: 100000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0024
        capabilities: [temperature]
        knowledge_cutoff: '2023-08'
      'anthropic.claude-opus-4-1-20250805-v1:0':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic.claude-opus-4-20250514-v1:0':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-04'
      'anthropic.claude-opus-4-5-20251101-v1:0':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic.claude-sonnet-4-20250514-v1:0':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-04'
      'anthropic.claude-sonnet-4-5-20250929-v1:0':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'anthropic.claude-v2':
        name: 'Claude 2'
        family: 'claude'
        mode: chat
        max_input_tokens: 100000
        max_output_tokens: 4096
        input_cost_per_1k: 0.008
        output_cost_per_1k: 0.024
        capabilities: [temperature]
        knowledge_cutoff: '2023-08'
      'anthropic.claude-v2:1':
        name: 'Claude 2.1'
        family: 'claude'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.008
        output_cost_per_1k: 0.024
        capabilities: [temperature]
        knowledge_cutoff: '2023-08'
      'cohere.command-light-text-v14':
        name: 'Command Light'
        family: 'command-light'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-08'
        open_weights: true
      'cohere.command-r-plus-v1:0':
        name: 'Command R+'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'cohere.command-r-v1:0':
        name: 'Command R'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'cohere.command-text-v14':
        name: 'Command'
        family: 'command'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2023-08'
        open_weights: true
      'deepseek.r1-v1:0':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'deepseek.v3-v1:0':
        name: 'DeepSeek-V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 81920
        input_cost_per_1k: 0.00058
        output_cost_per_1k: 0.00168
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'global.anthropic.claude-opus-4-5-20251101-v1:0':
        name: 'Claude Opus 4.5 (Global)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'google.gemma-3-12b-it':
        name: 'Google Gemma 3 12B'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0001
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-12'
      'google.gemma-3-27b-it':
        name: 'Google Gemma 3 27B Instruct'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 8192
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'google.gemma-3-4b-it':
        name: 'Gemma 3 4B IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature, vision]
      'meta.llama3-1-70b-instruct-v1:0':
        name: 'Llama 3.1 70B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00072
        output_cost_per_1k: 0.00072
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-1-8b-instruct-v1:0':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-2-11b-instruct-v1:0':
        name: 'Llama 3.2 11B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00016
        output_cost_per_1k: 0.00016
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-2-1b-instruct-v1:0':
        name: 'Llama 3.2 1B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-2-3b-instruct-v1:0':
        name: 'Llama 3.2 3B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-2-90b-instruct-v1:0':
        name: 'Llama 3.2 90B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00072
        output_cost_per_1k: 0.00072
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-3-70b-instruct-v1:0':
        name: 'Llama 3.3 70B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00072
        output_cost_per_1k: 0.00072
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-70b-instruct-v1:0':
        name: 'Llama 3 70B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.00265
        output_cost_per_1k: 0.0035
        capabilities: [temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta.llama3-8b-instruct-v1:0':
        name: 'Llama 3 8B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-03'
        open_weights: true
      'meta.llama4-maverick-17b-instruct-v1:0':
        name: 'Llama 4 Maverick 17B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00024
        output_cost_per_1k: 0.00097
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'meta.llama4-scout-17b-instruct-v1:0':
        name: 'Llama 4 Scout 17B Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 3500000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00066
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'minimax.minimax-m2':
        name: 'MiniMax M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204608
        max_output_tokens: 128000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'mistral.ministral-3-14b-instruct':
        name: 'Ministral 14B 3.0'
        family: 'ministral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
      'mistral.ministral-3-8b-instruct':
        name: 'Ministral 3 8B'
        family: 'ministral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
      'mistral.mistral-7b-instruct-v0:2':
        name: 'Mistral-7B-Instruct-v0.3'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 127000
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00011
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistral.mistral-large-2402-v1:0':
        name: 'Mistral Large (24.02)'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature]
      'mistral.mixtral-8x7b-instruct-v0:1':
        name: 'Mixtral-8x7B-Instruct-v0.1'
        family: 'mixtral-8x7b'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0007
        capabilities: [json_mode, temperature]
        open_weights: true
      'mistral.voxtral-mini-3b-2507':
        name: 'Voxtral Mini 3B 2507'
        family: 'mistral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 4e-05
        capabilities: [audio_input, function_calling, temperature]
      'mistral.voxtral-small-24b-2507':
        name: 'Voxtral Small 24B 2507'
        family: 'mistral'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00035
        capabilities: [audio_input, function_calling, temperature, vision]
        open_weights: true
      'moonshot.kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'nvidia.nemotron-nano-12b-v2':
        name: 'NVIDIA Nemotron Nano 12B v2 VL BF16'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature, vision]
      'nvidia.nemotron-nano-9b-v2':
        name: 'NVIDIA Nemotron Nano 9B v2'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00023
        capabilities: [function_calling, temperature]
      'openai.gpt-oss-120b-1:0':
        name: 'gpt-oss-120b'
        family: 'openai.gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
      'openai.gpt-oss-20b-1:0':
        name: 'gpt-oss-20b'
        family: 'openai.gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
      'openai.gpt-oss-safeguard-120b':
        name: 'GPT OSS Safeguard 120B'
        family: 'openai.gpt-oss-safeguard'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
      'openai.gpt-oss-safeguard-20b':
        name: 'GPT OSS Safeguard 20B'
        family: 'openai.gpt-oss-safeguard'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
      'qwen.qwen3-235b-a22b-2507-v1:0':
        name: 'Qwen3 235B A22B 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00088
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen.qwen3-32b-v1:0':
        name: 'Qwen3 32B (dense)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen.qwen3-coder-30b-a3b-v1:0':
        name: 'Qwen3 Coder 30B A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
      'qwen.qwen3-coder-480b-a35b-v1:0':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'qwen.qwen3-next-80b-a3b':
        name: 'Qwen/Qwen3-Next-80B-A3B-Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, json_mode, temperature]
      'qwen.qwen3-vl-235b-a22b':
        name: 'Qwen/Qwen3-VL-235B-A22B-Instruct'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, json_mode, temperature, vision]
  azure_cognitive_services:
    name: 'Azure Cognitive Services'
    logo_url: 'https://models.dev/logos/azure-cognitive-services.svg'
    model_count: 90
    models:
      'claude-haiku-4-5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-31'
      'claude-opus-4-1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'codestral-2501':
        name: 'Codestral 25.01'
        family: 'codestral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-03'
      'codex-mini':
        name: 'Codex Mini'
        family: 'codex'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.000375
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-04'
      'cohere-command-a':
        name: 'Command A'
        family: 'command-a'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-command-r-08-2024':
        name: 'Command R'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-command-r-plus-08-2024':
        name: 'Command R+'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-embed-v-4-0':
        name: 'Embed v4'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 128000
        max_output_tokens: 1536
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.0
        capabilities: [vision]
        open_weights: true
      'cohere-embed-v3-english':
        name: 'Embed v3 English'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 512
        max_output_tokens: 1024
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
        open_weights: true
      'cohere-embed-v3-multilingual':
        name: 'Embed v3 Multilingual'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 512
        max_output_tokens: 1024
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
        open_weights: true
      'deepseek-r1':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-r1-0528':
        name: 'DeepSeek-R1-0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3-0324':
        name: 'DeepSeek-V3-0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00114
        output_cost_per_1k: 0.00456
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.1':
        name: 'DeepSeek-V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.2':
        name: 'DeepSeek-V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 2.8e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.2-speciale':
        name: 'DeepSeek-V3.2-Speciale'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'gpt-3.5-turbo-0125':
        name: 'GPT-3.5 Turbo 0125'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-0301':
        name: 'GPT-3.5 Turbo 0301'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-0613':
        name: 'GPT-3.5 Turbo 0613'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.004
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-1106':
        name: 'GPT-3.5 Turbo 1106'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-instruct':
        name: 'GPT-3.5 Turbo Instruct'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-4':
        name: 'GPT-4'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.06
        output_cost_per_1k: 0.12
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-11'
      'gpt-4-32k':
        name: 'GPT-4 32K'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.06
        output_cost_per_1k: 0.12
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-11'
      'gpt-4-turbo':
        name: 'GPT-4 Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'gpt-4-turbo-vision':
        name: 'GPT-4 Turbo Vision'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4.1-mini':
        name: 'GPT-4.1 mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4.1-nano':
        name: 'GPT-4.1 nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-chat':
        name: 'GPT-5 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2024-10-24'
      'gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-pro':
        name: 'GPT-5 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 272000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.12
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: image
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-chat':
        name: 'GPT-5.1 Chat'
        family: 'gpt-5-chat'
        mode: image
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1 Codex Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2-chat':
        name: 'GPT-5.2 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-4':
        name: 'Grok 4'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'grok-4-fast-non-reasoning':
        name: 'Grok 4 Fast (Non-Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-4-fast-reasoning':
        name: 'Grok 4 Fast (Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'llama-3.2-11b-vision-instruct':
        name: 'Llama-3.2-11B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00037
        output_cost_per_1k: 0.00037
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.2-90b-vision-instruct':
        name: 'Llama-3.2-90B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00204
        output_cost_per_1k: 0.00204
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-70b-instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00071
        output_cost_per_1k: 0.00071
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-4-maverick-17b-128e-instruct-fp8':
        name: 'Llama 4 Maverick 17B 128E Instruct FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.00078
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'mai-ds-r1':
        name: 'MAI-DS-R1'
        family: 'mai-ds-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-06'
      'meta-llama-3-70b-instruct':
        name: 'Meta-Llama-3-70B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.00268
        output_cost_per_1k: 0.00354
        capabilities: [temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3-8b-instruct':
        name: 'Meta-Llama-3-8B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00061
        capabilities: [temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-405b-instruct':
        name: 'Meta-Llama-3.1-405B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00533
        output_cost_per_1k: 0.016
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-70b-instruct':
        name: 'Meta-Llama-3.1-70B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00268
        output_cost_per_1k: 0.00354
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-8b-instruct':
        name: 'Meta-Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00061
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'ministral-3b':
        name: 'Ministral 3B'
        family: 'ministral-3b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 4e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-03'
        open_weights: true
      'mistral-large-2411':
        name: 'Mistral Large 24.11'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-09'
      'mistral-medium-2505':
        name: 'Mistral Medium 3'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistral-nemo':
        name: 'Mistral Nemo'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'mistral-small-2503':
        name: 'Mistral Small 3.1'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09'
      'model-router':
        name: 'Model Router'
        family: 'model-router'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0
        capabilities: [function_calling, vision]
      'o1':
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'o1-mini':
        family: 'o1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2023-09'
      'o1-preview':
        family: 'o1-preview'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0165
        output_cost_per_1k: 0.066
        cache_read_cost_per_1k: 0.00825
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2023-09'
      'o3':
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o3-mini':
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2024-05'
      'o4-mini':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'phi-3-medium-128k-instruct':
        name: 'Phi-3-medium-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00068
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-medium-4k-instruct':
        name: 'Phi-3-medium-instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00068
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-mini-128k-instruct':
        name: 'Phi-3-mini-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-mini-4k-instruct':
        name: 'Phi-3-mini-instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-small-128k-instruct':
        name: 'Phi-3-small-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-small-8k-instruct':
        name: 'Phi-3-small-instruct (8k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3.5-mini-instruct':
        name: 'Phi-3.5-mini-instruct'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3.5-moe-instruct':
        name: 'Phi-3.5-MoE-instruct'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00016
        output_cost_per_1k: 0.00064
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4':
        name: 'Phi-4'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-mini':
        name: 'Phi-4-mini'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-mini-reasoning':
        name: 'Phi-4-mini-reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-multimodal':
        name: 'Phi-4-multimodal'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00032
        capabilities: [audio_input, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-reasoning':
        name: 'Phi-4-reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-reasoning-plus':
        name: 'Phi-4-reasoning-plus'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'text-embedding-3-large':
        family: 'text-embedding-3-large'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 3072
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0
      'text-embedding-3-small':
        family: 'text-embedding-3-small'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 1536
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0
      'text-embedding-ada-002':
        family: 'text-embedding-ada'
        mode: embedding
        max_input_tokens: 8192
        max_output_tokens: 1536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
  azure_openai:
    name: 'Azure'
    api_endpoint: 'https://*.openai.azure.com/openai'
    logo_url: 'https://models.dev/logos/azure.svg'
    model_count: 92
    models:
      'claude-haiku-4-5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-31'
      'claude-opus-4-1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'codestral-2501':
        name: 'Codestral 25.01'
        family: 'codestral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-03'
      'codex-mini':
        name: 'Codex Mini'
        family: 'codex'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.000375
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-04'
      'cohere-command-a':
        name: 'Command A'
        family: 'command-a'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-command-r-08-2024':
        name: 'Command R'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-command-r-plus-08-2024':
        name: 'Command R+'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'cohere-embed-v-4-0':
        name: 'Embed v4'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 128000
        max_output_tokens: 1536
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.0
        capabilities: [vision]
        open_weights: true
      'cohere-embed-v3-english':
        name: 'Embed v3 English'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 512
        max_output_tokens: 1024
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
        open_weights: true
      'cohere-embed-v3-multilingual':
        name: 'Embed v3 Multilingual'
        family: 'cohere-embed'
        mode: embedding
        max_input_tokens: 512
        max_output_tokens: 1024
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
        open_weights: true
      'deepseek-r1':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-r1-0528':
        name: 'DeepSeek-R1-0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3-0324':
        name: 'DeepSeek-V3-0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00114
        output_cost_per_1k: 0.00456
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.1':
        name: 'DeepSeek-V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.2':
        name: 'DeepSeek-V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 2.8e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-v3.2-speciale':
        name: 'DeepSeek-V3.2-Speciale'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'gpt-3.5-turbo-0125':
        name: 'GPT-3.5 Turbo 0125'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-0301':
        name: 'GPT-3.5 Turbo 0301'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-0613':
        name: 'GPT-3.5 Turbo 0613'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.004
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-1106':
        name: 'GPT-3.5 Turbo 1106'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-3.5-turbo-instruct':
        name: 'GPT-3.5 Turbo Instruct'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.002
        capabilities: [temperature]
        knowledge_cutoff: '2021-08'
      'gpt-4':
        name: 'GPT-4'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.06
        output_cost_per_1k: 0.12
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-11'
      'gpt-4-32k':
        name: 'GPT-4 32K'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.06
        output_cost_per_1k: 0.12
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-11'
      'gpt-4-turbo':
        name: 'GPT-4 Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'gpt-4-turbo-vision':
        name: 'GPT-4 Turbo Vision'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4.1-mini':
        name: 'GPT-4.1 mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4.1-nano':
        name: 'GPT-4.1 nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-chat':
        name: 'GPT-5 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2024-10-24'
      'gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-pro':
        name: 'GPT-5 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 272000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.12
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: image
        max_input_tokens: 272000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-chat':
        name: 'GPT-5.1 Chat'
        family: 'gpt-5-chat'
        mode: image
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-max':
        name: 'GPT-5.1 Codex Max'
        family: 'gpt-5-codex-max'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1 Codex Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'gpt-5.2-chat':
        name: 'GPT-5.2 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-4':
        name: 'Grok 4'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'grok-4-fast-non-reasoning':
        name: 'Grok 4 Fast (Non-Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-4-fast-reasoning':
        name: 'Grok 4 Fast (Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'llama-3.2-11b-vision-instruct':
        name: 'Llama-3.2-11B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00037
        output_cost_per_1k: 0.00037
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.2-90b-vision-instruct':
        name: 'Llama-3.2-90B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00204
        output_cost_per_1k: 0.00204
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-70b-instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00071
        output_cost_per_1k: 0.00071
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-4-maverick-17b-128e-instruct-fp8':
        name: 'Llama 4 Maverick 17B 128E Instruct FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.00078
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'mai-ds-r1':
        name: 'MAI-DS-R1'
        family: 'mai-ds-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-06'
      'meta-llama-3-70b-instruct':
        name: 'Meta-Llama-3-70B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.00268
        output_cost_per_1k: 0.00354
        capabilities: [temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3-8b-instruct':
        name: 'Meta-Llama-3-8B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00061
        capabilities: [temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-405b-instruct':
        name: 'Meta-Llama-3.1-405B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00533
        output_cost_per_1k: 0.016
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-70b-instruct':
        name: 'Meta-Llama-3.1-70B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00268
        output_cost_per_1k: 0.00354
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama-3.1-8b-instruct':
        name: 'Meta-Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00061
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'ministral-3b':
        name: 'Ministral 3B'
        family: 'ministral-3b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 4e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-03'
        open_weights: true
      'mistral-large-2411':
        name: 'Mistral Large 24.11'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-09'
      'mistral-medium-2505':
        name: 'Mistral Medium 3'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistral-nemo':
        name: 'Mistral Nemo'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'mistral-small-2503':
        name: 'Mistral Small 3.1'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09'
      'model-router':
        name: 'Model Router'
        family: 'model-router'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0
        capabilities: [function_calling, vision]
      'o1':
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'o1-mini':
        family: 'o1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2023-09'
      'o1-preview':
        family: 'o1-preview'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0165
        output_cost_per_1k: 0.066
        cache_read_cost_per_1k: 0.00825
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2023-09'
      'o3':
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o3-mini':
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, reasoning]
        knowledge_cutoff: '2024-05'
      'o4-mini':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'phi-3-medium-128k-instruct':
        name: 'Phi-3-medium-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00068
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-medium-4k-instruct':
        name: 'Phi-3-medium-instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00068
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-mini-128k-instruct':
        name: 'Phi-3-mini-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-mini-4k-instruct':
        name: 'Phi-3-mini-instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-small-128k-instruct':
        name: 'Phi-3-small-instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3-small-8k-instruct':
        name: 'Phi-3-small-instruct (8k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3.5-mini-instruct':
        name: 'Phi-3.5-mini-instruct'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-3.5-moe-instruct':
        name: 'Phi-3.5-MoE-instruct'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00016
        output_cost_per_1k: 0.00064
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4':
        name: 'Phi-4'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-mini':
        name: 'Phi-4-mini'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-mini-reasoning':
        name: 'Phi-4-mini-reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-multimodal':
        name: 'Phi-4-multimodal'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00032
        capabilities: [audio_input, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-reasoning':
        name: 'Phi-4-reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'phi-4-reasoning-plus':
        name: 'Phi-4-reasoning-plus'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 0.000125
        output_cost_per_1k: 0.0005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'text-embedding-3-large':
        family: 'text-embedding-3-large'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 3072
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0
      'text-embedding-3-small':
        family: 'text-embedding-3-small'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 1536
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0
      'text-embedding-ada-002':
        family: 'text-embedding-ada'
        mode: embedding
        max_input_tokens: 8192
        max_output_tokens: 1536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
  bailing:
    name: 'Bailing'
    api_endpoint: 'https://api.tbox.cn/api/llm/v1/chat/completions'
    logo_url: 'https://models.dev/logos/bailing.svg'
    model_count: 2
    models:
      'Ling-1T':
        family: 'ling-1t'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00057
        output_cost_per_1k: 0.00229
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'Ring-1T':
        family: 'ring-1t'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00057
        output_cost_per_1k: 0.00229
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
  baseten:
    name: 'Baseten'
    api_endpoint: 'https://inference.baseten.co/v1'
    logo_url: 'https://models.dev/logos/baseten.svg'
    model_count: 6
    models:
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.00038
        output_cost_per_1k: 0.00153
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'deepseek-ai/DeepSeek-V3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163800
        max_output_tokens: 131100
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-10'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct-0905':
        name: 'Kimi K2 Instruct 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-08'
        open_weights: true
      'moonshotai/Kimi-K2-Thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'zai-org/GLM-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 200000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-08-31'
        open_weights: true
      'zai-org/GLM-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  cerebras:
    name: 'Cerebras'
    api_endpoint: 'https://api.cerebras.ai/v1'
    logo_url: 'https://models.dev/logos/cerebras.svg'
    model_count: 4
    models:
      'gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00069
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'qwen-3-235b-a22b-instruct-2507':
        name: 'Qwen 3 235B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'zai-glm-4.6':
        name: 'Z.AI GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 40960
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'zai-glm-4.7':
        name: 'Z.AI GLM-4.7'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 40000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
  chutes:
    name: 'Chutes'
    api_endpoint: 'https://llm.chutes.ai/v1'
    logo_url: 'https://models.dev/logos/chutes.svg'
    model_count: 55
    models:
      'MiniMaxAI/MiniMax-M2.1-TEE':
        name: 'MiniMax M2.1 TEE'
        family: 'minimaxai'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'NousResearch/DeepHermes-3-Mistral-24B-Preview':
        name: 'DeepHermes 3 Mistral 24B Preview'
        family: 'nousresearch'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0001
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'NousResearch/Hermes-4-14B':
        name: 'Hermes 4 14B'
        family: 'nousresearch'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 5e-05
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'NousResearch/Hermes-4-405B-FP8-TEE':
        name: 'Hermes 4 405B FP8 TEE'
        family: 'nousresearch'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'NousResearch/Hermes-4-70B':
        name: 'Hermes 4 70B'
        family: 'nousresearch'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00038
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'NousResearch/Hermes-4.3-36B':
        name: 'Hermes 4.3 36B'
        family: 'nousresearch'
        mode: chat
        max_input_tokens: 524288
        max_output_tokens: 524288
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.00039
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'OpenGVLab/InternVL3-78B-TEE':
        name: 'InternVL3 78B TEE'
        family: 'opengvlab'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.00039
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'Qwen/Qwen2.5-72B-Instruct':
        name: 'Qwen2.5 72B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00052
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen2.5-Coder-32B-Instruct':
        name: 'Qwen2.5 Coder 32B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00011
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature]
        open_weights: true
      'Qwen/Qwen2.5-VL-32B-Instruct':
        name: 'Qwen2.5 VL 32B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'Qwen/Qwen2.5-VL-72B-Instruct-TEE':
        name: 'Qwen2.5 VL 72B Instruct TEE'
        family: 'qwen'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [temperature, vision]
        open_weights: true
      'Qwen/Qwen3-14B':
        name: 'Qwen3 14B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B':
        name: 'Qwen3 235B A22B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Instruct-2507-TEE':
        name: 'Qwen3 235B A22B Instruct 2507 TEE'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00055
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-30B-A3B':
        name: 'Qwen3 30B A3B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-30B-A3B-Instruct-2507':
        name: 'Qwen3 30B A3B Instruct 2507'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00033
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen3-32B':
        name: 'Qwen3 32B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00024
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE':
        name: 'Qwen3 Coder 480B A35B Instruct FP8 TEE'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00095
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen3-Next-80B-A3B-Instruct':
        name: 'Qwen3 Next 80B A3B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0008
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen3-VL-235B-A22B-Instruct':
        name: 'Qwen3 VL 235B A22B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'Qwen/Qwen3Guard-Gen-0.6B':
        name: 'Qwen3Guard Gen 0.6B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 1e-05
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'XiaomiMiMo/MiMo-V2-Flash':
        name: 'MiMo V2 Flash'
        family: 'xiaomimimo'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00065
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'chutesai/Mistral-Small-3.1-24B-Instruct-2503':
        name: 'Mistral Small 3.1 24B Instruct 2503'
        family: 'chutesai'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00011
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'chutesai/Mistral-Small-3.2-24B-Instruct-2506':
        name: 'Mistral Small 3.2 24B Instruct 2506'
        family: 'chutesai'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00018
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'deepseek-ai/DeepSeek-R1-0528-TEE':
        name: 'DeepSeek R1 0528 TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.00175
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-R1-Distill-Llama-70B':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00011
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-R1-TEE':
        name: 'DeepSeek R1 TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3':
        name: 'DeepSeek V3'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3-0324-TEE':
        name: 'DeepSeek V3 0324 TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00019
        output_cost_per_1k: 0.00087
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3.1-TEE':
        name: 'DeepSeek V3.1 TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3.1-Terminus-TEE':
        name: 'DeepSeek V3.1 Terminus TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00023
        output_cost_per_1k: 0.0009
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3.2-Speciale-TEE':
        name: 'DeepSeek V3.2 Speciale TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00041
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-V3.2-TEE':
        name: 'DeepSeek V3.2 TEE'
        family: 'deepseek-ai'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00038
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'mistralai/Devstral-2-123B-Instruct-2512':
        name: 'Devstral 2 123B Instruct 2512'
        family: 'mistralai'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'moonshotai/Kimi-K2-Instruct-0905':
        name: 'Kimi K2 Instruct 0905'
        family: 'moonshotai'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00039
        output_cost_per_1k: 0.0019
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'moonshotai/Kimi-K2-Thinking-TEE':
        name: 'Kimi K2 Thinking TEE'
        family: 'moonshotai'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65535
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.00175
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16':
        name: 'NVIDIA Nemotron 3 Nano 30B A3B BF16'
        family: 'nvidia'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00024
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'openai/gpt-oss-120b-TEE':
        name: 'gpt oss 120b TEE'
        family: 'openai'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00018
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'gpt oss 20b'
        family: 'openai'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0001
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'rednote-hilab/dots.ocr':
        name: 'dots.ocr'
        family: 'rednote-hilab'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 1e-05
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'tngtech/DeepSeek-R1T-Chimera':
        name: 'DeepSeek R1T Chimera'
        family: 'tngtech'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'tngtech/DeepSeek-TNG-R1T2-Chimera':
        name: 'DeepSeek TNG R1T2 Chimera'
        family: 'tngtech'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00085
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'tngtech/DeepSeek-TNG-R1T2-Chimera-TEE':
        name: 'DeepSeek TNG R1T2 Chimera TEE'
        family: 'tngtech'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00085
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'tngtech/TNG-R1T-Chimera-TEE':
        name: 'TNG R1T Chimera TEE'
        family: 'tngtech'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00085
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'unsloth/Mistral-Nemo-Instruct-2407':
        name: 'Mistral Nemo Instruct 2407'
        family: 'unsloth'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 4e-05
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature]
        open_weights: true
      'unsloth/Mistral-Small-24B-Instruct-2501':
        name: 'Mistral Small 24B Instruct 2501'
        family: 'unsloth'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00011
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'unsloth/gemma-3-12b-it':
        name: 'gemma 3 12b it'
        family: 'unsloth'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.0001
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [temperature, vision]
        open_weights: true
      'unsloth/gemma-3-27b-it':
        name: 'gemma 3 27b it'
        family: 'unsloth'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 96000
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00015
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'unsloth/gemma-3-4b-it':
        name: 'gemma 3 4b it'
        family: 'unsloth'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 96000
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 3e-05
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'zai-org/GLM-4.5-Air':
        name: 'GLM 4.5 Air'
        family: 'zai-org'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.5-TEE':
        name: 'GLM 4.5 TEE'
        family: 'zai-org'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00155
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.6-TEE':
        name: 'GLM 4.6 TEE'
        family: 'zai-org'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 65536
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.6V':
        name: 'GLM 4.6V'
        family: 'zai-org'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        open_weights: true
      'zai-org/GLM-4.7-TEE':
        name: 'GLM 4.7 TEE'
        family: 'zai-org'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 65535
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
  cloudflare_ai_gateway:
    name: 'Cloudflare AI Gateway'
    api_endpoint: 'https://gateway.ai.cloudflare.com/v1/${CLOUDFLARE_ACCOUNT_ID}/${CLOUDFLARE_GATEWAY_ID}/compat/'
    logo_url: 'https://models.dev/logos/cloudflare-ai-gateway.svg'
    model_count: 64
    models:
      'anthropic/claude-3-5-haiku':
        name: 'Claude Haiku 3.5 (latest)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'anthropic/claude-3-haiku':
        name: 'Claude Haiku 3'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic/claude-3-opus':
        name: 'Claude Opus 3'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic/claude-3-sonnet':
        name: 'Claude Sonnet 3'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic/claude-3.5-haiku':
        name: 'Claude Haiku 3.5 (latest)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'anthropic/claude-3.5-sonnet':
        name: 'Claude Sonnet 3.5 v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'anthropic/claude-haiku-4-5':
        name: 'Claude Haiku 4.5 (latest)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic/claude-opus-4':
        name: 'Claude Opus 4 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4-1':
        name: 'Claude Opus 4.1 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4-5':
        name: 'Claude Opus 4.5 (latest)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4 (latest)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5 (latest)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'openai/gpt-3.5-turbo':
        name: 'GPT-3.5-turbo'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16385
        max_output_tokens: 4096
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 0.00125
        capabilities: [temperature]
        knowledge_cutoff: '2021-09-01'
      'openai/gpt-4':
        name: 'GPT-4'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.03
        output_cost_per_1k: 0.06
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'openai/gpt-4-turbo':
        name: 'GPT-4 Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
      'openai/gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'openai/gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'openai/gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'openai/o1':
        name: 'o1'
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'openai/o3':
        name: 'o3'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'openai/o3-mini':
        name: 'o3-mini'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, json_mode, reasoning]
        knowledge_cutoff: '2024-05'
      'openai/o3-pro':
        name: 'o3-pro'
        family: 'o3-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.02
        output_cost_per_1k: 0.08
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'openai/o4-mini':
        name: 'o4-mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B':
        name: 'IndicTrans2 EN-Indic 1B'
        family: 'indictrans2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00034
        output_cost_per_1k: 0.00034
        capabilities: [temperature]
      'workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it':
        name: 'Gemma SEA-LION v4 27B IT'
        family: 'gemma-sea-lion'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [temperature]
      'workers-ai/@cf/baai/bge-base-en-v1.5':
        name: 'BGE Base EN v1.5'
        family: 'bge-base'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 6.7e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/baai/bge-large-en-v1.5':
        name: 'BGE Large EN v1.5'
        family: 'bge-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/baai/bge-m3':
        name: 'BGE M3'
        family: 'bge-m3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 1.2e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/baai/bge-reranker-base':
        name: 'BGE Reranker Base'
        family: 'bge-reranker'
        mode: rerank
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 3.1e-06
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/baai/bge-small-en-v1.5':
        name: 'BGE Small EN v1.5'
        family: 'bge-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/deepgram/aura-2-en':
        name: 'Deepgram Aura 2 (EN)'
        family: 'aura-2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/deepgram/aura-2-es':
        name: 'Deepgram Aura 2 (ES)'
        family: 'aura-2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/deepgram/nova-3':
        name: 'Deepgram Nova 3'
        family: 'nova'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b':
        name: 'DeepSeek R1 Distill Qwen 32B'
        family: 'deepseek-r1-distill-qwen'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00488
        capabilities: [temperature]
      'workers-ai/@cf/facebook/bart-large-cnn':
        name: 'BART Large CNN'
        family: 'bart'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/google/gemma-3-12b-it':
        name: 'Gemma 3 12B IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [temperature]
      'workers-ai/@cf/huggingface/distilbert-sst-2-int8':
        name: 'DistilBERT SST-2 INT8'
        family: 'distilbert'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 2.6e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/ibm-granite/granite-4.0-h-micro':
        name: 'IBM Granite 4.0 H Micro'
        family: 'granite-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 1.7e-05
        output_cost_per_1k: 0.00011
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-2-7b-chat-fp16':
        name: 'Llama 2 7B Chat FP16'
        family: 'llama-2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00667
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3-8b-instruct':
        name: 'Llama 3 8B Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00083
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3-8b-instruct-awq':
        name: 'Llama 3 8B Instruct AWQ'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.00027
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.1-8b-instruct':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00083
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.1-8b-instruct-awq':
        name: 'Llama 3.1 8B Instruct AWQ'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.00027
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8':
        name: 'Llama 3.1 8B Instruct FP8'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00029
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.2-11b-vision-instruct':
        name: 'Llama 3.2 11B Vision Instruct'
        family: 'llama-3.2-vision'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 4.9e-05
        output_cost_per_1k: 0.00068
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.2-1b-instruct':
        name: 'Llama 3.2 1B Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 2.7e-05
        output_cost_per_1k: 0.0002
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.2-3b-instruct':
        name: 'Llama 3.2 3B Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 5.1e-05
        output_cost_per_1k: 0.00034
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast':
        name: 'Llama 3.3 70B Instruct FP8 Fast'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00225
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00085
        capabilities: [temperature]
      'workers-ai/@cf/meta/llama-guard-3-8b':
        name: 'Llama Guard 3 8B'
        family: 'llama-guard'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00048
        output_cost_per_1k: 3e-05
        capabilities: [temperature]
      'workers-ai/@cf/meta/m2m100-1.2b':
        name: 'M2M100 1.2B'
        family: 'm2m100'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00034
        output_cost_per_1k: 0.00034
        capabilities: [temperature]
      'workers-ai/@cf/mistral/mistral-7b-instruct-v0.1':
        name: 'Mistral 7B Instruct v0.1'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00019
        capabilities: [temperature]
      'workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct':
        name: 'Mistral Small 3.1 24B Instruct'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [temperature]
      'workers-ai/@cf/myshell-ai/melotts':
        name: 'MyShell MeloTTS'
        family: 'melotts'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00075
        capabilities: [temperature]
      'workers-ai/@cf/openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0003
        capabilities: [temperature]
      'workers-ai/@cf/pfnet/plamo-embedding-1b':
        name: 'PLaMo Embedding 1B'
        family: 'plamo-embedding'
        mode: embedding
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 1.9e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/pipecat-ai/smart-turn-v2':
        name: 'Pipecat Smart Turn v2'
        family: 'smart-turn'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct':
        name: 'Qwen 2.5 Coder 32B Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00066
        output_cost_per_1k: 0.001
        capabilities: [temperature]
      'workers-ai/@cf/qwen/qwen3-30b-a3b-fp8':
        name: 'Qwen3 30B A3B FP8'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 5.1e-05
        output_cost_per_1k: 0.00034
        capabilities: [temperature]
      'workers-ai/@cf/qwen/qwen3-embedding-0.6b':
        name: 'Qwen3 Embedding 0.6B'
        family: 'qwen3-embedding'
        mode: embedding
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 1.2e-05
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'workers-ai/@cf/qwen/qwq-32b':
        name: 'QwQ 32B'
        family: 'qwq'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00066
        output_cost_per_1k: 0.001
        capabilities: [temperature]
  cloudflare_workers_ai:
    name: 'Cloudflare Workers AI'
    logo_url: 'https://models.dev/logos/cloudflare-workers-ai.svg'
    model_count: 73
    models:
      'aura-1':
        name: '@cf/deepgram/aura-1'
        family: 'aura'
        mode: audio_speech
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 1.5e-05
        output_cost_per_1k: 1.5e-05
        capabilities: [audio_output]
        open_weights: true
      'bart-large-cnn':
        name: '@cf/facebook/bart-large-cnn'
        family: 'bart-large-cnn'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        open_weights: true
      'deepseek-coder-6.7b-base-awq':
        name: '@hf/thebloke/deepseek-coder-6.7b-base-awq'
        family: 'deepseek-coder'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'deepseek-coder-6.7b-instruct-awq':
        name: '@hf/thebloke/deepseek-coder-6.7b-instruct-awq'
        family: 'deepseek-coder'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'deepseek-math-7b-instruct':
        name: '@cf/deepseek-ai/deepseek-math-7b-instruct'
        family: 'deepseek'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'deepseek-r1-distill-qwen-32b':
        name: '@cf/deepseek-ai/deepseek-r1-distill-qwen-32b'
        family: 'qwen'
        mode: chat
        max_input_tokens: 80000
        max_output_tokens: 80000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00488
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'discolm-german-7b-v1-awq':
        name: '@cf/thebloke/discolm-german-7b-v1-awq'
        family: 'discolm-german'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'dreamshaper-8-lcm':
        name: '@cf/lykon/dreamshaper-8-lcm'
        family: 'dreamshaper-8-lcm'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output, vision]
        open_weights: true
      'falcon-7b-instruct':
        name: '@cf/tiiuae/falcon-7b-instruct'
        family: 'falcon-7b'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'flux-1-schnell':
        name: '@cf/black-forest-labs/flux-1-schnell'
        family: 'flux-1'
        mode: image
        max_input_tokens: 2048
        max_output_tokens: 0
        input_cost_per_1k: 5e-08
        output_cost_per_1k: 1.1e-07
        capabilities: [image_output]
        open_weights: true
      'gemma-2b-it-lora':
        name: '@cf/google/gemma-2b-it-lora'
        family: 'gemma-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'gemma-3-12b-it':
        name: '@cf/google/gemma-3-12b-it'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 80000
        max_output_tokens: 80000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [function_calling, temperature]
        open_weights: true
      'gemma-7b-it':
        name: '@hf/google/gemma-7b-it'
        family: 'gemma'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'gemma-7b-it-lora':
        name: '@cf/google/gemma-7b-it-lora'
        family: 'gemma'
        mode: chat
        max_input_tokens: 3500
        max_output_tokens: 3500
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'gemma-sea-lion-v4-27b-it':
        name: '@cf/aisingapore/gemma-sea-lion-v4-27b-it'
        family: 'gemma'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 0
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [function_calling, temperature]
      'gpt-oss-120b':
        name: '@cf/openai/gpt-oss-120b'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00075
        capabilities: [reasoning]
        open_weights: true
      'gpt-oss-20b':
        name: '@cf/openai/gpt-oss-20b'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0003
        capabilities: [reasoning]
        open_weights: true
      'granite-4.0-h-micro':
        name: '@cf/ibm-granite/granite-4.0-h-micro'
        family: 'granite'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 0
        input_cost_per_1k: 1.7e-05
        output_cost_per_1k: 0.00011
        capabilities: [function_calling, temperature]
      'hermes-2-pro-mistral-7b':
        name: '@hf/nousresearch/hermes-2-pro-mistral-7b'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 24000
        max_output_tokens: 24000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-2-13b-chat-awq':
        name: '@hf/thebloke/llama-2-13b-chat-awq'
        family: 'llama-2'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'llama-2-7b-chat-fp16':
        name: '@cf/meta/llama-2-7b-chat-fp16'
        family: 'llama-2'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00667
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-2-7b-chat-hf-lora':
        name: '@cf/meta-llama/llama-2-7b-chat-hf-lora'
        family: 'llama-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-2-7b-chat-int8':
        name: '@cf/meta/llama-2-7b-chat-int8'
        family: 'llama-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.000556
        output_cost_per_1k: 0.006667
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3-8b-instruct':
        name: '@cf/meta/llama-3-8b-instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 7968
        max_output_tokens: 7968
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00083
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3-8b-instruct-awq':
        name: '@cf/meta/llama-3-8b-instruct-awq'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.1-70b-instruct':
        name: '@cf/meta/llama-3.1-70b-instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 24000
        max_output_tokens: 24000
        input_cost_per_1k: 0.000293
        output_cost_per_1k: 0.002253
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.1-8b-instruct':
        name: '@cf/meta/llama-3.1-8b-instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 7968
        max_output_tokens: 7968
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00083
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.1-8b-instruct-awq':
        name: '@cf/meta/llama-3.1-8b-instruct-awq'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.1-8b-instruct-fast':
        name: '@cf/meta/llama-3.1-8b-instruct-fast'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 4.5e-05
        output_cost_per_1k: 0.000384
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.1-8b-instruct-fp8':
        name: '@cf/meta/llama-3.1-8b-instruct-fp8'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00029
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.2-11b-vision-instruct':
        name: '@cf/meta/llama-3.2-11b-vision-instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 4.9e-05
        output_cost_per_1k: 0.00068
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.2-1b-instruct':
        name: '@cf/meta/llama-3.2-1b-instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 60000
        max_output_tokens: 60000
        input_cost_per_1k: 2.7e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.2-3b-instruct':
        name: '@cf/meta/llama-3.2-3b-instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 5.1e-05
        output_cost_per_1k: 0.00034
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-3.3-70b-instruct-fp8-fast':
        name: '@cf/meta/llama-3.3-70b-instruct-fp8-fast'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 24000
        max_output_tokens: 24000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00225
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-4-scout-17b-16e-instruct':
        name: '@cf/meta/llama-4-scout-17b-16e-instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00085
        capabilities: [function_calling, temperature]
        open_weights: true
      'llama-guard-3-8b':
        name: '@cf/meta/llama-guard-3-8b'
        family: 'llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 0
        input_cost_per_1k: 0.00048
        output_cost_per_1k: 3e-05
        capabilities: [temperature]
        open_weights: true
      'llamaguard-7b-awq':
        name: '@hf/thebloke/llamaguard-7b-awq'
        family: 'llama'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'llava-1.5-7b-hf':
        name: '@cf/llava-hf/llava-1.5-7b-hf'
        family: 'llava-1.5-7b-hf'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature, vision]
        open_weights: true
      'lucid-origin':
        name: '@cf/leonardo/lucid-origin'
        family: 'lucid-origin'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 7e-06
        output_cost_per_1k: 7e-06
        capabilities: [image_output]
      'm2m100-1.2b':
        name: '@cf/meta/m2m100-1.2b'
        family: 'm2m100-1.2b'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.00034
        output_cost_per_1k: 0.00034
        open_weights: true
      'melotts':
        name: '@cf/myshell-ai/melotts'
        family: 'melotts'
        mode: audio_speech
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 2e-07
        output_cost_per_1k: 0.0
        capabilities: [audio_output, vision]
        open_weights: true
      'mistral-7b-instruct-v0.1':
        name: '@cf/mistral/mistral-7b-instruct-v0.1'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 2824
        max_output_tokens: 2824
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00019
        capabilities: [function_calling, temperature]
        open_weights: true
      'mistral-7b-instruct-v0.1-awq':
        name: '@hf/thebloke/mistral-7b-instruct-v0.1-awq'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'mistral-7b-instruct-v0.2':
        name: '@hf/mistral/mistral-7b-instruct-v0.2'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 3072
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'mistral-7b-instruct-v0.2-lora':
        name: '@cf/mistral/mistral-7b-instruct-v0.2-lora'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 15000
        max_output_tokens: 15000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'mistral-small-3.1-24b-instruct':
        name: '@cf/mistralai/mistral-small-3.1-24b-instruct'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00056
        capabilities: [function_calling, temperature]
        open_weights: true
      'neural-chat-7b-v3-1-awq':
        name: '@hf/thebloke/neural-chat-7b-v3-1-awq'
        family: 'neural-chat-7b-v3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'nova-3':
        name: '@cf/deepgram/nova-3'
        family: 'nova'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 5.2e-06
        output_cost_per_1k: 5.2e-06
        capabilities: [audio_input]
        open_weights: true
      'openchat-3.5-0106':
        name: '@cf/openchat/openchat-3.5-0106'
        family: 'openchat'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'openhermes-2.5-mistral-7b-awq':
        name: '@hf/thebloke/openhermes-2.5-mistral-7b-awq'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'phi-2':
        name: '@cf/microsoft/phi-2'
        family: 'phi'
        mode: chat
        max_input_tokens: 2048
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'phoenix-1.0':
        name: '@cf/leonardo/phoenix-1.0'
        family: 'phoenix'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 5.8e-06
        output_cost_per_1k: 5.8e-06
        capabilities: [image_output]
      'qwen1.5-0.5b-chat':
        name: '@cf/qwen/qwen1.5-0.5b-chat'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'qwen1.5-1.8b-chat':
        name: '@cf/qwen/qwen1.5-1.8b-chat'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'qwen1.5-14b-chat-awq':
        name: '@cf/qwen/qwen1.5-14b-chat-awq'
        family: 'qwen'
        mode: chat
        max_input_tokens: 7500
        max_output_tokens: 7500
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'qwen1.5-7b-chat-awq':
        name: '@cf/qwen/qwen1.5-7b-chat-awq'
        family: 'qwen'
        mode: chat
        max_input_tokens: 20000
        max_output_tokens: 20000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'qwen2.5-coder-32b-instruct':
        name: '@cf/qwen/qwen2.5-coder-32b-instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.00066
        output_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        open_weights: true
      'qwen3-30b-a3b-fp8':
        name: '@cf/qwen/qwen3-30b-a3b-fp8'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 0
        input_cost_per_1k: 5.1e-05
        output_cost_per_1k: 0.00034
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'qwq-32b':
        name: '@cf/qwen/qwq-32b'
        family: 'qwq'
        mode: chat
        max_input_tokens: 24000
        max_output_tokens: 24000
        input_cost_per_1k: 0.00066
        output_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        open_weights: true
      'resnet-50':
        name: '@cf/microsoft/resnet-50'
        family: 'resnet'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [vision]
        open_weights: true
      'sqlcoder-7b-2':
        name: '@cf/defog/sqlcoder-7b-2'
        family: 'sqlcoder'
        mode: chat
        max_input_tokens: 10000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
      'stable-diffusion-v1-5-img2img':
        name: '@cf/runwayml/stable-diffusion-v1-5-img2img'
        family: 'stable-diffusion'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output]
        open_weights: true
      'stable-diffusion-v1-5-inpainting':
        name: '@cf/runwayml/stable-diffusion-v1-5-inpainting'
        family: 'stable-diffusion'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output]
        open_weights: true
      'stable-diffusion-xl-base-1.0':
        name: '@cf/stabilityai/stable-diffusion-xl-base-1.0'
        family: 'stable-diffusion'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output]
        open_weights: true
      'stable-diffusion-xl-lightning':
        name: '@cf/bytedance/stable-diffusion-xl-lightning'
        family: 'stable-diffusion'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output]
        open_weights: true
      'starling-lm-7b-beta':
        name: '@hf/nexusflow/starling-lm-7b-beta'
        family: 'starling-lm'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'tinyllama-1.1b-chat-v1.0':
        name: '@cf/tinyllama/tinyllama-1.1b-chat-v1.0'
        family: 'llama'
        mode: chat
        max_input_tokens: 2048
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'uform-gen2-qwen-500m':
        name: '@cf/unum/uform-gen2-qwen-500m'
        family: 'qwen'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [vision]
        open_weights: true
      'una-cybertron-7b-v2-bf16':
        name: '@cf/fblgit/una-cybertron-7b-v2-bf16'
        family: 'una-cybertron'
        mode: chat
        max_input_tokens: 15000
        max_output_tokens: 15000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
      'whisper':
        name: '@cf/openai/whisper'
        family: 'whisper'
        mode: audio_transcription
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 4.5e-07
        output_cost_per_1k: 4.5e-07
        capabilities: [audio_input]
        open_weights: true
      'whisper-large-v3-turbo':
        name: '@cf/openai/whisper-large-v3-turbo'
        family: 'whisper-large'
        mode: audio_transcription
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 5.1e-07
        output_cost_per_1k: 5.1e-07
        capabilities: [audio_input]
        open_weights: true
      'whisper-tiny-en':
        name: '@cf/openai/whisper-tiny-en'
        family: 'whisper'
        mode: audio_transcription
        max_input_tokens: 0
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input]
        open_weights: true
      'zephyr-7b-beta-awq':
        name: '@hf/thebloke/zephyr-7b-beta-awq'
        family: 'zephyr'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        open_weights: true
        deprecated: true
  cohere:
    name: 'Cohere'
    api_endpoint: 'https://api.cohere.ai/v1'
    logo_url: 'https://models.dev/logos/cohere.svg'
    model_count: 7
    models:
      'command-a-03-2025':
        name: 'Command A'
        family: 'command-a'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-a-reasoning-08-2025':
        name: 'Command A Reasoning'
        family: 'command-a'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-a-translate-08-2025':
        name: 'Command A Translate'
        family: 'command-a'
        mode: chat
        max_input_tokens: 8000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-a-vision-07-2025':
        name: 'Command A Vision'
        family: 'command-a'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-r-08-2024':
        name: 'Command R'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-r-plus-08-2024':
        name: 'Command R+'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
      'command-r7b-12-2024':
        name: 'Command R7B'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4000
        input_cost_per_1k: 3.75e-05
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06-01'
        open_weights: true
  cortecs:
    name: 'Cortecs'
    api_endpoint: 'https://api.cortecs.ai/v1'
    logo_url: 'https://models.dev/logos/cortecs.svg'
    model_count: 16
    models:
      'claude-4-5-sonnet':
        name: 'Claude 4.5 Sonnet'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 200000
        input_cost_per_1k: 0.003259
        output_cost_per_1k: 0.016296
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003307
        output_cost_per_1k: 0.016536
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2025-03'
      'deepseek-v3-0324':
        name: 'DeepSeek V3 0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.000551
        output_cost_per_1k: 0.001654
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'devstral-2512':
        name: 'Devstral 2 2512'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'devstral-small-2512':
        name: 'Devstral Small 2 2512'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65535
        input_cost_per_1k: 0.001654
        output_cost_per_1k: 0.011024
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
      'gpt-4.1':
        name: 'GPT 4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002354
        output_cost_per_1k: 0.009417
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-06'
      'gpt-oss-120b':
        name: 'GPT Oss 120b'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-01'
        open_weights: true
      'intellect-3':
        name: 'INTELLECT 3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.000219
        output_cost_per_1k: 0.001202
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
        open_weights: true
      'kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.000551
        output_cost_per_1k: 0.002646
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.000656
        output_cost_per_1k: 0.002731
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'llama-3.1-405b-instruct':
        name: 'Llama 3.1 405B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'nova-pro-v1':
        name: 'Nova Pro 1.0'
        family: 'nova-pro'
        mode: chat
        max_input_tokens: 300000
        max_output_tokens: 5000
        input_cost_per_1k: 0.001016
        output_cost_per_1k: 0.004061
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'qwen3-32b':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 9.9e-05
        output_cost_per_1k: 0.00033
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.000441
        output_cost_per_1k: 0.001984
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'qwen3-next-80b-a3b-thinking':
        name: 'Qwen3 Next 80B A3B Thinking'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.000164
        output_cost_per_1k: 0.001311
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  deepinfra:
    name: 'Deep Infra'
    logo_url: 'https://models.dev/logos/deepinfra.svg'
    model_count: 9
    models:
      'MiniMaxAI/MiniMax-M2':
        name: 'MiniMax M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.000254
        output_cost_per_1k: 0.00102
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo':
        name: 'Qwen3 Coder 480B A35B Instruct Turbo'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct':
        name: 'Kimi K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/Kimi-K2-Thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00047
        output_cost_per_1k: 0.002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00024
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00014
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
        deprecated: true
      'zai-org/GLM-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 16384
        input_cost_per_1k: 0.00043
        output_cost_per_1k: 0.00175
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  deepseek:
    name: 'DeepSeek'
    api_endpoint: 'https://api.deepseek.com'
    logo_url: 'https://models.dev/logos/deepseek.svg'
    model_count: 2
    models:
      'deepseek-chat':
        name: 'DeepSeek Chat'
        family: 'deepseek-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 2.8e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-07'
      'deepseek-reasoner':
        name: 'DeepSeek Reasoner'
        family: 'deepseek'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 2.8e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-07'
  fastrouter:
    name: 'FastRouter'
    api_endpoint: 'https://go.fastrouter.ai/api/v1'
    logo_url: 'https://models.dev/logos/fastrouter.svg'
    model_count: 14
    models:
      'anthropic/claude-opus-4.1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'deepseek-ai/deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00014
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01'
      'moonshotai/kimi-k2':
        name: 'Kimi K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 5e-06
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'qwen/qwen3-coder':
        name: 'Qwen3 Coder'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'x-ai/grok-4':
        name: 'Grok 4'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        cache_write_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
  fireworks:
    name: 'Fireworks AI'
    api_endpoint: 'https://api.fireworks.ai/inference/v1/'
    logo_url: 'https://models.dev/logos/fireworks-ai.svg'
    model_count: 16
    models:
      'accounts/fireworks/models/deepseek-r1-0528':
        name: 'Deepseek R1 05/28'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 160000
        max_output_tokens: 16384
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.008
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'accounts/fireworks/models/deepseek-v3-0324':
        name: 'Deepseek V3 03-24'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 160000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'accounts/fireworks/models/deepseek-v3p1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'accounts/fireworks/models/deepseek-v3p2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 160000
        max_output_tokens: 160000
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'accounts/fireworks/models/glm-4p5':
        name: 'GLM 4.5'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'accounts/fireworks/models/glm-4p5-air':
        name: 'GLM 4.5 Air'
        family: 'glm-4-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00088
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'accounts/fireworks/models/glm-4p6':
        name: 'GLM 4.6'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 198000
        max_output_tokens: 198000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'accounts/fireworks/models/glm-4p7':
        name: 'GLM 4.7'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 198000
        max_output_tokens: 198000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'accounts/fireworks/models/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'accounts/fireworks/models/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'accounts/fireworks/models/kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'accounts/fireworks/models/kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'accounts/fireworks/models/minimax-m2':
        name: 'MiniMax-M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 192000
        max_output_tokens: 192000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'accounts/fireworks/models/minimax-m2p1':
        name: 'MiniMax-M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 200000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'accounts/fireworks/models/qwen3-235b-a22b':
        name: 'Qwen3 235B-A22B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00088
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'accounts/fireworks/models/qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, temperature]
        open_weights: true
  friendli:
    name: 'Friendli'
    api_endpoint: 'https://api.friendli.ai/serverless/v1'
    logo_url: 'https://models.dev/logos/friendli.svg'
    model_count: 11
    models:
      'LGAI-EXAONE/EXAONE-4.0.1-32B':
        name: 'EXAONE 4.0.1 32B'
        family: 'exaone'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-30B-A3B':
        name: 'Qwen3 30B A3B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8000
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-32B':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8000
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek R1 0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'meta-llama-3.1-8b-instruct':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta-llama-3.3-70b-instruct':
        name: 'Llama 3.3 70B Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta-llama/Llama-4-Maverick-17B-128E-Instruct':
        name: 'Llama 4 Maverick 17B 128E Instruct'
        family: 'llama-4'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8000
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'meta-llama/Llama-4-Scout-17B-16E-Instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8000
        capabilities: [json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.6':
        name: 'GLM 4.6'
        family: 'glm-4'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
  github_copilot:
    name: 'GitHub Copilot'
    api_endpoint: 'https://api.githubcopilot.com'
    logo_url: 'https://models.dev/logos/github-copilot.svg'
    model_count: 28
    models:
      'claude-3.5-sonnet':
        name: 'Claude Sonnet 3.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 90000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        deprecated: true
      'claude-3.7-sonnet':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
        deprecated: true
      'claude-3.7-sonnet-thought':
        name: 'Claude Sonnet 3.7 Thinking'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-04'
        deprecated: true
      'claude-haiku-4.5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-opus-4':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 80000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2025-03-31'
        deprecated: true
      'claude-opus-4.5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-41':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 80000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4.5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'gemini-2.0-flash-001':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
        deprecated: true
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-flash-preview':
        name: 'Gemini 3 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, json_mode, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, json_mode, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10'
      'gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5-mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-06'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex':
        name: 'GPT-5.1-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-max':
        name: 'GPT-5.1-Codex-max'
        family: 'gpt-5-codex-max'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1-Codex-mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-08'
      'o3':
        name: 'o3 (Preview)'
        family: 'o3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
        deprecated: true
      'o3-mini':
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning]
        knowledge_cutoff: '2024-10'
        deprecated: true
      'o4-mini':
        name: 'o4-mini (Preview)'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning]
        knowledge_cutoff: '2024-10'
        deprecated: true
      'oswe-vscode-prime':
        name: 'Raptor Mini (Preview)'
        family: 'oswe-vscode-prime'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10'
  github_models:
    name: 'GitHub Models'
    api_endpoint: 'https://models.github.ai/inference'
    logo_url: 'https://models.dev/logos/github-models.svg'
    model_count: 55
    models:
      'ai21-labs/ai21-jamba-1.5-large':
        name: 'AI21 Jamba 1.5 Large'
        family: 'jamba-1.5-large'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'ai21-labs/ai21-jamba-1.5-mini':
        name: 'AI21 Jamba 1.5 Mini'
        family: 'jamba-1.5-mini'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'cohere/cohere-command-a':
        name: 'Cohere Command A'
        family: 'command-a'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'cohere/cohere-command-r':
        name: 'Cohere Command R'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'cohere/cohere-command-r-08-2024':
        name: 'Cohere Command R 08-2024'
        family: 'command-r'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'cohere/cohere-command-r-plus':
        name: 'Cohere Command R+'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'cohere/cohere-command-r-plus-08-2024':
        name: 'Cohere Command R+ 08-2024'
        family: 'command-r-plus'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'core42/jais-30b-chat':
        name: 'JAIS 30b Chat'
        family: 'jais'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-03'
        open_weights: true
      'deepseek/deepseek-r1':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'deepseek/deepseek-r1-0528':
        name: 'DeepSeek-R1-0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'deepseek/deepseek-v3-0324':
        name: 'DeepSeek-V3-0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'meta/llama-3.2-11b-vision-instruct':
        name: 'Llama-3.2-11B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.2-90b-vision-instruct':
        name: 'Llama-3.2-90B-Vision-Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.3-70b-instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-4-maverick-17b-128e-instruct-fp8':
        name: 'Llama 4 Maverick 17B 128E Instruct FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'meta/llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'meta/meta-llama-3-70b-instruct':
        name: 'Meta-Llama-3-70B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/meta-llama-3-8b-instruct':
        name: 'Meta-Llama-3-8B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/meta-llama-3.1-405b-instruct':
        name: 'Meta-Llama-3.1-405B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/meta-llama-3.1-70b-instruct':
        name: 'Meta-Llama-3.1-70B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/meta-llama-3.1-8b-instruct':
        name: 'Meta-Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'microsoft/mai-ds-r1':
        name: 'MAI-DS-R1'
        family: 'mai-ds-r1'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
      'microsoft/phi-3-medium-128k-instruct':
        name: 'Phi-3-medium instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-medium-4k-instruct':
        name: 'Phi-3-medium instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-mini-128k-instruct':
        name: 'Phi-3-mini instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-mini-4k-instruct':
        name: 'Phi-3-mini instruct (4k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 4096
        max_output_tokens: 1024
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-small-128k-instruct':
        name: 'Phi-3-small instruct (128k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-small-8k-instruct':
        name: 'Phi-3-small instruct (8k)'
        family: 'phi-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3.5-mini-instruct':
        name: 'Phi-3.5-mini instruct (128k)'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3.5-moe-instruct':
        name: 'Phi-3.5-MoE instruct (128k)'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3.5-vision-instruct':
        name: 'Phi-3.5-vision instruct (128k)'
        family: 'phi-3.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-4':
        name: 'Phi-4'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-4-mini-instruct':
        name: 'Phi-4-mini-instruct'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-4-mini-reasoning':
        name: 'Phi-4-mini-reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-4-multimodal-instruct':
        name: 'Phi-4-multimodal-instruct'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-4-reasoning':
        name: 'Phi-4-Reasoning'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'mistral-ai/codestral-2501':
        name: 'Codestral 25.01'
        family: 'codestral'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'mistral-ai/ministral-3b':
        name: 'Ministral 3B'
        family: 'ministral-3b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
        open_weights: true
      'mistral-ai/mistral-large-2411':
        name: 'Mistral Large 24.11'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-09'
      'mistral-ai/mistral-medium-2505':
        name: 'Mistral Medium 3 (25.05)'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09'
      'mistral-ai/mistral-nemo':
        name: 'Mistral Nemo'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
        open_weights: true
      'mistral-ai/mistral-small-2503':
        name: 'Mistral Small 3.1'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09'
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-mini':
        name: 'GPT-4.1-mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-nano':
        name: 'GPT-4.1-nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2023-10'
      'openai/gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2023-10'
      'openai/o1':
        name: 'OpenAI o1'
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2023-10'
      'openai/o1-mini':
        name: 'OpenAI o1-mini'
        family: 'o1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning]
        knowledge_cutoff: '2023-10'
      'openai/o1-preview':
        name: 'OpenAI o1-preview'
        family: 'o1-preview'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning]
        knowledge_cutoff: '2023-10'
      'openai/o3':
        name: 'OpenAI o3'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2024-04'
      'openai/o3-mini':
        name: 'OpenAI o3-mini'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning]
        knowledge_cutoff: '2024-04'
      'openai/o4-mini':
        name: 'OpenAI o4-mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, vision]
        knowledge_cutoff: '2024-04'
      'xai/grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
      'xai/grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
  google:
    name: 'Google'
    api_endpoint: 'https://generativelanguage.googleapis.com/v1'
    logo_url: 'https://models.dev/logos/google.svg'
    model_count: 26
    models:
      'gemini-1.5-flash':
        name: 'Gemini 1.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 8192
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        cache_read_cost_per_1k: 1.875e-05
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'gemini-1.5-flash-8b':
        name: 'Gemini 1.5 Flash-8B'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 8192
        input_cost_per_1k: 3.75e-05
        output_cost_per_1k: 0.00015
        cache_read_cost_per_1k: 1e-05
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'gemini-1.5-pro':
        name: 'Gemini 1.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0003125
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'gemini-2.0-flash':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'gemini-2.0-flash-lite':
        name: 'Gemini 2.0 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [audio_input, function_calling, json_mode, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-image':
        name: 'Gemini 2.5 Flash Image'
        family: 'gemini-flash-image'
        mode: image
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.03
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [image_output, reasoning, temperature, vision]
        knowledge_cutoff: '2025-06'
      'gemini-2.5-flash-image-preview':
        name: 'Gemini 2.5 Flash Image (Preview)'
        family: 'gemini-flash-image'
        mode: image
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.03
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [image_output, reasoning, temperature, vision]
        knowledge_cutoff: '2025-06'
      'gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-lite-preview-06-17':
        name: 'Gemini 2.5 Flash Lite Preview 06-17'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-lite-preview-09-2025':
        name: 'Gemini 2.5 Flash Lite Preview 09-25'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-04-17':
        name: 'Gemini 2.5 Flash Preview 04-17'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-05-20':
        name: 'Gemini 2.5 Flash Preview 05-20'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-09-2025':
        name: 'Gemini 2.5 Flash Preview 09-25'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-tts':
        name: 'Gemini 2.5 Flash Preview TTS'
        family: 'gemini-flash-tts'
        mode: audio_speech
        max_input_tokens: 8000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.01
        capabilities: [audio_output]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro-preview-05-06':
        name: 'Gemini 2.5 Pro Preview 05-06'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro-preview-06-05':
        name: 'Gemini 2.5 Pro Preview 06-05'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro-preview-tts':
        name: 'Gemini 2.5 Pro Preview TTS'
        family: 'gemini-flash-tts'
        mode: audio_speech
        max_input_tokens: 8000
        max_output_tokens: 16000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.02
        capabilities: [audio_output]
        knowledge_cutoff: '2025-01'
      'gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-embedding-001':
        name: 'Gemini Embedding 001'
        family: 'gemini'
        mode: embedding
        max_input_tokens: 2048
        max_output_tokens: 3072
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2025-05'
      'gemini-flash-latest':
        name: 'Gemini Flash Latest'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-flash-lite-latest':
        name: 'Gemini Flash-Lite Latest'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-live-2.5-flash':
        name: 'Gemini Live 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [audio_input, audio_output, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-live-2.5-flash-preview-native-audio':
        name: 'Gemini Live 2.5 Flash Preview Native Audio'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [audio_input, audio_output, function_calling, reasoning, video_input]
        knowledge_cutoff: '2025-01'
  google_vertex:
    name: 'Vertex'
    api_endpoint: 'https://us-central1-aiplatform.googleapis.com/v1'
    logo_url: 'https://models.dev/logos/google-vertex.svg'
    model_count: 19
    models:
      'gemini-2.0-flash':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'gemini-2.0-flash-lite':
        name: 'Gemini 2.0 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [audio_input, function_calling, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.000383
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-lite-preview-06-17':
        name: 'Gemini 2.5 Flash Lite Preview 06-17'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-lite-preview-09-2025':
        name: 'Gemini 2.5 Flash Lite Preview 09-25'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-04-17':
        name: 'Gemini 2.5 Flash Preview 04-17'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-05-20':
        name: 'Gemini 2.5 Flash Preview 05-20'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-flash-preview-09-2025':
        name: 'Gemini 2.5 Flash Preview 09-25'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.000383
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro-preview-05-06':
        name: 'Gemini 2.5 Pro Preview 05-06'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro-preview-06-05':
        name: 'Gemini 2.5 Pro Preview 06-05'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-embedding-001':
        name: 'Gemini Embedding 001'
        family: 'gemini'
        mode: embedding
        max_input_tokens: 2048
        max_output_tokens: 3072
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2025-05'
      'gemini-flash-latest':
        name: 'Gemini Flash Latest'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.000383
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-flash-lite-latest':
        name: 'Gemini Flash-Lite Latest'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'openai/gpt-oss-120b-maas':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00036
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b-maas':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00025
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
  google_vertex_anthropic:
    name: 'Vertex (Anthropic)'
    logo_url: 'https://models.dev/logos/google-vertex-anthropic.svg'
    model_count: 9
    models:
      'claude-3-5-haiku@20241022':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'claude-3-5-sonnet@20241022':
        name: 'Claude Sonnet 3.5 v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'claude-3-7-sonnet@20250219':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'claude-haiku-4-5@20251001':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-opus-4-1@20250805':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5@20251101':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4@20250514':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-5@20250929':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'claude-sonnet-4@20250514':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
  groq:
    name: 'Groq'
    api_endpoint: 'https://api.groq.com/openai/v1'
    logo_url: 'https://models.dev/logos/groq.svg'
    model_count: 17
    models:
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00075
        output_cost_per_1k: 0.00099
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
        deprecated: true
      'gemma2-9b-it':
        name: 'Gemma 2 9B'
        family: 'gemma-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
        deprecated: true
      'llama-3.1-8b-instant':
        name: 'Llama 3.1 8B Instant'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-70b-versatile':
        name: 'Llama 3.3 70B Versatile'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-guard-3-8b':
        name: 'Llama Guard 3 8B'
        family: 'llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [temperature]
        open_weights: true
        deprecated: true
      'llama3-70b-8192':
        name: 'Llama 3 70B'
        family: 'llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-03'
        open_weights: true
        deprecated: true
      'llama3-8b-8192':
        name: 'Llama 3 8B'
        family: 'llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-03'
        open_weights: true
        deprecated: true
      'meta-llama/llama-4-maverick-17b-128e-instruct':
        name: 'Llama 4 Maverick 17B'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'meta-llama/llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17B'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00034
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'meta-llama/llama-guard-4-12b':
        name: 'Llama Guard 4 12B'
        family: 'llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 1024
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [temperature, vision]
        open_weights: true
      'mistral-saba-24b':
        name: 'Mistral Saba 24B'
        family: 'mistral'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.00079
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
        deprecated: true
      'moonshotai/kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
        deprecated: true
      'moonshotai/kimi-k2-instruct-0905':
        name: 'Kimi K2 Instruct 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'qwen-qwq-32b':
        name: 'Qwen QwQ 32B'
        family: 'qwq'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00039
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-09'
        open_weights: true
        deprecated: true
      'qwen/qwen3-32b':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11-08'
        open_weights: true
  helicone:
    name: 'Helicone'
    api_endpoint: 'https://ai-gateway.helicone.ai/v1'
    logo_url: 'https://models.dev/logos/helicone.svg'
    model_count: 91
    models:
      'chatgpt-4o-latest':
        name: 'OpenAI ChatGPT-4o'
        family: 'chatgpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.02
        cache_read_cost_per_1k: 0.0025
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
      'claude-3-haiku-20240307':
        name: 'Anthropic: Claude 3 Haiku'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-03'
      'claude-3.5-haiku':
        name: 'Anthropic: Claude 3.5 Haiku'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'claude-3.5-sonnet-v2':
        name: 'Anthropic: Claude 3.5 Sonnet v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'claude-3.7-sonnet':
        name: 'Anthropic: Claude 3.7 Sonnet'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-02'
      'claude-4.5-haiku':
        name: 'Anthropic: Claude 4.5 Haiku'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-10'
      'claude-4.5-opus':
        name: 'Anthropic: Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'claude-4.5-sonnet':
        name: 'Anthropic: Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-09'
      'claude-haiku-4-5-20251001':
        name: 'Anthropic: Claude 4.5 Haiku (20251001)'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-10'
      'claude-opus-4':
        name: 'Anthropic: Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-05'
      'claude-opus-4-1':
        name: 'Anthropic: Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-08'
      'claude-opus-4-1-20250805':
        name: 'Anthropic: Claude Opus 4.1 (20250805)'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-08'
      'claude-sonnet-4':
        name: 'Anthropic: Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-05'
      'claude-sonnet-4-5-20250929':
        name: 'Anthropic: Claude Sonnet 4.5 (20250929)'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-09'
      'codex-mini-latest':
        name: 'OpenAI Codex Mini Latest'
        family: 'codex'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.000375
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2025-01'
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
      'deepseek-reasoner':
        name: 'DeepSeek Reasoner'
        family: 'deepseek'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        cache_read_cost_per_1k: 7e-05
        capabilities: [temperature]
        knowledge_cutoff: '2025-01'
      'deepseek-tng-r1t2-chimera':
        name: 'DeepSeek TNG R1T2 Chimera'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 130000
        max_output_tokens: 163840
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-07'
      'deepseek-v3':
        name: 'DeepSeek V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        cache_read_cost_per_1k: 7e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'deepseek-v3.1-terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        cache_read_cost_per_1k: 0.000216
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
      'deepseek-v3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00041
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-09'
      'ernie-4.5-21b-a3b-thinking':
        name: 'Baidu Ernie 4.5 21B A3B Thinking'
        family: 'ernie-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-03'
      'gemini-2.5-flash':
        name: 'Google Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65535
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-06'
      'gemini-2.5-flash-lite':
        name: 'Google Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65535
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        cache_write_cost_per_1k: 0.0001
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'gemini-2.5-pro':
        name: 'Google Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.0003125
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-06'
      'gemini-3-pro-preview':
        name: 'Google Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        capabilities: [audio_input, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-11'
      'gemma-3-12b-it':
        name: 'Google Gemma 3 12B'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0001
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-12'
      'gemma2-9b-it':
        name: 'Google Gemma 2'
        family: 'gemma-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 3e-05
        capabilities: [temperature]
        knowledge_cutoff: '2024-06'
      'glm-4.6':
        name: 'Zai GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'gpt-4.1':
        name: 'OpenAI GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-04'
      'gpt-4.1-mini':
        name: 'OpenAI GPT-4.1 Mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-04'
      'gpt-4.1-mini-2025-04-14':
        name: 'OpenAI GPT-4.1 Mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-04'
      'gpt-4.1-nano':
        name: 'OpenAI GPT-4.1 Nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-04'
      'gpt-4o':
        name: 'OpenAI GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-05'
      'gpt-4o-mini':
        name: 'OpenAI GPT-4o-mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-07'
      'gpt-5':
        name: 'OpenAI GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5-chat-latest':
        name: 'OpenAI GPT-5 Chat Latest'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2024-09'
      'gpt-5-codex':
        name: 'OpenAI: GPT-5 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling]
        knowledge_cutoff: '2025-01'
      'gpt-5-mini':
        name: 'OpenAI GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5-nano':
        name: 'OpenAI GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 5e-06
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5-pro':
        name: 'OpenAI: GPT-5 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.12
        knowledge_cutoff: '2025-01'
      'gpt-5.1':
        name: 'OpenAI GPT-5.1'
        family: 'gpt-5'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, image_output, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5.1-chat-latest':
        name: 'OpenAI GPT-5.1 Chat'
        family: 'gpt-5-chat'
        mode: image
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, image_output, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5.1-codex':
        name: 'OpenAI: GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, image_output, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5.1-codex-mini':
        name: 'OpenAI: GPT-5.1 Codex Mini'
        family: 'gpt-5-codex-mini'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, image_output, vision]
        knowledge_cutoff: '2025-01'
      'gpt-oss-120b':
        name: 'OpenAI GPT-OSS 120b'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00016
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
      'gpt-oss-20b':
        name: 'OpenAI GPT-OSS 20b'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-06'
      'grok-3':
        name: 'xAI Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06'
      'grok-3-mini':
        name: 'xAI Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06'
      'grok-4':
        name: 'xAI Grok 4'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
      'grok-4-1-fast-non-reasoning':
        name: 'xAI Grok 4.1 Fast Non-Reasoning'
        family: 'grok'
        mode: image
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, image_output, temperature, vision]
        knowledge_cutoff: '2025-11'
      'grok-4-1-fast-reasoning':
        name: 'xAI Grok 4.1 Fast Reasoning'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 2000000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'grok-4-fast-non-reasoning':
        name: 'xAI Grok 4 Fast Non-Reasoning'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 2000000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2025-09'
      'grok-4-fast-reasoning':
        name: 'xAI: Grok 4 Fast Reasoning'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 2000000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-09'
      'grok-code-fast-1':
        name: 'xAI Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'hermes-2-pro-llama-3-8b':
        name: 'Hermes 2 Pro Llama 3 8B'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00014
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-05'
      'kimi-k2-0711':
        name: 'Kimi K2 (07/11)'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.00057
        output_cost_per_1k: 0.0023
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01'
      'kimi-k2-0905':
        name: 'Kimi K2 (09/05)'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 0.0004
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-09'
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 262144
        input_cost_per_1k: 0.00048
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-11'
      'llama-3.1-8b-instant':
        name: 'Meta Llama 3.1 8B Instant'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32678
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
      'llama-3.1-8b-instruct':
        name: 'Meta Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 16384
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
      'llama-3.1-8b-instruct-turbo':
        name: 'Meta Llama 3.1 8B Instruct Turbo'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 3e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
      'llama-3.3-70b-instruct':
        name: 'Meta Llama 3.3 70B Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16400
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00039
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'llama-3.3-70b-versatile':
        name: 'Meta Llama 3.3 70B Versatile'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32678
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00079
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'llama-4-maverick':
        name: 'Meta Llama 4 Maverick 17B 128E'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
      'llama-4-scout':
        name: 'Meta Llama 4 Scout 17B 16E'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
      'llama-guard-4':
        name: 'Meta Llama Guard 4 12B'
        family: 'llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 1024
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.00021
        capabilities: [temperature, vision]
        knowledge_cutoff: '2025-01'
      'llama-prompt-guard-2-22m':
        name: 'Meta Llama Prompt Guard 2 22M'
        family: 'llama'
        mode: chat
        max_input_tokens: 512
        max_output_tokens: 2
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 1e-05
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
      'llama-prompt-guard-2-86m':
        name: 'Meta Llama Prompt Guard 2 86M'
        family: 'llama'
        mode: chat
        max_input_tokens: 512
        max_output_tokens: 2
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 1e-05
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
      'mistral-large-2411':
        name: 'Mistral-Large'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
      'mistral-nemo':
        name: 'Mistral Nemo'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16400
        input_cost_per_1k: 0.02
        output_cost_per_1k: 0.04
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-07'
      'mistral-small':
        name: 'Mistral Small'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.075
        output_cost_per_1k: 0.2
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-02'
      'o1':
        name: 'OpenAI: o1'
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        knowledge_cutoff: '2025-01'
      'o1-mini':
        name: 'OpenAI: o1-mini'
        family: 'o1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        knowledge_cutoff: '2025-01'
      'o3':
        name: 'OpenAI o3'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2024-06'
      'o3-mini':
        name: 'OpenAI o3 Mini'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling]
        knowledge_cutoff: '2023-10'
      'o3-pro':
        name: 'OpenAI o3 Pro'
        family: 'o3-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.02
        output_cost_per_1k: 0.08
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2024-06'
      'o4-mini':
        name: 'OpenAI o4 Mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.000275
        capabilities: [function_calling, vision]
        knowledge_cutoff: '2024-06'
      'qwen2.5-coder-7b-fast':
        name: 'Qwen2.5 Coder 7B fast'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 8192
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 9e-05
        capabilities: [temperature]
        knowledge_cutoff: '2024-09'
      'qwen3-235b-a22b-thinking':
        name: 'Qwen3 235B A22B Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 81920
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0029
        capabilities: [reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-07'
      'qwen3-30b-a3b':
        name: 'Qwen3 30B A3B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 41000
        max_output_tokens: 41000
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00029
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-06'
      'qwen3-32b':
        name: 'Qwen3 32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 40960
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
      'qwen3-coder':
        name: 'Qwen3 Coder 480B A35B Instruct Turbo'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00095
        capabilities: [audio_input, function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-07'
      'qwen3-coder-30b-a3b-instruct':
        name: 'Qwen3 Coder 30B A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-07'
      'qwen3-next-80b-a3b-instruct':
        name: 'Qwen3 Next 80B A3B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'qwen3-vl-235b-a22b-instruct':
        name: 'Qwen3 VL 235B A22B Instruct'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-09'
      'sonar':
        name: 'Perplexity Sonar'
        family: 'sonar'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 4096
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.001
        capabilities: [temperature]
        knowledge_cutoff: '2025-01'
      'sonar-deep-research':
        name: 'Perplexity Sonar Deep Research'
        family: 'sonar-deep-research'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-01'
      'sonar-pro':
        name: 'Perplexity Sonar Pro'
        family: 'sonar-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [temperature]
        knowledge_cutoff: '2025-01'
      'sonar-reasoning':
        name: 'Perplexity Sonar Reasoning'
        family: 'sonar-reasoning'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 4096
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-01'
      'sonar-reasoning-pro':
        name: 'Perplexity Sonar Reasoning Pro'
        family: 'sonar-reasoning'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-01'
  huggingface:
    name: 'Hugging Face'
    api_endpoint: 'https://router.huggingface.co/v1'
    logo_url: 'https://models.dev/logos/huggingface.svg'
    model_count: 14
    models:
      'MiniMaxAI/MiniMax-M2.1':
        name: 'MiniMax-M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-10'
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3-235B-A22B-Thinking-2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        name: 'Qwen3-Coder-480B-A35B-Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Embedding-4B':
        name: 'Qwen 3 Embedding 4B'
        family: 'qwen3'
        mode: embedding
        max_input_tokens: 32000
        max_output_tokens: 2048
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2024-12'
        open_weights: true
      'Qwen/Qwen3-Embedding-8B':
        name: 'Qwen 3 Embedding 8B'
        family: 'qwen3'
        mode: embedding
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2024-12'
        open_weights: true
      'Qwen/Qwen3-Next-80B-A3B-Instruct':
        name: 'Qwen3-Next-80B-A3B-Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Next-80B-A3B-Thinking':
        name: 'Qwen3-Next-80B-A3B-Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'XiaomiMiMo/MiMo-V2-Flash':
        name: 'MiMo-V2-Flash'
        family: 'mimo'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 4096
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek-R1-0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.005
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'deepseek-ai/DeepSeek-V3.2':
        name: 'DeepSeek-V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct':
        name: 'Kimi-K2-Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct-0905':
        name: 'Kimi-K2-Instruct-0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/Kimi-K2-Thinking':
        name: 'Kimi-K2-Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'zai-org/GLM-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  iflowcn:
    name: 'iFlow'
    api_endpoint: 'https://apis.iflow.cn/v1'
    logo_url: 'https://models.dev/logos/iflowcn.svg'
    model_count: 20
    models:
      'deepseek-r1':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'deepseek-v3':
        name: 'DeepSeek-V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek-v3.1':
        name: 'DeepSeek-V3.1-Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'deepseek-v3.2':
        name: 'DeepSeek-V3.2-Exp'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'deepseek-v3.2-chat':
        name: 'DeepSeek-V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-11'
        open_weights: true
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
      'kimi-k2':
        name: 'Kimi-K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
      'kimi-k2-0905':
        name: 'Kimi-K2-0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'kimi-k2-thinking':
        name: 'Kimi-K2-Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-11'
        open_weights: true
      'minimax-m2':
        name: 'MiniMax-M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131100
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'qwen3-235b':
        name: 'Qwen3-235B-A22B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'qwen3-235b-a22b-instruct':
        name: 'Qwen3-235B-A22B-Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-235b-a22b-thinking-2507':
        name: 'Qwen3-235B-A22B-Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-32b':
        name: 'Qwen3-32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'qwen3-coder':
        name: 'Qwen3-Coder-480B-A35B'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-coder-plus':
        name: 'Qwen3-Coder-Plus'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen3-max':
        name: 'Qwen3-Max'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'qwen3-max-preview':
        name: 'Qwen3-Max-Preview'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'qwen3-vl-plus':
        name: 'Qwen3-VL-Plus'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-12'
      'tstars2.0':
        name: 'TStars-2.0'
        family: 'tstars2.0'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-01'
  inception:
    name: 'Inception'
    api_endpoint: 'https://api.inceptionlabs.ai/v1/'
    logo_url: 'https://models.dev/logos/inception.svg'
    model_count: 2
    models:
      'mercury':
        name: 'Mercury'
        family: 'mercury'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        cache_read_cost_per_1k: 0.00025
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-10'
      'mercury-coder':
        name: 'Mercury Coder'
        family: 'mercury-coder'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        cache_read_cost_per_1k: 0.00025
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-10'
  inference:
    name: 'Inference'
    api_endpoint: 'https://inference.net/v1'
    logo_url: 'https://models.dev/logos/inference.svg'
    model_count: 9
    models:
      'google/gemma-3':
        name: 'Google Gemma 3'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 125000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'meta/llama-3.1-8b-instruct':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 2.5e-05
        output_cost_per_1k: 2.5e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.2-11b-vision-instruct':
        name: 'Llama 3.2 11B Vision Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 5.5e-05
        output_cost_per_1k: 5.5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.2-1b-instruct':
        name: 'Llama 3.2 1B Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 1e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.2-3b-instruct':
        name: 'Llama 3.2 3B Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 2e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'mistral/mistral-nemo-12b-instruct':
        name: 'Mistral Nemo 12B Instruct'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 3.8e-05
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'osmosis/osmosis-structure-0.6b':
        name: 'Osmosis Structure 0.6B'
        family: 'osmosis-structure-0.6b'
        mode: chat
        max_input_tokens: 4000
        max_output_tokens: 2048
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'qwen/qwen-2.5-7b-vision-instruct':
        name: 'Qwen 2.5 7B Vision Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 125000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'qwen/qwen3-embedding-4b':
        name: 'Qwen 3 Embedding 4B'
        family: 'qwen3'
        mode: embedding
        max_input_tokens: 32000
        max_output_tokens: 2048
        input_cost_per_1k: 1e-05
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2024-12'
        open_weights: true
  io_net:
    name: 'IO.NET'
    api_endpoint: 'https://api.intelligence.io.solutions/api/v1'
    logo_url: 'https://models.dev/logos/io-net.svg'
    model_count: 17
    models:
      'Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar':
        name: 'Qwen 3 Coder 480B'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 106000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00095
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.00044
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'Qwen/Qwen2.5-VL-32B-Instruct':
        name: 'Qwen 2.5 VL 32B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 2.5e-05
        cache_write_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen 3 235B Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 4096
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 5.5e-05
        cache_write_cost_per_1k: 0.00022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'Qwen/Qwen3-Next-80B-A3B-Instruct':
        name: 'Qwen 3 Next 80B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 4096
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0008
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.00875
        cache_read_cost_per_1k: 0.001
        cache_write_cost_per_1k: 0.004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'meta-llama/Llama-3.2-90B-Vision-Instruct':
        name: 'Llama 3.2 90B Vision Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 0.000175
        cache_write_cost_per_1k: 0.0007
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/Llama-3.3-70B-Instruct':
        name: 'Llama 3.3 70B Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.00038
        cache_read_cost_per_1k: 6.5e-05
        cache_write_cost_per_1k: 0.00026
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8':
        name: 'Llama 4 Maverick 17B 128E Instruct'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 430000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'mistralai/Devstral-Small-2505':
        name: 'Devstral Small 2505'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00022
        cache_read_cost_per_1k: 2.5e-05
        cache_write_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'mistralai/Magistral-Small-2506':
        name: 'Magistral Small 2506'
        family: 'magistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 0.00025
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01'
      'mistralai/Mistral-Large-Instruct-2411':
        name: 'Mistral Large Instruct 2411'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.001
        cache_write_cost_per_1k: 0.004
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'mistralai/Mistral-Nemo-Instruct-2407':
        name: 'Mistral Nemo Instruct 2407'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 4e-05
        cache_read_cost_per_1k: 1e-05
        cache_write_cost_per_1k: 4e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-05'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct-0905':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 4096
        input_cost_per_1k: 0.00039
        output_cost_per_1k: 0.0019
        cache_read_cost_per_1k: 0.000195
        cache_write_cost_per_1k: 0.00078
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'moonshotai/Kimi-K2-Thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 4096
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00225
        cache_read_cost_per_1k: 0.000275
        cache_write_cost_per_1k: 0.0011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
      'openai/gpt-oss-120b':
        name: 'GPT-OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 4096
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2e-05
        cache_write_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT-OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 4096
        input_cost_per_1k: 3e-05
        output_cost_per_1k: 0.00014
        cache_read_cost_per_1k: 1.5e-05
        cache_write_cost_per_1k: 6e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'zai-org/GLM-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.00175
        cache_read_cost_per_1k: 0.0002
        cache_write_cost_per_1k: 0.0008
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
  kimi_for_coding:
    name: 'Kimi For Coding'
    api_endpoint: 'https://api.kimi.com/coding/v1'
    logo_url: 'https://models.dev/logos/kimi-for-coding.svg'
    model_count: 1
    models:
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
  llama:
    name: 'Llama'
    api_endpoint: 'https://api.llama.com/compat/v1/'
    logo_url: 'https://models.dev/logos/llama.svg'
    model_count: 7
    models:
      'cerebras-llama-4-maverick-17b-128e-instruct':
        name: 'Cerebras-Llama-4-Maverick-17B-128E-Instruct'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'cerebras-llama-4-scout-17b-16e-instruct':
        name: 'Cerebras-Llama-4-Scout-17B-16E-Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'groq-llama-4-maverick-17b-128e-instruct':
        name: 'Groq-Llama-4-Maverick-17B-128E-Instruct'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'llama-3.3-70b-instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-8b-instruct':
        name: 'Llama-3.3-8B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-4-maverick-17b-128e-instruct-fp8':
        name: 'Llama-4-Maverick-17B-128E-Instruct-FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'llama-4-scout-17b-16e-instruct-fp8':
        name: 'Llama-4-Scout-17B-16E-Instruct-FP8'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
  lmstudio:
    name: 'LMStudio'
    api_endpoint: 'http://127.0.0.1:1234/v1'
    logo_url: 'https://models.dev/logos/lmstudio.svg'
    model_count: 3
    models:
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'qwen/qwen3-30b-a3b-2507':
        name: 'Qwen3 30B A3B 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-coder-30b':
        name: 'Qwen3 Coder 30B'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  lucidquery:
    name: 'LucidQuery AI'
    api_endpoint: 'https://lucidquery.com/api/v1'
    logo_url: 'https://models.dev/logos/lucidquery.svg'
    model_count: 2
    models:
      'lucidnova-rf1-100b':
        name: 'LucidNova RF1 100B'
        family: 'nova'
        mode: chat
        max_input_tokens: 120000
        max_output_tokens: 8000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.005
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-09-16'
      'lucidquery-nexus-coder':
        name: 'LucidQuery Nexus Coder'
        family: 'lucidquery-nexus-coder'
        mode: chat
        max_input_tokens: 250000
        max_output_tokens: 60000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.005
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-01'
  minimax:
    name: 'MiniMax'
    api_endpoint: 'https://api.minimax.io/anthropic/v1'
    logo_url: 'https://models.dev/logos/minimax.svg'
    model_count: 2
    models:
      'MiniMax-M2':
        family: 'minimax'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 128000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'MiniMax-M2.1':
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
  minimax_cn:
    name: 'MiniMax (China)'
    api_endpoint: 'https://api.minimaxi.com/anthropic/v1'
    logo_url: 'https://models.dev/logos/minimax-cn.svg'
    model_count: 2
    models:
      'MiniMax-M2':
        family: 'minimax'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 128000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'MiniMax-M2.1':
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
  mistral:
    name: 'Mistral'
    api_endpoint: 'https://api.mistral.ai/v1'
    logo_url: 'https://models.dev/logos/mistral.svg'
    model_count: 26
    models:
      'codestral-latest':
        name: 'Codestral'
        family: 'codestral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'devstral-2512':
        name: 'Devstral 2'
        family: 'devstral-medium'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'devstral-medium-2507':
        name: 'Devstral Medium'
        family: 'devstral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'devstral-medium-latest':
        name: 'Devstral 2'
        family: 'devstral-medium'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'devstral-small-2505':
        name: 'Devstral Small 2505'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'devstral-small-2507':
        name: 'Devstral Small'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'labs-devstral-small-2512':
        name: 'Devstral Small 2'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'magistral-medium-latest':
        name: 'Magistral Medium'
        family: 'magistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.005
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'magistral-small':
        name: 'Magistral Small'
        family: 'magistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'ministral-3b-latest':
        name: 'Ministral 3B'
        family: 'ministral-3b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 4e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'ministral-8b-latest':
        name: 'Ministral 8B'
        family: 'ministral-8b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistral-embed':
        name: 'Mistral Embed'
        family: 'mistral-embed'
        mode: embedding
        max_input_tokens: 8000
        max_output_tokens: 3072
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
      'mistral-large-2411':
        name: 'Mistral Large 2.1'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'mistral-large-2512':
        name: 'Mistral Large 3'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'mistral-large-latest':
        name: 'Mistral Large'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'mistral-medium-2505':
        name: 'Mistral Medium 3'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistral-medium-2508':
        name: 'Mistral Medium 3.1'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistral-medium-latest':
        name: 'Mistral Medium'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistral-nemo':
        name: 'Mistral Nemo'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'mistral-small-2506':
        name: 'Mistral Small 3.2'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'mistral-small-latest':
        name: 'Mistral Small'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'open-mistral-7b':
        name: 'Mistral 7B'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 8000
        max_output_tokens: 8000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00025
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'open-mixtral-8x22b':
        name: 'Mixtral 8x22B'
        family: 'mixtral-8x22b'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 64000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'open-mixtral-8x7b':
        name: 'Mixtral 8x7B'
        family: 'mixtral-8x7b'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0007
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-01'
        open_weights: true
      'pixtral-12b':
        name: 'Pixtral 12B'
        family: 'pixtral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'pixtral-large-latest':
        name: 'Pixtral Large'
        family: 'pixtral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-11'
        open_weights: true
  modelscope:
    name: 'ModelScope'
    api_endpoint: 'https://api-inference.modelscope.cn/v1'
    logo_url: 'https://models.dev/logos/modelscope.svg'
    model_count: 7
    models:
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3-235B-A22B-Thinking-2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-30B-A3B-Instruct-2507':
        name: 'Qwen3 30B A3B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-30B-A3B-Thinking-2507':
        name: 'Qwen3 30B A3B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Coder-30B-A3B-Instruct':
        name: 'Qwen3 Coder 30B A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'ZhipuAI/GLM-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'ZhipuAI/GLM-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
  moonshotai:
    name: 'Moonshot AI'
    api_endpoint: 'https://api.moonshot.ai/v1'
    logo_url: 'https://models.dev/logos/moonshotai.svg'
    model_count: 5
    models:
      'kimi-k2-0711-preview':
        name: 'Kimi K2 0711'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-0905-preview':
        name: 'Kimi K2 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'kimi-k2-thinking-turbo':
        name: 'Kimi K2 Thinking Turbo'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00115
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'kimi-k2-turbo-preview':
        name: 'Kimi K2 Turbo'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0024
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
  moonshotai_cn:
    name: 'Moonshot AI (China)'
    api_endpoint: 'https://api.moonshot.cn/v1'
    logo_url: 'https://models.dev/logos/moonshotai-cn.svg'
    model_count: 5
    models:
      'kimi-k2-0711-preview':
        name: 'Kimi K2 0711'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-0905-preview':
        name: 'Kimi K2 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'kimi-k2-thinking-turbo':
        name: 'Kimi K2 Thinking Turbo'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00115
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'kimi-k2-turbo-preview':
        name: 'Kimi K2 Turbo'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0024
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
  morph:
    name: 'Morph'
    api_endpoint: 'https://api.morphllm.com/v1'
    logo_url: 'https://models.dev/logos/morph.svg'
    model_count: 3
    models:
      'auto':
        name: 'Auto'
        family: 'auto'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00085
        output_cost_per_1k: 0.00155
      'morph-v3-fast':
        name: 'Morph v3 Fast'
        family: 'morph-v3-fast'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0012
      'morph-v3-large':
        name: 'Morph v3 Large'
        family: 'morph-v3-large'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0019
  nano_gpt:
    name: 'NanoGPT'
    api_endpoint: 'https://nano-gpt.com/api/v1'
    logo_url: 'https://models.dev/logos/nano-gpt.svg'
    model_count: 21
    models:
      'deepseek/deepseek-r1':
        name: 'Deepseek R1'
        family: 'deepseek'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek/deepseek-v3.2:thinking':
        name: 'Deepseek V3.2 Thinking'
        family: 'deepseek'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'meta-llama/llama-3.3-70b-instruct':
        name: 'Llama 3.3 70b Instruct'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/llama-4-maverick':
        name: 'Llama 4 Maverick'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'minimax/minimax-m2.1':
        name: 'Minimax M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'mistralai/devstral-2-123b-instruct-2512':
        name: 'Devstral 2 123b Instruct 2512'
        family: 'mistral'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistralai/ministral-14b-instruct-2512':
        name: 'Ministral 14b Instruct 2512'
        family: 'mistral'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'mistralai/mistral-large-3-675b-instruct-2512':
        name: 'Mistral Large 3 675b Instruct 2512'
        family: 'mistral'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'moonshotai/kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-10'
      'moonshotai/kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2024-08'
      'nousresearch/hermes-4-405b:thinking':
        name: 'Hermes 4 405b Thinking'
        family: 'hermes'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'nvidia/llama-3_3-nemotron-super-49b-v1_5':
        name: 'Llama 3 3 Nemotron Super 49B V1 5'
        family: 'llama'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'openai/gpt-oss-120b':
        name: 'GPT Oss 120b'
        family: 'gpt'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-10'
      'qwen/qwen3-235b-a22b-thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'qwen/qwen3-coder':
        name: 'Qwen3 Coder'
        family: 'qwen'
        mode: chat
        max_input_tokens: 106000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'z-ai/glm-4.6':
        name: 'GLM 4.6'
        family: 'glm'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'z-ai/glm-4.6:thinking':
        name: 'GLM 4.6 Thinking'
        family: 'glm'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/glm-4.5-air':
        name: 'GLM 4.5 Air'
        family: 'glm'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'zai-org/glm-4.5-air:thinking':
        name: 'GLM 4.5 Air Thinking'
        family: 'glm'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'zai-org/glm-4.7':
        name: 'GLM 4.7'
        family: 'glm'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'zai-org/glm-4.7:thinking':
        name: 'GLM 4.7 Thinking'
        family: 'glm'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
  nebius:
    name: 'Nebius Token Factory'
    api_endpoint: 'https://api.tokenfactory.nebius.com/v1'
    logo_url: 'https://models.dev/logos/nebius.svg'
    model_count: 15
    models:
      'NousResearch/hermes-4-405b':
        name: 'Hermes-4 405B'
        family: 'hermes'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'NousResearch/hermes-4-70b':
        name: 'Hermes 4 70B'
        family: 'hermes'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'deepseek-ai/deepseek-v3':
        name: 'DeepSeek V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
      'meta-llama/llama-3.3-70b-instruct-base':
        name: 'Llama-3.3-70B-Instruct (Base)'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
      'meta-llama/llama-3.3-70b-instruct-fast':
        name: 'Llama-3.3-70B-Instruct (Fast)'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
      'meta-llama/llama-3_1-405b-instruct':
        name: 'Llama 3.1 405B Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-03'
      'moonshotai/kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0024
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-01'
      'nvidia/llama-3_1-nemotron-ultra-253b-v1':
        name: 'Llama 3.1 Nemotron Ultra 253B v1'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-01'
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-01'
      'qwen/qwen3-235b-a22b-instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'qwen/qwen3-235b-a22b-thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'qwen/qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'zai-org/glm-4.5':
        name: 'GLM 4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-05'
      'zai-org/glm-4.5-air':
        name: 'GLM 4.5 Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-05'
  nvidia:
    name: 'Nvidia'
    api_endpoint: 'https://integrate.api.nvidia.com/v1'
    logo_url: 'https://models.dev/logos/nvidia.svg'
    model_count: 66
    models:
      'black-forest-labs/flux.1-dev':
        name: 'FLUX.1-dev'
        family: 'flux'
        mode: image
        max_input_tokens: 4096
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [image_output, temperature]
        knowledge_cutoff: '2024-08'
      'deepseek-ai/deepseek-coder-6.7b-instruct':
        name: 'Deepseek Coder 6.7b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'deepseek-ai/deepseek-r1':
        name: 'Deepseek R1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        open_weights: true
      'deepseek-ai/deepseek-r1-0528':
        name: 'Deepseek R1 0528'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'deepseek-ai/deepseek-v3.1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'deepseek-ai/deepseek-v3.1-terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
      'google/codegemma-1.1-7b':
        name: 'Codegemma 1.1 7b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'google/codegemma-7b':
        name: 'Codegemma 7b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'google/gemma-2-27b-it':
        name: 'Gemma 2 27b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'google/gemma-2-2b-it':
        name: 'Gemma 2 2b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'google/gemma-3-12b-it':
        name: 'Gemma 3 12b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'google/gemma-3-1b-it':
        name: 'Gemma 3 1b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'google/gemma-3-27b-it':
        name: 'Gemma-3-27B-IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
      'google/gemma-3n-e2b-it':
        name: 'Gemma 3n E2b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'google/gemma-3n-e4b-it':
        name: 'Gemma 3n E4b It'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'meta/codellama-70b':
        name: 'Codellama 70b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'meta/llama-3.1-405b-instruct':
        name: 'Llama 3.1 405b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta/llama-3.1-70b-instruct':
        name: 'Llama 3.1 70b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta/llama-3.2-11b-vision-instruct':
        name: 'Llama 3.2 11b Vision Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.2-1b-instruct':
        name: 'Llama 3.2 1b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-3.3-70b-instruct':
        name: 'Llama 3.3 70b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta/llama-4-maverick-17b-128e-instruct':
        name: 'Llama 4 Maverick 17b 128e Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-02'
        open_weights: true
      'meta/llama-4-scout-17b-16e-instruct':
        name: 'Llama 4 Scout 17b 16e Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-02'
        open_weights: true
      'meta/llama3-70b-instruct':
        name: 'Llama3 70b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'meta/llama3-8b-instruct':
        name: 'Llama3 8b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'microsoft/phi-3-medium-128k-instruct':
        name: 'Phi 3 Medium 128k Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-medium-4k-instruct':
        name: 'Phi 3 Medium 4k Instruct'
        mode: chat
        max_input_tokens: 4000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-small-128k-instruct':
        name: 'Phi 3 Small 128k Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-small-8k-instruct':
        name: 'Phi 3 Small 8k Instruct'
        mode: chat
        max_input_tokens: 8000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'microsoft/phi-3-vision-128k-instruct':
        name: 'Phi 3 Vision 128k Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'microsoft/phi-3.5-moe-instruct':
        name: 'Phi 3.5 Moe Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'microsoft/phi-3.5-vision-instruct':
        name: 'Phi 3.5 Vision Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'microsoft/phi-4-mini-instruct':
        name: 'Phi-4-Mini'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
      'minimaxai/minimax-m2':
        name: 'MiniMax-M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'mistralai/codestral-22b-instruct-v0.1':
        name: 'Codestral 22b Instruct V0.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistralai/devstral-2-123b-instruct-2512':
        name: 'Devstral-2-123B-Instruct-2512'
        family: 'devstral'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'mistralai/mamba-codestral-7b-v0.1':
        name: 'Mamba Codestral 7b V0.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        open_weights: true
      'mistralai/ministral-14b-instruct-2512':
        name: 'Ministral 3 14B Instruct 2512'
        family: 'ministral'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'mistralai/mistral-large-2-instruct':
        name: 'Mistral Large 2 Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistralai/mistral-large-3-675b-instruct-2512':
        name: 'Mistral Large 3 675B Instruct 2512'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'mistralai/mistral-small-3.1-24b-instruct-2503':
        name: 'Mistral Small 3.1 24b Instruct 2503'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'moonshotai/kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-01'
      'moonshotai/kimi-k2-instruct-0905':
        name: 'Kimi K2 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'nvidia/cosmos-nemotron-34b':
        name: 'Cosmos Nemotron 34B'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2024-01'
      'nvidia/llama-3.1-nemotron-51b-instruct':
        name: 'Llama 3.1 Nemotron 51b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'nvidia/llama-3.1-nemotron-70b-instruct':
        name: 'Llama 3.1 Nemotron 70b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'nvidia/llama-3.1-nemotron-ultra-253b-v1':
        name: 'Llama-3.1-Nemotron-Ultra-253B-v1'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'nvidia/llama-3.3-nemotron-super-49b-v1':
        name: 'Llama 3.3 Nemotron Super 49b V1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'nvidia/llama-3.3-nemotron-super-49b-v1.5':
        name: 'Llama 3.3 Nemotron Super 49b V1.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
      'nvidia/llama-embed-nemotron-8b':
        name: 'Llama Embed Nemotron 8B'
        family: 'llama'
        mode: embedding
        max_input_tokens: 32768
        max_output_tokens: 2048
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2025-03'
      'nvidia/llama3-chatqa-1.5-70b':
        name: 'Llama3 Chatqa 1.5 70b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'nvidia/nemoretriever-ocr-v1':
        name: 'NeMo Retriever OCR v1'
        family: 'nemoretriever-ocr'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [vision]
        knowledge_cutoff: '2024-01'
      'nvidia/nemotron-3-nano-30b-a3b':
        name: 'nemotron-3-nano-30b-a3b'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'nvidia/nemotron-4-340b-instruct':
        name: 'Nemotron 4 340b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'nvidia/nvidia-nemotron-nano-9b-v2':
        name: 'nvidia-nemotron-nano-9b-v2'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'nvidia/parakeet-tdt-0.6b-v2':
        name: 'Parakeet TDT 0.6B v2'
        family: 'parakeet-tdt-0.6b'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input]
        knowledge_cutoff: '2024-01'
      'openai/gpt-oss-120b':
        name: 'GPT-OSS-120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature, vision]
        knowledge_cutoff: '2025-08'
      'openai/whisper-large-v3':
        name: 'Whisper Large v3'
        family: 'whisper-large'
        mode: audio_transcription
        max_input_tokens: 0
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input]
        knowledge_cutoff: '2023-09'
        open_weights: true
      'qwen/qwen2.5-coder-32b-instruct':
        name: 'Qwen2.5 Coder 32b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'qwen/qwen2.5-coder-7b-instruct':
        name: 'Qwen2.5 Coder 7b Instruct'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'qwen/qwen3-235b-a22b':
        name: 'Qwen3-235B-A22B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
      'qwen/qwen3-coder-480b-a35b-instruct':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen/qwen3-next-80b-a3b-instruct':
        name: 'Qwen3-Next-80B-A3B-Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
      'qwen/qwen3-next-80b-a3b-thinking':
        name: 'Qwen3-Next-80B-A3B-Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'qwen/qwq-32b':
        name: 'Qwq 32b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        open_weights: true
  ollama:
    name: 'Ollama Cloud'
    api_endpoint: 'https://ollama.com/v1'
    logo_url: 'https://models.dev/logos/ollama-cloud.svg'
    model_count: 12
    models:
      'cogito-2.1:671b-cloud':
        name: 'Cogito 2.1 671B'
        family: 'cogito-2.1:671b-cloud'
        mode: chat
        max_input_tokens: 160000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'deepseek-v3.1:671b-cloud':
        name: 'DeepSeek-V3.1 671B'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 160000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'gemini-3-pro-preview:latest':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        capabilities: [audio_input, function_calling, json_mode, temperature, video_input, vision]
      'glm-4.6:cloud':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'gpt-oss:120b-cloud':
        name: 'GPT-OSS 120B'
        family: 'gpt-oss:120b'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'gpt-oss:20b-cloud':
        name: 'GPT-OSS 20B'
        family: 'gpt-oss:20b'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'kimi-k2-thinking:cloud':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'kimi-k2:1t-cloud':
        name: 'Kimi K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'minimax-m2:cloud':
        name: 'MiniMax M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'qwen3-coder:480b-cloud':
        name: 'Qwen3 Coder 480B'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'qwen3-vl-235b-cloud':
        name: 'Qwen3-VL 235B Instruct'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'qwen3-vl-235b-instruct-cloud':
        name: 'Qwen3-VL 235B Instruct'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
  openai:
    name: 'OpenAI'
    api_endpoint: 'https://api.openai.com/v1'
    logo_url: 'https://models.dev/logos/openai.svg'
    model_count: 39
    models:
      'codex-mini-latest':
        name: 'Codex Mini'
        family: 'codex'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0015
        output_cost_per_1k: 0.006
        cache_read_cost_per_1k: 0.000375
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-04'
      'gpt-3.5-turbo':
        name: 'GPT-3.5-turbo'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16385
        max_output_tokens: 4096
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 0.00125
        capabilities: [temperature]
        knowledge_cutoff: '2021-09-01'
      'gpt-4':
        name: 'GPT-4'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.03
        output_cost_per_1k: 0.06
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-11'
      'gpt-4-turbo':
        name: 'GPT-4 Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
      'gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-mini':
        name: 'GPT-4.1 mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4.1-nano':
        name: 'GPT-4.1 nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-2024-05-13':
        name: 'GPT-4o (2024-05-13)'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.015
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-2024-08-06':
        name: 'GPT-4o (2024-08-06)'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-2024-11-20':
        name: 'GPT-4o (2024-11-20)'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-chat-latest':
        name: 'GPT-5 Chat (latest)'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-pro':
        name: 'GPT-5 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 272000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.12
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-chat-latest':
        name: 'GPT-5.1 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-max':
        name: 'GPT-5.1 Codex Max'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1 Codex mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'gpt-5.2-chat-latest':
        name: 'GPT-5.2 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'gpt-5.2-pro':
        name: 'GPT-5.2 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.021
        output_cost_per_1k: 0.168
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'o1':
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'o1-mini':
        family: 'o1-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [json_mode, reasoning]
        knowledge_cutoff: '2023-09'
      'o1-preview':
        family: 'o1-preview'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2023-09'
      'o1-pro':
        family: 'o1-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.15
        output_cost_per_1k: 0.6
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'o3':
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o3-deep-research':
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.04
        cache_read_cost_per_1k: 0.0025
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o3-mini':
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, json_mode, reasoning]
        knowledge_cutoff: '2024-05'
      'o3-pro':
        family: 'o3-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.02
        output_cost_per_1k: 0.08
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o4-mini':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'o4-mini-deep-research':
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'text-embedding-3-large':
        family: 'text-embedding-3-large'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 3072
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2024-01'
      'text-embedding-3-small':
        family: 'text-embedding-3-small'
        mode: embedding
        max_input_tokens: 8191
        max_output_tokens: 1536
        input_cost_per_1k: 2e-05
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2024-01'
      'text-embedding-ada-002':
        family: 'text-embedding-ada'
        mode: embedding
        max_input_tokens: 8192
        max_output_tokens: 1536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0
        knowledge_cutoff: '2022-12'
  opencode:
    name: 'OpenCode Zen'
    api_endpoint: 'https://opencode.ai/zen/v1'
    logo_url: 'https://models.dev/logos/opencode.svg'
    model_count: 26
    models:
      'alpha-gd4':
        name: 'Alpha GD4'
        family: 'alpha-gd4'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'alpha-glm-4.7':
        name: 'Alpha GLM-4.7'
        family: 'alpha-glm'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'big-pickle':
        name: 'Big Pickle'
        family: 'big-pickle'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
      'claude-3-5-haiku':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'claude-haiku-4-5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'claude-opus-4-1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-opus-4-5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'gemini-3-flash':
        name: 'Gemini 3 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro':
        name: 'Gemini 3 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.7-free':
        name: 'GLM-4.7'
        family: 'glm-free'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00107
        output_cost_per_1k: 0.0085
        cache_read_cost_per_1k: 0.000107
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-codex':
        name: 'GPT-5 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00107
        output_cost_per_1k: 0.0085
        cache_read_cost_per_1k: 0.000107
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00107
        output_cost_per_1k: 0.0085
        cache_read_cost_per_1k: 0.000107
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex':
        name: 'GPT-5.1 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00107
        output_cost_per_1k: 0.0085
        cache_read_cost_per_1k: 0.000107
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-max':
        name: 'GPT-5.1 Codex Max'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.1-codex-mini':
        name: 'GPT-5.1 Codex Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'grok-code':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
      'kimi-k2':
        name: 'Kimi K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.0004
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'minimax-m2.1-free':
        name: 'MiniMax M2.1'
        family: 'minimax-free'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'qwen3-coder':
        name: 'Qwen3 Coder'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  openrouter:
    name: 'OpenRouter'
    api_endpoint: 'https://openrouter.ai/api/v1'
    logo_url: 'https://models.dev/logos/openrouter.svg'
    model_count: 137
    models:
      'anthropic/claude-3.5-haiku':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'anthropic/claude-3.7-sonnet':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-01'
      'anthropic/claude-haiku-4.5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic/claude-opus-4':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4.1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4.5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-05-30'
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4.5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'cognitivecomputations/dolphin3.0-mistral-24b':
        name: 'Dolphin3.0 Mistral 24B'
        family: 'mistral'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'cognitivecomputations/dolphin3.0-r1-mistral-24b':
        name: 'Dolphin3.0 R1 Mistral 24B'
        family: 'mistral'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek/deepseek-chat-v3-0324':
        name: 'DeepSeek V3 0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek/deepseek-chat-v3.1':
        name: 'DeepSeek-V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'deepseek/deepseek-r1-0528-qwen3-8b:free':
        name: 'Deepseek R1 0528 Qwen3 8B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'deepseek/deepseek-r1-0528:free':
        name: 'R1 0528 (free)'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'deepseek/deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek/deepseek-r1-distill-qwen-14b':
        name: 'DeepSeek R1 Distill Qwen 14B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek/deepseek-r1:free':
        name: 'R1 (free)'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'deepseek/deepseek-v3-base:free':
        name: 'DeepSeek V3 Base (free)'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'deepseek/deepseek-v3.1-terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'deepseek/deepseek-v3.1-terminus:exacto':
        name: 'DeepSeek V3.1 Terminus (exacto)'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'deepseek/deepseek-v3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek/deepseek-v3.2-speciale':
        name: 'DeepSeek V3.2 Speciale'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 65536
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00041
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'featherless/qwerky-72b':
        name: 'Qwerky 72B'
        family: 'qwerky'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'google/gemini-2.0-flash-001':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'google/gemini-2.0-flash-exp:free':
        name: 'Gemini 2.0 Flash Experimental (free)'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 1048576
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-12'
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 3.75e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-lite-preview-09-2025':
        name: 'Gemini 2.5 Flash Lite Preview 09-25'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-preview-09-2025':
        name: 'Gemini 2.5 Flash Preview 09-25'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 3.1e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro-preview-05-06':
        name: 'Gemini 2.5 Pro Preview 05-06'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro-preview-06-05':
        name: 'Gemini 2.5 Pro Preview 06-05'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1050000
        max_output_tokens: 66000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemma-2-9b-it:free':
        name: 'Gemma 2 9B (free)'
        family: 'gemma-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-06'
        open_weights: true
      'google/gemma-3-12b-it':
        name: 'Gemma 3 12B IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'google/gemma-3-27b-it':
        name: 'Gemma 3 27B IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'google/gemma-3n-e4b-it':
        name: 'Gemma 3n E4B IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'google/gemma-3n-e4b-it:free':
        name: 'Gemma 3n 4B (free)'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'kwaipilot/kat-coder-pro:free':
        name: 'Kat Coder Pro (free)'
        family: 'kat-coder-pro'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-11'
      'meta-llama/llama-3.2-11b-vision-instruct':
        name: 'Llama 3.2 11B Vision Instruct'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/llama-3.3-70b-instruct:free':
        name: 'Llama 3.3 70B Instruct (free)'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 65536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'meta-llama/llama-4-scout:free':
        name: 'Llama 4 Scout (free)'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'microsoft/mai-ds-r1:free':
        name: 'MAI DS R1 (free)'
        family: 'mai-ds-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'minimax/minimax-01':
        name: 'MiniMax-01'
        family: 'minimax'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 1000000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0011
        capabilities: [function_calling, reasoning, temperature, vision]
        open_weights: true
      'minimax/minimax-m1':
        name: 'MiniMax M1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 40000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'minimax/minimax-m2':
        name: 'MiniMax M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 196600
        max_output_tokens: 118000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00115
        cache_read_cost_per_1k: 0.00028
        cache_write_cost_per_1k: 0.00115
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'minimax/minimax-m2.1':
        name: 'MiniMax M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'mistralai/codestral-2508':
        name: 'Codestral 2508'
        family: 'codestral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistralai/devstral-2512':
        name: 'Devstral 2 2512'
        family: 'devstral'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'mistralai/devstral-2512:free':
        name: 'Devstral 2 2512 (free)'
        family: 'devstral'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-12'
        open_weights: true
      'mistralai/devstral-medium-2507':
        name: 'Devstral Medium'
        family: 'devstral-medium'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistralai/devstral-small-2505':
        name: 'Devstral Small'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistralai/devstral-small-2505:free':
        name: 'Devstral Small 2505 (free)'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistralai/devstral-small-2507':
        name: 'Devstral Small 1.1'
        family: 'devstral-small'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'mistralai/mistral-7b-instruct:free':
        name: 'Mistral 7B Instruct (free)'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-05'
        open_weights: true
      'mistralai/mistral-medium-3':
        name: 'Mistral Medium 3'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistralai/mistral-medium-3.1':
        name: 'Mistral Medium 3.1'
        family: 'mistral-medium'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-05'
      'mistralai/mistral-nemo:free':
        name: 'Mistral Nemo (free)'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'mistralai/mistral-small-3.1-24b-instruct':
        name: 'Mistral Small 3.1 24B Instruct'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistralai/mistral-small-3.2-24b-instruct':
        name: 'Mistral Small 3.2 24B Instruct'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistralai/mistral-small-3.2-24b-instruct:free':
        name: 'Mistral Small 3.2 24B (free)'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 96000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'moonshotai/kimi-dev-72b:free':
        name: 'Kimi Dev 72b (free)'
        family: 'kimi'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'moonshotai/kimi-k2':
        name: 'Kimi K2'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/kimi-k2-0905':
        name: 'Kimi K2 Instruct 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/kimi-k2-0905:exacto':
        name: 'Kimi K2 Instruct 0905 (exacto)'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'moonshotai/kimi-k2:free':
        name: 'Kimi K2 (free)'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 32800
        max_output_tokens: 32800
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'nousresearch/deephermes-3-llama-3-8b-preview':
        name: 'DeepHermes 3 Llama 3 8B Preview'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'nousresearch/hermes-4-405b':
        name: 'Hermes 4 405B'
        family: 'hermes'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'nousresearch/hermes-4-70b':
        name: 'Hermes 4 70B'
        family: 'hermes'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'nvidia/nemotron-nano-9b-v2':
        name: 'nvidia-nemotron-nano-9b-v2'
        family: 'nemotron'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00016
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-mini':
        name: 'GPT-4.1 Mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4o-mini':
        name: 'GPT-4o-mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'openai/gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-chat':
        name: 'GPT-5 Chat (latest)'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        capabilities: [reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5-codex':
        name: 'GPT-5 Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-image':
        name: 'GPT-5 Image'
        family: 'gpt-5'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, image_output, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-01'
      'openai/gpt-5-pro':
        name: 'GPT-5 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 272000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.12
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.1-chat':
        name: 'GPT-5.1 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.1-codex':
        name: 'GPT-5.1-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.1-codex-mini':
        name: 'GPT-5.1-Codex-Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 100000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5.2':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'openai/gpt-5.2-chat-latest':
        name: 'GPT-5.2 Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.000175
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'openai/gpt-5.2-pro':
        name: 'GPT-5.2 Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.021
        output_cost_per_1k: 0.168
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2025-08-31'
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 7.2e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-120b:exacto':
        name: 'GPT OSS 120B (exacto)'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00024
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-safeguard-20b':
        name: 'GPT OSS Safeguard 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 65536
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
      'openai/o4-mini':
        name: 'o4 Mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-06'
      'openrouter/sherlock-dash-alpha':
        name: 'Sherlock Dash Alpha'
        family: 'sherlock'
        mode: chat
        max_input_tokens: 1840000
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-11'
      'openrouter/sherlock-think-alpha':
        name: 'Sherlock Think Alpha'
        family: 'sherlock'
        mode: chat
        max_input_tokens: 1840000
        max_output_tokens: 0
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-11'
      'qwen/qwen-2.5-coder-32b-instruct':
        name: 'Qwen2.5 Coder 32B Instruct'
        family: 'qwen'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'qwen/qwen2.5-vl-32b-instruct:free':
        name: 'Qwen2.5 VL 32B Instruct (free)'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'qwen/qwen2.5-vl-72b-instruct':
        name: 'Qwen2.5 VL 72B Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [temperature, vision]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'qwen/qwen2.5-vl-72b-instruct:free':
        name: 'Qwen2.5 VL 72B Instruct (free)'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-02'
        open_weights: true
      'qwen/qwen3-14b:free':
        name: 'Qwen3 14B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-235b-a22b-07-25':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00085
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-235b-a22b-07-25:free':
        name: 'Qwen3 235B A22B Instruct 2507 (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-235b-a22b-thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 81920
        input_cost_per_1k: 7.8e-05
        output_cost_per_1k: 0.000312
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-235b-a22b:free':
        name: 'Qwen3 235B A22B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-30b-a3b-instruct-2507':
        name: 'Qwen3 30B A3B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-30b-a3b-thinking-2507':
        name: 'Qwen3 30B A3B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-30b-a3b:free':
        name: 'Qwen3 30B A3B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-32b:free':
        name: 'Qwen3 32B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-8b:free':
        name: 'Qwen3 8B (free)'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 40960
        max_output_tokens: 40960
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-coder':
        name: 'Qwen3 Coder'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-coder-flash':
        name: 'Qwen3 Coder Flash'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 66536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'qwen/qwen3-coder:exacto':
        name: 'Qwen3 Coder (exacto)'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00038
        output_cost_per_1k: 0.00153
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-coder:free':
        name: 'Qwen3 Coder 480B A35B Instruct (free)'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-max':
        name: 'Qwen3 Max'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.006
        capabilities: [function_calling, reasoning, temperature]
      'qwen/qwen3-next-80b-a3b-instruct':
        name: 'Qwen3 Next 80B A3B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwen3-next-80b-a3b-thinking':
        name: 'Qwen3 Next 80B A3B Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'qwen/qwq-32b:free':
        name: 'QwQ 32B (free)'
        family: 'qwq'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'rekaai/reka-flash-3':
        name: 'Reka Flash 3'
        family: 'reka-flash'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'sarvamai/sarvam-m:free':
        name: 'Sarvam-M (free)'
        family: 'sarvam-m'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'thudm/glm-z1-32b:free':
        name: 'GLM Z1 32B (free)'
        family: 'glm-z1'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'tngtech/deepseek-r1t2-chimera:free':
        name: 'DeepSeek R1T2 Chimera (free)'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 163840
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'x-ai/grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        cache_write_cost_per_1k: 0.015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-3-beta':
        name: 'Grok 3 Beta'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        cache_write_cost_per_1k: 0.015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-3-mini-beta':
        name: 'Grok 3 Mini Beta'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-4':
        name: 'Grok 4'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        cache_write_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'x-ai/grok-4-fast':
        name: 'Grok 4 Fast'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-4.1-fast':
        name: 'Grok 4.1 Fast'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-11'
      'x-ai/grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-08'
      'z-ai/glm-4.5':
        name: 'GLM 4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'z-ai/glm-4.5-air':
        name: 'GLM 4.5 Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'z-ai/glm-4.5-air:free':
        name: 'GLM 4.5 Air (free)'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'z-ai/glm-4.5v':
        name: 'GLM 4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'z-ai/glm-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'z-ai/glm-4.6:exacto':
        name: 'GLM 4.6 (exacto)'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0019
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'z-ai/glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  ovhcloud:
    name: 'OVHcloud AI Endpoints'
    api_endpoint: 'https://oai.endpoints.kepler.ai.cloud.ovh.net/v1'
    logo_url: 'https://models.dev/logos/ovhcloud.svg'
    model_count: 15
    models:
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek-R1-Distill-Llama-70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00074
        output_cost_per_1k: 0.00074
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'gpt-oss-120b':
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00047
        capabilities: [function_calling, json_mode, reasoning]
        open_weights: true
      'gpt-oss-20b':
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, reasoning]
        open_weights: true
      'llama-3.1-8b-instruct':
        name: 'Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00011
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'llava-next-mistral-7b':
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00032
        output_cost_per_1k: 0.00032
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'meta-llama-3_1-70b-instruct':
        name: 'Meta-Llama-3_1-70B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00074
        output_cost_per_1k: 0.00074
        capabilities: [temperature]
        open_weights: true
      'meta-llama-3_3-70b-instruct':
        name: 'Meta-Llama-3_3-70B-Instruct'
        family: 'llama-3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00074
        output_cost_per_1k: 0.00074
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistral-7b-instruct-v0.3':
        name: 'Mistral-7B-Instruct-v0.3'
        family: 'mistral-7b'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 127000
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00011
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistral-nemo-instruct-2407':
        name: 'Mistral-Nemo-Instruct-2407'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 118000
        max_output_tokens: 118000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00014
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
      'mistral-small-3.2-24b-instruct-2506':
        name: 'Mistral-Small-3.2-24B-Instruct-2506'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.00031
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'mixtral-8x7b-instruct-v0.1':
        name: 'Mixtral-8x7B-Instruct-v0.1'
        family: 'mixtral-8x7b'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0007
        capabilities: [json_mode, temperature]
        open_weights: true
      'qwen2.5-coder-32b-instruct':
        name: 'Qwen2.5-Coder-32B-Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00096
        output_cost_per_1k: 0.00096
        capabilities: [json_mode, temperature]
        open_weights: true
      'qwen2.5-vl-72b-instruct':
        name: 'Qwen2.5-VL-72B-Instruct'
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00101
        output_cost_per_1k: 0.00101
        capabilities: [json_mode, temperature, vision]
        open_weights: true
      'qwen3-32b':
        name: 'Qwen3-32B'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00025
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'qwen3-coder-30b-a3b-instruct':
        name: 'Qwen3-Coder-30B-A3B-Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 256000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00026
        capabilities: [function_calling, json_mode, temperature]
        open_weights: true
  perplexity:
    name: 'Perplexity'
    api_endpoint: 'https://api.perplexity.ai'
    logo_url: 'https://models.dev/logos/perplexity.svg'
    model_count: 3
    models:
      'sonar':
        name: 'Sonar'
        family: 'sonar'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.001
        capabilities: [temperature]
        knowledge_cutoff: '2025-09-01'
      'sonar-pro':
        name: 'Sonar Pro'
        family: 'sonar-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [temperature, vision]
        knowledge_cutoff: '2025-09-01'
      'sonar-reasoning-pro':
        name: 'Sonar Reasoning Pro'
        family: 'sonar-reasoning'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [reasoning, temperature, vision]
        knowledge_cutoff: '2025-09-01'
  poe:
    name: 'Poe'
    api_endpoint: 'https://api.poe.com/v1'
    logo_url: 'https://models.dev/logos/poe.svg'
    model_count: 115
    models:
      'anthropic/claude-haiku-3':
        name: 'Claude-Haiku-3'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.0011
        cache_read_cost_per_1k: 2.1e-05
        cache_write_cost_per_1k: 0.00026
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-haiku-3.5':
        name: 'Claude-Haiku-3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.00068
        output_cost_per_1k: 0.0034
        cache_read_cost_per_1k: 6.8e-05
        cache_write_cost_per_1k: 0.00085
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-haiku-3.5-search':
        name: 'Claude-Haiku-3.5-Search'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.00068
        output_cost_per_1k: 0.0034
        cache_read_cost_per_1k: 6.8e-05
        cache_write_cost_per_1k: 0.00085
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-haiku-4.5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 192000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00085
        output_cost_per_1k: 0.0043
        cache_read_cost_per_1k: 8.5e-05
        cache_write_cost_per_1k: 0.0011
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-opus-3':
        name: 'Claude-Opus-3'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.013
        output_cost_per_1k: 0.064
        cache_read_cost_per_1k: 0.0013
        cache_write_cost_per_1k: 0.016
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-opus-4':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 192512
        max_output_tokens: 32768
        input_cost_per_1k: 0.013
        output_cost_per_1k: 0.064
        cache_read_cost_per_1k: 0.0013
        cache_write_cost_per_1k: 0.016
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-opus-4-reasoning':
        name: 'Claude Opus 4 Reasoning'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 32768
        input_cost_per_1k: 0.013
        output_cost_per_1k: 0.064
        cache_read_cost_per_1k: 0.0013
        cache_write_cost_per_1k: 0.016
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-opus-4-search':
        name: 'Claude Opus 4 Search'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 128000
        input_cost_per_1k: 0.013
        output_cost_per_1k: 0.064
        cache_read_cost_per_1k: 0.0013
        cache_write_cost_per_1k: 0.016
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-opus-4.1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 32000
        input_cost_per_1k: 0.013
        output_cost_per_1k: 0.064
        cache_read_cost_per_1k: 0.0013
        cache_write_cost_per_1k: 0.016
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-opus-4.5':
        name: 'claude-opus-4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 64000
        input_cost_per_1k: 0.0043
        output_cost_per_1k: 0.021
        cache_read_cost_per_1k: 0.00043
        cache_write_cost_per_1k: 0.0053
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-3.5':
        name: 'Claude-Sonnet-3.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-sonnet-3.5-june':
        name: 'Claude-Sonnet-3.5-June'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 189096
        max_output_tokens: 8192
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, vision]
      'anthropic/claude-sonnet-3.7':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 32768
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-3.7-reasoning':
        name: 'Claude Sonnet 3.7 Reasoning'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 128000
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-3.7-search':
        name: 'Claude Sonnet 3.7 Search'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 128000
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 983040
        max_output_tokens: 32768
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-4-reasoning':
        name: 'Claude Sonnet 4 Reasoning'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 983040
        max_output_tokens: 64000
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-4-search':
        name: 'Claude Sonnet 4 Search'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 983040
        max_output_tokens: 128000
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'anthropic/claude-sonnet-4.5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 983040
        max_output_tokens: 32768
        input_cost_per_1k: 0.0026
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00026
        cache_write_cost_per_1k: 0.0032
        capabilities: [function_calling, pdf_input, reasoning, vision]
      'cerebras/gpt-oss-120b-cs':
        name: 'gpt-oss-120b-cs'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, reasoning, vision]
      'cerebras/zai-glm-4.6-cs':
        name: 'zai-glm-4.6-cs'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 40000
        capabilities: [function_calling, reasoning, vision]
      'elevenlabs/elevenlabs-music':
        name: 'ElevenLabs-Music'
        family: 'elevenlabs-music'
        mode: audio_speech
        max_input_tokens: 2000
        max_output_tokens: 0
        capabilities: [audio_output, function_calling, vision]
      'elevenlabs/elevenlabs-v2.5-turbo':
        name: 'ElevenLabs-v2.5-Turbo'
        family: 'elevenlabs-v2.5-turbo'
        mode: audio_speech
        max_input_tokens: 128000
        max_output_tokens: 0
        capabilities: [audio_output, function_calling, vision]
      'elevenlabs/elevenlabs-v3':
        name: 'ElevenLabs-v3'
        family: 'elevenlabs'
        mode: audio_speech
        max_input_tokens: 128000
        max_output_tokens: 0
        capabilities: [audio_output, function_calling, vision]
      'google/gemini-2.0-flash':
        name: 'Gemini-2.0-Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 990000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.00042
        capabilities: [audio_input, function_calling, video_input, vision]
      'google/gemini-2.0-flash-lite':
        name: 'Gemini-2.0-Flash-Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 990000
        max_output_tokens: 8192
        input_cost_per_1k: 5.2e-05
        output_cost_per_1k: 0.00021
        capabilities: [audio_input, function_calling, video_input, vision]
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1065535
        max_output_tokens: 65535
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.0018
        cache_read_cost_per_1k: 2.1e-05
        capabilities: [audio_input, function_calling, reasoning, video_input, vision]
      'google/gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1024000
        max_output_tokens: 64000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [audio_input, function_calling, reasoning, video_input, vision]
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1065535
        max_output_tokens: 65535
        input_cost_per_1k: 0.00087
        output_cost_per_1k: 0.007
        cache_read_cost_per_1k: 8.7e-05
        capabilities: [audio_input, function_calling, reasoning, video_input, vision]
      'google/gemini-3-flash':
        name: 'gemini-3-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0024
        cache_read_cost_per_1k: 4e-05
        capabilities: [audio_input, function_calling, reasoning, video_input, vision]
      'google/gemini-3-pro':
        name: 'Gemini-3-Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.0016
        output_cost_per_1k: 0.0096
        cache_read_cost_per_1k: 0.00016
        capabilities: [audio_input, function_calling, reasoning, video_input, vision]
      'google/gemini-deep-research':
        name: 'gemini-deep-research'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 0
        input_cost_per_1k: 0.0016
        output_cost_per_1k: 0.0096
        capabilities: [function_calling, reasoning, video_input, vision]
      'google/imagen-3':
        name: 'Imagen-3'
        family: 'imagen'
        mode: image
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'google/imagen-3-fast':
        name: 'Imagen-3-Fast'
        family: 'imagen-3-fast'
        mode: image
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'google/imagen-4':
        name: 'Imagen-4'
        family: 'imagen'
        mode: image
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'google/imagen-4-fast':
        name: 'Imagen-4-Fast'
        family: 'imagen-4-fast'
        mode: image
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'google/imagen-4-ultra':
        name: 'Imagen-4-Ultra'
        family: 'imagen-4-ultra'
        mode: image
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'google/lyria':
        name: 'Lyria'
        family: 'lyria'
        mode: audio_speech
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [audio_output, function_calling, vision]
      'google/nano-banana':
        name: 'Nano-Banana'
        family: 'nano-banana'
        mode: image
        max_input_tokens: 32768
        max_output_tokens: 0
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.0018
        cache_read_cost_per_1k: 2.1e-05
        capabilities: [function_calling, image_output, vision]
      'google/nano-banana-pro':
        name: 'Nano-Banana-Pro'
        family: 'nano-banana-pro'
        mode: image
        max_input_tokens: 65536
        max_output_tokens: 0
        input_cost_per_1k: 0.0017
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00017
        capabilities: [function_calling, image_output, vision]
      'google/veo-2':
        name: 'Veo-2'
        family: 'veo'
        mode: chat
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'google/veo-3':
        name: 'Veo-3'
        family: 'veo'
        mode: chat
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'google/veo-3-fast':
        name: 'Veo-3-Fast'
        family: 'veo-3-fast'
        mode: chat
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'google/veo-3.1':
        name: 'Veo-3.1'
        family: 'veo'
        mode: chat
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'google/veo-3.1-fast':
        name: 'Veo-3.1-Fast'
        family: 'veo-3.1-fast'
        mode: chat
        max_input_tokens: 480
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'ideogramai/ideogram':
        name: 'Ideogram'
        family: 'ideogram'
        mode: image
        max_input_tokens: 150
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'ideogramai/ideogram-v2':
        name: 'Ideogram-v2'
        family: 'ideogram'
        mode: image
        max_input_tokens: 150
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'ideogramai/ideogram-v2a':
        name: 'Ideogram-v2a'
        family: 'ideogram'
        mode: image
        max_input_tokens: 150
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'ideogramai/ideogram-v2a-turbo':
        name: 'Ideogram-v2a-Turbo'
        family: 'ideogram'
        mode: image
        max_input_tokens: 150
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'lumalabs/dream-machine':
        name: 'Dream-Machine'
        family: 'dream-machine'
        mode: chat
        max_input_tokens: 5000
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'lumalabs/ray2':
        name: 'Ray2'
        family: 'ray2'
        mode: chat
        max_input_tokens: 5000
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'novita/glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'novita/glm-4.6v':
        name: 'glm-4.6v'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 32768
        capabilities: [function_calling, reasoning, vision]
      'novita/glm-4.7':
        name: 'glm-4.7'
        mode: chat
        max_input_tokens: 205000
        max_output_tokens: 131072
        capabilities: [function_calling, reasoning, temperature, vision]
      'novita/kat-coder-pro':
        name: 'kat-coder-pro'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'novita/kimi-k2-thinking':
        name: 'kimi-k2-thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 0
        capabilities: [function_calling, reasoning, vision]
      'novita/minimax-m2.1':
        name: 'minimax-m2.1'
        mode: chat
        max_input_tokens: 205000
        max_output_tokens: 131072
        capabilities: [function_calling, reasoning, vision]
      'openai/chatgpt-4o-latest':
        name: 'ChatGPT-4o-Latest'
        family: 'chatgpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0045
        output_cost_per_1k: 0.014
        capabilities: [function_calling, vision]
      'openai/dall-e-3':
        name: 'DALL-E-3'
        family: 'dall-e-3'
        mode: image
        max_input_tokens: 800
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'openai/gpt-3.5-turbo':
        name: 'GPT-3.5-Turbo'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 16384
        max_output_tokens: 2048
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, vision]
      'openai/gpt-3.5-turbo-instruct':
        name: 'GPT-3.5-Turbo-Instruct'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 3500
        max_output_tokens: 1024
        input_cost_per_1k: 0.0014
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, vision]
      'openai/gpt-3.5-turbo-raw':
        name: 'GPT-3.5-Turbo-Raw'
        family: 'gpt-3.5-turbo'
        mode: chat
        max_input_tokens: 4524
        max_output_tokens: 2048
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, vision]
      'openai/gpt-4-classic':
        name: 'GPT-4-Classic'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.027
        output_cost_per_1k: 0.054
        capabilities: [function_calling, vision]
      'openai/gpt-4-classic-0314':
        name: 'GPT-4-Classic-0314'
        family: 'gpt-4'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.027
        output_cost_per_1k: 0.054
        capabilities: [function_calling, vision]
      'openai/gpt-4-turbo':
        name: 'GPT-4-Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.009
        output_cost_per_1k: 0.027
        capabilities: [function_calling, vision]
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0018
        output_cost_per_1k: 0.0072
        cache_read_cost_per_1k: 0.00045
        capabilities: [function_calling, vision]
      'openai/gpt-4.1-mini':
        name: 'GPT-4.1-mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.00036
        output_cost_per_1k: 0.0014
        cache_read_cost_per_1k: 9e-05
        capabilities: [function_calling, vision]
      'openai/gpt-4.1-nano':
        name: 'GPT-4.1-nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00036
        cache_read_cost_per_1k: 2.2e-05
        capabilities: [function_calling, vision]
      'openai/gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        capabilities: [function_calling, vision]
      'openai/gpt-4o-aug':
        name: 'GPT-4o-Aug'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0022
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.0011
        capabilities: [function_calling, vision]
      'openai/gpt-4o-mini':
        name: 'GPT-4o-mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00054
        cache_read_cost_per_1k: 6.8e-05
        capabilities: [function_calling, vision]
      'openai/gpt-4o-mini-search':
        name: 'GPT-4o-mini-Search'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00054
        capabilities: [function_calling, vision]
      'openai/gpt-4o-search':
        name: 'GPT-4o-Search'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0022
        output_cost_per_1k: 0.009
        capabilities: [function_calling, vision]
      'openai/gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5-chat':
        name: 'GPT-5-Chat'
        family: 'gpt-5-chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, vision]
      'openai/gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5-mini':
        name: 'GPT-5-mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.0018
        cache_read_cost_per_1k: 2.2e-05
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5-nano':
        name: 'GPT-5-nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 4.5e-05
        output_cost_per_1k: 0.00036
        cache_read_cost_per_1k: 4.5e-06
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5-pro':
        name: 'GPT-5-Pro'
        family: 'gpt-5-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.014
        output_cost_per_1k: 0.11
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.1':
        name: 'GPT-5.1'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.1-codex':
        name: 'GPT-5.1-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.1-codex-max':
        name: 'gpt-5.1-codex-max'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.1-codex-mini':
        name: 'GPT-5.1-Codex-Mini'
        family: 'gpt-5-codex-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.0018
        cache_read_cost_per_1k: 2.2e-05
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.1-instant':
        name: 'GPT-5.1-Instant'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.009
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, vision]
      'openai/gpt-5.2':
        name: 'gpt-5.2'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0016
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00016
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-5.2-instant':
        name: 'gpt-5.2-instant'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0016
        output_cost_per_1k: 0.013
        cache_read_cost_per_1k: 0.00016
        capabilities: [function_calling, vision]
      'openai/gpt-5.2-pro':
        name: 'gpt-5.2-pro'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.019
        output_cost_per_1k: 0.15
        capabilities: [function_calling, reasoning, vision]
      'openai/gpt-image-1':
        name: 'GPT-Image-1'
        family: 'gpt-image'
        mode: image
        max_input_tokens: 128000
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'openai/gpt-image-1-mini':
        name: 'GPT-Image-1-Mini'
        family: 'gpt-image'
        mode: image
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'openai/gpt-image-1.5':
        name: 'gpt-image-1.5'
        mode: image
        max_input_tokens: 128000
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'openai/o1':
        name: 'o1'
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.014
        output_cost_per_1k: 0.054
        capabilities: [function_calling, reasoning, vision]
      'openai/o1-pro':
        name: 'o1-pro'
        family: 'o1-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.14
        output_cost_per_1k: 0.54
        capabilities: [function_calling, reasoning, vision]
      'openai/o3':
        name: 'o3'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0018
        output_cost_per_1k: 0.0072
        cache_read_cost_per_1k: 0.00045
        capabilities: [function_calling, reasoning, vision]
      'openai/o3-deep-research':
        name: 'o3-deep-research'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.009
        output_cost_per_1k: 0.036
        cache_read_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, vision]
      'openai/o3-mini':
        name: 'o3-mini'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.00099
        output_cost_per_1k: 0.004
        capabilities: [function_calling, reasoning, vision]
      'openai/o3-mini-high':
        name: 'o3-mini-high'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.00099
        output_cost_per_1k: 0.004
        capabilities: [function_calling, reasoning, vision]
      'openai/o3-pro':
        name: 'o3-pro'
        family: 'o3-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.018
        output_cost_per_1k: 0.072
        capabilities: [function_calling, reasoning, vision]
      'openai/o4-mini':
        name: 'o4-mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.00099
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 0.00025
        capabilities: [function_calling, reasoning, vision]
      'openai/o4-mini-deep-research':
        name: 'o4-mini-deep-research'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0018
        output_cost_per_1k: 0.0072
        cache_read_cost_per_1k: 0.00045
        capabilities: [function_calling, reasoning, vision]
      'openai/sora-2':
        name: 'Sora-2'
        family: 'sora'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'openai/sora-2-pro':
        name: 'Sora-2-Pro'
        family: 'sora-2-pro'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'poetools/claude-code':
        name: 'claude-code'
        mode: chat
        max_input_tokens: 0
        max_output_tokens: 0
        capabilities: [function_calling, reasoning, vision]
      'runwayml/runway':
        name: 'Runway'
        family: 'runway'
        mode: chat
        max_input_tokens: 256
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'runwayml/runway-gen-4-turbo':
        name: 'Runway-Gen-4-Turbo'
        family: 'runway-gen-4-turbo'
        mode: chat
        max_input_tokens: 256
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'stabilityai/stablediffusionxl':
        name: 'StableDiffusionXL'
        family: 'stablediffusionxl'
        mode: image
        max_input_tokens: 200
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'topazlabs-co/topazlabs':
        name: 'TopazLabs'
        family: 'topazlabs'
        mode: image
        max_input_tokens: 204
        max_output_tokens: 0
        capabilities: [function_calling, image_output, vision]
      'trytako/tako':
        name: 'Tako'
        family: 'tako'
        mode: chat
        max_input_tokens: 2048
        max_output_tokens: 0
        capabilities: [function_calling, vision]
      'xai/grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, vision]
      'xai/grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, vision]
      'xai/grok-4':
        name: 'Grok 4'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 128000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, vision]
      'xai/grok-4-fast-non-reasoning':
        name: 'Grok-4-Fast-Non-Reasoning'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, vision]
      'xai/grok-4-fast-reasoning':
        name: 'Grok 4 Fast Reasoning'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, vision]
      'xai/grok-4.1-fast-non-reasoning':
        name: 'Grok-4.1-Fast-Non-Reasoning'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        capabilities: [function_calling, vision]
      'xai/grok-4.1-fast-reasoning':
        name: 'Grok-4.1-Fast-Reasoning'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        capabilities: [function_calling, reasoning, vision]
      'xai/grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, vision]
  requesty:
    name: 'Requesty'
    api_endpoint: 'https://router.requesty.ai/v1'
    logo_url: 'https://models.dev/logos/requesty.svg'
    model_count: 20
    models:
      'anthropic/claude-3-7-sonnet':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-01'
      'anthropic/claude-haiku-4-5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 62000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-01'
      'anthropic/claude-opus-4':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4-1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4-5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-sonnet-4-5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.00055
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        cache_write_cost_per_1k: 0.002375
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-flash-preview':
        name: 'Gemini 3 Flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-pro-preview':
        name: 'Gemini 3 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        cache_write_cost_per_1k: 0.0045
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-mini':
        name: 'GPT-4.1 Mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4o-mini':
        name: 'GPT-4o Mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-10'
      'openai/gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: image
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [audio_input, audio_output, function_calling, image_output, reasoning, video_input, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'openai/gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 4000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'openai/o4-mini':
        name: 'o4 Mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-06'
      'xai/grok-4':
        name: 'Grok 4'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        cache_write_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01'
      'xai/grok-4-fast':
        name: 'Grok 4 Fast'
        family: 'grok-4'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01'
  sap_ai_core:
    name: 'SAP AI Core'
    logo_url: 'https://models.dev/logos/sap-ai-core.svg'
    model_count: 14
    models:
      'anthropic--claude-3-haiku':
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic--claude-3-opus':
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic--claude-3-sonnet':
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic--claude-3.5-sonnet':
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'anthropic--claude-3.7-sonnet':
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'anthropic--claude-4-opus':
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-31'
      'anthropic--claude-4-sonnet':
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-31'
      'anthropic--claude-4.5-haiku':
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic--claude-4.5-sonnet':
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-31'
      'gemini-2.5-flash':
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-2.5-pro':
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gpt-5':
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'gpt-5-mini':
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'gpt-5-nano':
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
  scaleway:
    name: 'Scaleway'
    api_endpoint: 'https://api.scaleway.ai/v1'
    logo_url: 'https://models.dev/logos/scaleway.svg'
    model_count: 14
    models:
      'bge-multilingual-gemma2':
        name: 'BGE Multilingual Gemma2'
        family: 'gemma-2'
        mode: chat
        max_input_tokens: 8191
        max_output_tokens: 3072
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'devstral-2-123b-instruct-2512':
        name: 'Devstral 2 123B Instruct (2512)'
        family: 'devstral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        open_weights: true
      'gemma-3-27b-it':
        name: 'Gemma-3-27B-IT'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 40000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
      'gpt-oss-120b':
        name: 'GPT-OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'llama-3.1-8b-instruct':
        name: 'Llama 3.1 8B Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-70b-instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 100000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'mistral-nemo-instruct-2407':
        name: 'Mistral Nemo Instruct 2407'
        family: 'mistral-nemo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'mistral-small-3.2-24b-instruct-2506':
        name: 'Mistral Small 3.2 24B Instruct (2506)'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00035
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'pixtral-12b-2409':
        name: 'Pixtral 12B 2409'
        family: 'pixtral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'qwen3-235b-a22b-instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 260000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00075
        output_cost_per_1k: 0.00225
        capabilities: [function_calling, temperature, vision]
        open_weights: true
      'qwen3-coder-30b-a3b-instruct':
        name: 'Qwen3-Coder 30B-A3B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'voxtral-small-24b-2507':
        name: 'Voxtral Small 24B 2507'
        family: 'voxtral-small'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00035
        capabilities: [audio_input, function_calling, temperature, vision]
        open_weights: true
      'whisper-large-v3':
        name: 'Whisper Large v3'
        family: 'whisper-large'
        mode: audio_transcription
        max_input_tokens: 0
        max_output_tokens: 4096
        input_cost_per_1k: 3e-06
        output_cost_per_1k: 0.0
        capabilities: [audio_input]
        knowledge_cutoff: '2023-09'
        open_weights: true
  siliconflow:
    name: 'SiliconFlow'
    api_endpoint: 'https://api.siliconflow.com/v1'
    logo_url: 'https://models.dev/logos/siliconflow.svg'
    model_count: 72
    models:
      'ByteDance-Seed/Seed-OSS-36B-Instruct':
        family: 'bytedance-seed-seed-oss'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'MiniMaxAI/MiniMax-M1-80k':
        family: 'minimax'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'MiniMaxAI/MiniMax-M2':
        family: 'minimax'
        mode: chat
        max_input_tokens: 197000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/QwQ-32B':
        family: 'qwq'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00058
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen2.5-14B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-32B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-72B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-72B-Instruct-128K':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-7B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-Coder-32B-Instruct':
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-VL-32B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen2.5-VL-72B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen2.5-VL-7B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-14B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00142
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-30B-A3B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-30B-A3B-Instruct-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-30B-A3B-Thinking-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 131000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-32B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-8B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 6e-05
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Coder-30B-A3B-Instruct':
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Next-80B-A3B-Instruct':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Next-80B-A3B-Thinking':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-Omni-30B-A3B-Captioner':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-Omni-30B-A3B-Instruct':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-Omni-30B-A3B-Thinking':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-235B-A22B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-235B-A22B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0035
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-30B-A3B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-30B-A3B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-32B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-32B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-8B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00068
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-8B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'THUDM/GLM-4-32B-0414':
        family: 'glm-4'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, json_mode, temperature]
      'THUDM/GLM-4-9B-0414':
        family: 'glm-4'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 8.6e-05
        output_cost_per_1k: 8.6e-05
        capabilities: [function_calling, json_mode, temperature]
      'THUDM/GLM-4.1V-9B-Thinking':
        family: 'glm-4v'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 3.5e-05
        output_cost_per_1k: 0.00014
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'THUDM/GLM-Z1-32B-0414':
        family: 'glm-z1'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'THUDM/GLM-Z1-9B-0414':
        family: 'glm-z1'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 8.6e-05
        output_cost_per_1k: 8.6e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'baidu/ERNIE-4.5-300B-A47B':
        family: 'ernie-4'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.0011
        capabilities: [function_calling, json_mode, temperature]
      'deepseek-ai/DeepSeek-R1':
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00218
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 16000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature]
      'deepseek-ai/DeepSeek-V3.1':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3.1-Terminus':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3.2-Exp':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00041
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/deepseek-vl2':
        family: 'deepseek'
        mode: chat
        max_input_tokens: 4000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, json_mode, temperature, vision]
      'inclusionAI/Ling-flash-2.0':
        family: 'inclusionai-ling-flash'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'inclusionAI/Ling-mini-2.0':
        family: 'inclusionai-ling-mini'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'inclusionAI/Ring-flash-2.0':
        family: 'inclusionai-ring-flash'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'meta-llama/Meta-Llama-3.1-8B-Instruct':
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 6e-05
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-Dev-72B':
        family: 'kimi'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00115
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Instruct':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00058
        output_cost_per_1k: 0.00229
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Instruct-0905':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Thinking':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'nex-agi/DeepSeek-V3.1-Nex-N1':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'openai/gpt-oss-120b':
        family: 'openai-gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 8000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'openai/gpt-oss-20b':
        family: 'openai-gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 8000
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'stepfun-ai/step3':
        family: 'stepfun-ai-step3'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.00057
        output_cost_per_1k: 0.00142
        capabilities: [function_calling, json_mode, temperature, vision]
      'tencent/Hunyuan-A13B-Instruct':
        family: 'hunyuan'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'tencent/Hunyuan-MT-7B':
        family: 'hunyuan'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'z-ai/GLM-4.5':
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'z-ai/GLM-4.5-Air':
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5':
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5-Air':
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5V':
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature, vision]
      'zai-org/GLM-4.6':
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 205000
        max_output_tokens: 205000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0019
        capabilities: [function_calling, json_mode, temperature]
  siliconflow_cn:
    name: 'SiliconFlow (China)'
    api_endpoint: 'https://api.siliconflow.cn/v1'
    logo_url: 'https://models.dev/logos/siliconflow-cn.svg'
    model_count: 72
    models:
      'ByteDance-Seed/Seed-OSS-36B-Instruct':
        family: 'bytedance-seed-seed-oss'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'MiniMaxAI/MiniMax-M1-80k':
        family: 'minimax'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'MiniMaxAI/MiniMax-M2':
        family: 'minimax'
        mode: chat
        max_input_tokens: 197000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/QwQ-32B':
        family: 'qwq'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00058
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen2.5-14B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-32B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-72B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-72B-Instruct-128K':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-7B-Instruct':
        family: 'qwen2.5'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-Coder-32B-Instruct':
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen2.5-VL-32B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen2.5-VL-72B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00059
        output_cost_per_1k: 0.00059
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen2.5-VL-7B-Instruct':
        family: 'qwen2.5-vl'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-14B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00142
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00013
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-30B-A3B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-30B-A3B-Instruct-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-30B-A3B-Thinking-2507':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 131000
        input_cost_per_1k: 9e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-32B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-8B':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 6e-05
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Coder-30B-A3B-Instruct':
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Next-80B-A3B-Instruct':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.0014
        capabilities: [function_calling, json_mode, temperature]
      'Qwen/Qwen3-Next-80B-A3B-Thinking':
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'Qwen/Qwen3-Omni-30B-A3B-Captioner':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-Omni-30B-A3B-Instruct':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-Omni-30B-A3B-Thinking':
        family: 'qwen3-omni'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        capabilities: [audio_input, function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-235B-A22B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-235B-A22B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0035
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-30B-A3B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-30B-A3B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-32B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-32B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'Qwen/Qwen3-VL-8B-Instruct':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00068
        capabilities: [function_calling, json_mode, temperature, vision]
      'Qwen/Qwen3-VL-8B-Thinking':
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'THUDM/GLM-4-32B-0414':
        family: 'glm-4'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00027
        capabilities: [function_calling, json_mode, temperature]
      'THUDM/GLM-4-9B-0414':
        family: 'glm-4'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 8.6e-05
        output_cost_per_1k: 8.6e-05
        capabilities: [function_calling, json_mode, temperature]
      'THUDM/GLM-4.1V-9B-Thinking':
        family: 'glm-4v'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 3.5e-05
        output_cost_per_1k: 0.00014
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
      'THUDM/GLM-Z1-32B-0414':
        family: 'glm-z1'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'THUDM/GLM-Z1-9B-0414':
        family: 'glm-z1'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 8.6e-05
        output_cost_per_1k: 8.6e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'baidu/ERNIE-4.5-300B-A47B':
        family: 'ernie-4'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.0011
        capabilities: [function_calling, json_mode, temperature]
      'deepseek-ai/DeepSeek-R1':
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00218
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-14B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00018
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-R1-Distill-Qwen-7B':
        family: 'qwen'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 16000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 5e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, temperature]
      'deepseek-ai/DeepSeek-V3.1':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3.1-Terminus':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3.2-Exp':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 164000
        max_output_tokens: 164000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.00041
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'deepseek-ai/deepseek-vl2':
        family: 'deepseek'
        mode: chat
        max_input_tokens: 4000
        max_output_tokens: 4000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, json_mode, temperature, vision]
      'inclusionAI/Ling-flash-2.0':
        family: 'inclusionai-ling-flash'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'inclusionAI/Ling-mini-2.0':
        family: 'inclusionai-ling-mini'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, temperature]
      'inclusionAI/Ring-flash-2.0':
        family: 'inclusionai-ring-flash'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'meta-llama/Meta-Llama-3.1-8B-Instruct':
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 4000
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 6e-05
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-Dev-72B':
        family: 'kimi'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00029
        output_cost_per_1k: 0.00115
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Instruct':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00058
        output_cost_per_1k: 0.00229
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Instruct-0905':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'moonshotai/Kimi-K2-Thinking':
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262000
        max_output_tokens: 262000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.0025
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'nex-agi/DeepSeek-V3.1-Nex-N1':
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'openai/gpt-oss-120b':
        family: 'openai-gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 8000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00045
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'openai/gpt-oss-20b':
        family: 'openai-gpt-oss'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 8000
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 0.00018
        capabilities: [function_calling, json_mode, temperature]
      'stepfun-ai/step3':
        family: 'stepfun-ai-step3'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.00057
        output_cost_per_1k: 0.00142
        capabilities: [function_calling, json_mode, temperature, vision]
      'tencent/Hunyuan-A13B-Instruct':
        family: 'hunyuan'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, json_mode, temperature]
      'tencent/Hunyuan-MT-7B':
        family: 'hunyuan'
        mode: chat
        max_input_tokens: 33000
        max_output_tokens: 33000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, temperature]
      'z-ai/GLM-4.5':
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'z-ai/GLM-4.5-Air':
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5':
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5-Air':
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131000
        max_output_tokens: 131000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature]
      'zai-org/GLM-4.5V':
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 66000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00086
        capabilities: [function_calling, json_mode, temperature, vision]
      'zai-org/GLM-4.6':
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 205000
        max_output_tokens: 205000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0019
        capabilities: [function_calling, json_mode, temperature]
  submodel:
    name: 'submodel'
    api_endpoint: 'https://llm.submodel.ai/v1'
    logo_url: 'https://models.dev/logos/submodel.svg'
    model_count: 9
    models:
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, temperature]
      'deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek R1 0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 75000
        max_output_tokens: 163840
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00215
        capabilities: [function_calling, reasoning, temperature]
      'deepseek-ai/DeepSeek-V3-0324':
        name: 'DeepSeek V3 0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 75000
        max_output_tokens: 163840
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, temperature]
      'deepseek-ai/DeepSeek-V3.1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 75000
        max_output_tokens: 163840
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature]
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'zai-org/GLM-4.5-Air':
        name: 'GLM 4.5 Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, temperature]
        open_weights: true
      'zai-org/GLM-4.5-FP8':
        name: 'GLM 4.5 FP8'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0008
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
  synthetic:
    name: 'Synthetic'
    api_endpoint: 'https://api.synthetic.new/v1'
    logo_url: 'https://models.dev/logos/synthetic.svg'
    model_count: 25
    models:
      'hf:MiniMaxAI/MiniMax-M2':
        name: 'MiniMax-M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 196608
        max_output_tokens: 131000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'hf:MiniMaxAI/MiniMax-M2.1':
        name: 'MiniMax-M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'hf:Qwen/Qwen2.5-Coder-32B-Instruct':
        name: 'Qwen2.5-Coder-32B-Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0008
        capabilities: [temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'hf:Qwen/Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen 3 235B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'hf:Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.00065
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'hf:Qwen/Qwen3-Coder-480B-A35B-Instruct':
        name: 'Qwen 3 Coder 480B'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'hf:deepseek-ai/DeepSeek-R1':
        name: 'DeepSeek R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01'
        open_weights: true
      'hf:deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek R1 (0528)'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.008
        capabilities: [function_calling, reasoning, temperature]
      'hf:deepseek-ai/DeepSeek-V3':
        name: 'DeepSeek V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.00125
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'hf:deepseek-ai/DeepSeek-V3-0324':
        name: 'DeepSeek V3 (0324)'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
      'hf:deepseek-ai/DeepSeek-V3.1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00168
        capabilities: [function_calling, reasoning, temperature]
      'hf:deepseek-ai/DeepSeek-V3.1-Terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, reasoning, temperature]
      'hf:deepseek-ai/DeepSeek-V3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 162816
        max_output_tokens: 8000
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 0.00027
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, json_mode, reasoning, temperature]
        open_weights: true
      'hf:meta-llama/Llama-3.1-405B-Instruct':
        name: 'Llama-3.1-405B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.003
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'hf:meta-llama/Llama-3.1-70B-Instruct':
        name: 'Llama-3.1-70B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'hf:meta-llama/Llama-3.1-8B-Instruct':
        name: 'Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'hf:meta-llama/Llama-3.3-70B-Instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8':
        name: 'Llama-4-Maverick-17B-128E-Instruct-FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 524000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00088
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'hf:meta-llama/Llama-4-Scout-17B-16E-Instruct':
        name: 'Llama-4-Scout-17B-16E-Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 328000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'hf:moonshotai/Kimi-K2-Instruct-0905':
        name: 'Kimi K2 0905'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.0012
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'hf:moonshotai/Kimi-K2-Thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-11'
        open_weights: true
      'hf:openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'hf:zai-org/GLM-4.5':
        name: 'GLM 4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'hf:zai-org/GLM-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'hf:zai-org/GLM-4.7':
        name: 'GLM 4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00219
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  togetherai:
    name: 'Together AI'
    logo_url: 'https://models.dev/logos/togetherai.svg'
    model_count: 10
    models:
      'Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8':
        name: 'Qwen3 Coder 480B A35B Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'deepseek-ai/DeepSeek-R1':
        name: 'DeepSeek R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 163839
        max_output_tokens: 12288
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.007
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-ai/DeepSeek-V3':
        name: 'DeepSeek V3'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 12288
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.00125
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'deepseek-ai/DeepSeek-V3-1':
        name: 'DeepSeek V3.1'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 12288
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0017
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-08'
        open_weights: true
      'essentialai/Rnj-1-Instruct':
        name: 'Rnj-1 Instruct'
        family: 'rnj'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 32768
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'meta-llama/Llama-3.3-70B-Instruct-Turbo':
        name: 'Llama 3.3 70B'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 66536
        input_cost_per_1k: 0.00088
        output_cost_per_1k: 0.00088
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'moonshotai/Kimi-K2-Thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.004
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 131072
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-08'
        open_weights: true
      'zai-org/GLM-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
  upstage:
    name: 'Upstage'
    api_endpoint: 'https://api.upstage.ai'
    logo_url: 'https://models.dev/logos/upstage.svg'
    model_count: 2
    models:
      'solar-mini':
        family: 'solar-mini'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 4096
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-09'
      'solar-pro2':
        family: 'solar-pro'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 8192
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00025
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-03'
  v0:
    name: 'v0'
    logo_url: 'https://models.dev/logos/v0.svg'
    model_count: 3
    models:
      'v0-1.0-md':
        family: 'v0'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature, vision]
      'v0-1.5-lg':
        family: 'v0'
        mode: chat
        max_input_tokens: 512000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        capabilities: [function_calling, reasoning, temperature, vision]
      'v0-1.5-md':
        family: 'v0'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature, vision]
  venice:
    name: 'Venice AI'
    api_endpoint: 'https://api.venice.ai/api/v1'
    logo_url: 'https://models.dev/logos/venice.svg'
    model_count: 24
    models:
      'claude-opus-45':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.006
        output_cost_per_1k: 0.03
        cache_read_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03'
      'deepseek-v3.2':
        name: 'DeepSeek V3.2'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 40960
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.001
        cache_read_cost_per_1k: 0.0002
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-10'
        open_weights: true
      'gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.00375
        cache_read_cost_per_1k: 7e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.000625
        capabilities: [audio_input, function_calling, json_mode, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2024-04'
      'google-gemma-3-27b-it':
        name: 'Google Gemma 3 27B Instruct'
        family: 'gemma-3'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.00012
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'grok-41-fast':
        name: 'Grok 4.1 Fast'
        family: 'grok'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00187
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'hermes-3-llama-3.1-405b':
        name: 'Hermes 3 Llama 3.1 405b'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.003
        capabilities: [temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00075
        output_cost_per_1k: 0.0032
        cache_read_cost_per_1k: 0.000375
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'llama-3.2-3b':
        name: 'Llama 3.2 3B'
        family: 'llama-3.2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'llama-3.3-70b':
        name: 'Llama 3.3 70B'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'minimax-m21':
        name: 'MiniMax M2.1'
        family: 'minimax'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 4e-05
        capabilities: [function_calling, json_mode, reasoning, temperature]
      'mistral-31-24b':
        name: 'Venice Medium'
        family: 'mistral'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'openai-gpt-52':
        name: 'GPT-5.2'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00219
        output_cost_per_1k: 0.0175
        cache_read_cost_per_1k: 0.000219
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2025-08-31'
      'openai-gpt-oss-120b':
        name: 'OpenAI GPT OSS 120B'
        family: 'openai-gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'qwen3-235b-a22b-instruct-2507':
        name: 'Qwen 3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00075
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'qwen3-235b-a22b-thinking-2507':
        name: 'Qwen 3 235B A22B Thinking 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00045
        output_cost_per_1k: 0.0035
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'qwen3-4b':
        name: 'Venice Small'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
      'qwen3-coder-480b-a35b-instruct':
        name: 'Qwen 3 Coder 480b'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00075
        output_cost_per_1k: 0.003
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'qwen3-next-80b':
        name: 'Qwen 3 Next 80b'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 65536
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.0019
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'venice-uncensored':
        name: 'Venice Uncensored 1.1'
        family: 'venice-uncensored'
        mode: chat
        max_input_tokens: 32768
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0009
        capabilities: [json_mode, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'zai-org-glm-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.00085
        output_cost_per_1k: 0.00275
        capabilities: [function_calling, json_mode, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'zai-org-glm-4.6v':
        name: 'GLM 4.6V'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.00039
        output_cost_per_1k: 0.00113
        capabilities: [function_calling, json_mode, temperature, vision]
        open_weights: true
      'zai-org-glm-4.7':
        name: 'GLM 4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 202752
        max_output_tokens: 50688
        input_cost_per_1k: 0.00055
        output_cost_per_1k: 0.00265
        capabilities: [function_calling, json_mode, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  vercel:
    name: 'Vercel AI Gateway'
    logo_url: 'https://models.dev/logos/vercel.svg'
    model_count: 86
    models:
      'alibaba/qwen3-coder-plus':
        name: 'Qwen3 Coder Plus'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 1000000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'alibaba/qwen3-max':
        name: 'Qwen3 Max'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 32768
        input_cost_per_1k: 0.0012
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
      'alibaba/qwen3-next-80b-a3b-instruct':
        name: 'Qwen3 Next 80B A3B Instruct'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'alibaba/qwen3-next-80b-a3b-thinking':
        name: 'Qwen3 Next 80B A3B Thinking'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.006
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'alibaba/qwen3-vl-instruct':
        name: 'Qwen3 VL Instruct'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 129024
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0028
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'alibaba/qwen3-vl-thinking':
        name: 'Qwen3 VL Thinking'
        family: 'qwen3-vl'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 129024
        input_cost_per_1k: 0.0007
        output_cost_per_1k: 0.0084
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'amazon/nova-lite':
        name: 'Nova Lite'
        family: 'nova-lite'
        mode: chat
        max_input_tokens: 300000
        max_output_tokens: 8192
        input_cost_per_1k: 6e-05
        output_cost_per_1k: 0.00024
        cache_read_cost_per_1k: 1.5e-05
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-10'
      'amazon/nova-micro':
        name: 'Nova Micro'
        family: 'nova-micro'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 3.5e-05
        output_cost_per_1k: 0.00014
        cache_read_cost_per_1k: 8.75e-06
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
      'amazon/nova-pro':
        name: 'Nova Pro'
        family: 'nova-pro'
        mode: chat
        max_input_tokens: 300000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0032
        cache_read_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature, video_input, vision]
        knowledge_cutoff: '2024-10'
      'anthropic/claude-3-haiku':
        name: 'Claude Haiku 3'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0003
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic/claude-3-opus':
        name: 'Claude Opus 3'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 4096
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2023-08-31'
      'anthropic/claude-3.5-haiku':
        name: 'Claude Haiku 3.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 8e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-07-31'
      'anthropic/claude-3.5-sonnet':
        name: 'Claude Sonnet 3.5 v2'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, temperature, vision]
        knowledge_cutoff: '2024-04-30'
      'anthropic/claude-3.7-sonnet':
        name: 'Claude Sonnet 3.7'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2024-10-31'
      'anthropic/claude-4-1-opus':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-4-opus':
        name: 'Claude Opus 4'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-4-sonnet':
        name: 'Claude Sonnet 4'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-4.5-sonnet':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'anthropic/claude-haiku-4.5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.00125
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic/claude-opus-4.5':
        name: 'Claude Opus 4.5'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'deepseek/deepseek-r1':
        name: 'DeepSeek-R1'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
      'deepseek/deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.00075
        output_cost_per_1k: 0.00099
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-07'
        open_weights: true
        deprecated: true
      'deepseek/deepseek-v3.1-terminus':
        name: 'DeepSeek V3.1 Terminus'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00027
        output_cost_per_1k: 0.001
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'deepseek/deepseek-v3.2-exp':
        name: 'DeepSeek V3.2 Exp'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 8192
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-09'
      'deepseek/deepseek-v3.2-exp-thinking':
        name: 'DeepSeek V3.2 Exp Thinking'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 8192
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
      'google/gemini-2.0-flash':
        name: 'Gemini 2.0 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'google/gemini-2.0-flash-lite':
        name: 'Gemini 2.0 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 8192
        input_cost_per_1k: 7.5e-05
        output_cost_per_1k: 0.0003
        capabilities: [audio_input, function_calling, json_mode, pdf_input, temperature, video_input, vision]
        knowledge_cutoff: '2024-06'
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-lite-preview-09-2025':
        name: 'Gemini 2.5 Flash Lite Preview 09-25'
        family: 'gemini-flash-lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 2.5e-05
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-flash-preview-09-2025':
        name: 'Gemini 2.5 Flash Preview 09-25'
        family: 'gemini-flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7.5e-05
        cache_write_cost_per_1k: 0.000383
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        capabilities: [audio_input, function_calling, json_mode, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'meta/llama-3.3-70b':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta/llama-4-maverick':
        name: 'Llama-4-Maverick-17B-128E-Instruct-FP8'
        family: 'llama-4-maverick'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'meta/llama-4-scout':
        name: 'Llama-4-Scout-17B-16E-Instruct-FP8'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
        open_weights: true
      'minimax/minimax-m2':
        name: 'MiniMax M2'
        family: 'minimax'
        mode: chat
        max_input_tokens: 205000
        max_output_tokens: 131072
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.00038
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistral/codestral':
        name: 'Codestral'
        family: 'codestral'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 4096
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistral/magistral-medium':
        name: 'Magistral Medium'
        family: 'magistral-medium'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.005
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'mistral/magistral-small':
        name: 'Magistral Small'
        family: 'magistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-06'
        open_weights: true
      'mistral/ministral-3b':
        name: 'Ministral 3B'
        family: 'ministral-3b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 4e-05
        output_cost_per_1k: 4e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistral/ministral-8b':
        name: 'Ministral 8B'
        family: 'ministral-8b'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'mistral/mistral-large':
        name: 'Mistral Large'
        family: 'mistral-large'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 262144
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'mistral/mistral-small':
        name: 'Mistral Small'
        family: 'mistral-small'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-03'
        open_weights: true
      'mistral/mixtral-8x22b-instruct':
        name: 'Mixtral 8x22B'
        family: 'mixtral-8x22b'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 64000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-04'
        open_weights: true
      'mistral/pixtral-12b':
        name: 'Pixtral 12B'
        family: 'pixtral'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-09'
        open_weights: true
      'mistral/pixtral-large':
        name: 'Pixtral Large'
        family: 'pixtral-large'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 128000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.006
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-11'
        open_weights: true
      'moonshotai/kimi-k2':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 16384
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.003
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
        deprecated: true
      'morph/morph-v3-fast':
        name: 'Morph v3 Fast'
        family: 'morph-v3-fast'
        mode: chat
        max_input_tokens: 16000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0008
        output_cost_per_1k: 0.0012
      'morph/morph-v3-large':
        name: 'Morph v3 Large'
        family: 'morph-v3-large'
        mode: chat
        max_input_tokens: 32000
        max_output_tokens: 32000
        input_cost_per_1k: 0.0009
        output_cost_per_1k: 0.0019
      'openai/gpt-4-turbo':
        name: 'GPT-4 Turbo'
        family: 'gpt-4-turbo'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 0.01
        output_cost_per_1k: 0.03
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2023-12'
      'openai/gpt-4.1':
        name: 'GPT-4.1'
        family: 'gpt-4.1'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-mini':
        name: 'GPT-4.1 mini'
        family: 'gpt-4.1-mini'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0004
        output_cost_per_1k: 0.0016
        cache_read_cost_per_1k: 0.0001
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4.1-nano':
        name: 'GPT-4.1 nano'
        family: 'gpt-4.1-nano'
        mode: chat
        max_input_tokens: 1047576
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2024-04'
      'openai/gpt-4o':
        name: 'GPT-4o'
        family: 'gpt-4o'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0025
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'openai/gpt-4o-mini':
        name: 'GPT-4o mini'
        family: 'gpt-4o-mini'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00015
        output_cost_per_1k: 0.0006
        cache_read_cost_per_1k: 8e-05
        capabilities: [function_calling, json_mode, temperature, vision]
        knowledge_cutoff: '2023-09'
      'openai/gpt-5':
        name: 'GPT-5'
        family: 'gpt-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5-codex':
        name: 'GPT-5-Codex'
        family: 'gpt-5-codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.000125
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-09-30'
      'openai/gpt-5-mini':
        name: 'GPT-5 Mini'
        family: 'gpt-5-mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'openai/gpt-5-nano':
        name: 'GPT-5 Nano'
        family: 'gpt-5-nano'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 128000
        input_cost_per_1k: 5e-05
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 1e-05
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05-30'
      'openai/gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0005
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/gpt-oss-20b':
        name: 'GPT OSS 20B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 32768
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.0003
        capabilities: [function_calling, reasoning, temperature]
        open_weights: true
      'openai/o1':
        name: 'o1'
        family: 'o1'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.06
        cache_read_cost_per_1k: 0.0075
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2023-09'
      'openai/o3':
        name: 'o3'
        family: 'o3'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.0005
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'openai/o3-mini':
        name: 'o3-mini'
        family: 'o3-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00055
        capabilities: [function_calling, json_mode, reasoning]
        knowledge_cutoff: '2024-05'
      'openai/o4-mini':
        name: 'o4-mini'
        family: 'o4-mini'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 100000
        input_cost_per_1k: 0.0011
        output_cost_per_1k: 0.0044
        cache_read_cost_per_1k: 0.00028
        capabilities: [function_calling, json_mode, reasoning, vision]
        knowledge_cutoff: '2024-05'
      'perplexity/sonar':
        name: 'Sonar'
        family: 'sonar'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 8000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.001
        capabilities: [temperature, vision]
        knowledge_cutoff: '2025-02'
      'perplexity/sonar-pro':
        name: 'Sonar Pro'
        family: 'sonar-pro'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 8000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [temperature, vision]
        knowledge_cutoff: '2025-09'
      'perplexity/sonar-reasoning':
        name: 'Sonar Reasoning'
        family: 'sonar-reasoning'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 8000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-09'
      'perplexity/sonar-reasoning-pro':
        name: 'Sonar Reasoning Pro'
        family: 'sonar-reasoning'
        mode: chat
        max_input_tokens: 127000
        max_output_tokens: 8000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.008
        capabilities: [reasoning, temperature]
        knowledge_cutoff: '2025-09'
      'vercel/v0-1.0-md':
        name: 'v0-1.0-md'
        family: 'v0'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature, vision]
      'vercel/v0-1.5-md':
        name: 'v0-1.5-md'
        family: 'v0'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        capabilities: [function_calling, reasoning, temperature, vision]
      'xai/grok-2':
        name: 'Grok 2'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'xai/grok-2-vision':
        name: 'Grok 2 Vision'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
      'xai/grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'xai/grok-3-fast':
        name: 'Grok 3 Fast'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'xai/grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'xai/grok-3-mini-fast':
        name: 'Grok 3 Mini Fast'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'xai/grok-4':
        name: 'Grok 4'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'xai/grok-4-fast':
        name: 'Grok 4 Fast'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'xai/grok-4-fast-non-reasoning':
        name: 'Grok 4 Fast (Non-Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
      'xai/grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
      'zai/glm-4.5':
        name: 'GLM 4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
        open_weights: true
      'zai/glm-4.5-air':
        name: 'GLM 4.5 Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'zai/glm-4.5v':
        name: 'GLM 4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 66000
        max_output_tokens: 16000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-08'
        open_weights: true
      'zai/glm-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 96000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  vultr:
    name: 'Vultr'
    api_endpoint: 'https://api.vultrinference.com/v1'
    logo_url: 'https://models.dev/logos/vultr.svg'
    model_count: 5
    models:
      'deepseek-r1-distill-llama-70b':
        name: 'DeepSeek R1 Distill Llama 70B'
        family: 'deepseek-r1-distill-llama'
        mode: chat
        max_input_tokens: 121808
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'deepseek-r1-distill-qwen-32b':
        name: 'DeepSeek R1 Distill Qwen 32B'
        family: 'qwen'
        mode: chat
        max_input_tokens: 121808
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'gpt-oss-120b':
        name: 'GPT OSS 120B'
        family: 'gpt-oss'
        mode: chat
        max_input_tokens: 121808
        max_output_tokens: 8192
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'kimi-k2-instruct':
        name: 'Kimi K2 Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 58904
        max_output_tokens: 4096
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'qwen2.5-coder-32b-instruct':
        name: 'Qwen2.5 Coder 32B Instruct'
        family: 'qwen2.5-coder'
        mode: chat
        max_input_tokens: 12952
        max_output_tokens: 2048
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
  wandb:
    name: 'Weights & Biases'
    api_endpoint: 'https://api.inference.wandb.ai/v1'
    logo_url: 'https://models.dev/logos/wandb.svg'
    model_count: 10
    models:
      'Qwen/Qwen3-235B-A22B-Instruct-2507':
        name: 'Qwen3 235B A22B Instruct 2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-235B-A22B-Thinking-2507':
        name: 'Qwen3-235B-A22B-Thinking-2507'
        family: 'qwen3'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 131072
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0001
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'Qwen/Qwen3-Coder-480B-A35B-Instruct':
        name: 'Qwen3-Coder-480B-A35B-Instruct'
        family: 'qwen3-coder'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 66536
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.0015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'deepseek-ai/DeepSeek-R1-0528':
        name: 'DeepSeek-R1-0528'
        family: 'deepseek-r1'
        mode: chat
        max_input_tokens: 161000
        max_output_tokens: 163840
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.0054
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-05'
        open_weights: true
      'deepseek-ai/DeepSeek-V3-0324':
        name: 'DeepSeek-V3-0324'
        family: 'deepseek-v3'
        mode: chat
        max_input_tokens: 161000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00114
        output_cost_per_1k: 0.00275
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
      'meta-llama/Llama-3.1-8B-Instruct':
        name: 'Meta-Llama-3.1-8B-Instruct'
        family: 'llama-3.1'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00022
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/Llama-3.3-70B-Instruct':
        name: 'Llama-3.3-70B-Instruct'
        family: 'llama-3.3'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.00071
        output_cost_per_1k: 0.00071
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-12'
        open_weights: true
      'meta-llama/Llama-4-Scout-17B-16E-Instruct':
        name: 'Llama 4 Scout 17B 16E Instruct'
        family: 'llama-4-scout'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 8192
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00066
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2024-12'
        open_weights: true
      'microsoft/Phi-4-mini-instruct':
        name: 'Phi-4-mini-instruct'
        family: 'phi-4'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 4096
        input_cost_per_1k: 8e-05
        output_cost_per_1k: 0.00035
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
        open_weights: true
      'moonshotai/Kimi-K2-Instruct':
        name: 'Kimi-K2-Instruct'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 16384
        input_cost_per_1k: 0.00135
        output_cost_per_1k: 0.004
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-10'
        open_weights: true
  xai:
    name: 'xAI'
    api_endpoint: 'https://api.x.ai/v1'
    logo_url: 'https://models.dev/logos/xai.svg'
    model_count: 22
    models:
      'grok-2':
        name: 'Grok 2'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'grok-2-1212':
        name: 'Grok 2 (1212)'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'grok-2-latest':
        name: 'Grok 2 Latest'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'grok-2-vision':
        name: 'Grok 2 Vision'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
      'grok-2-vision-1212':
        name: 'Grok 2 Vision (1212)'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
      'grok-2-vision-latest':
        name: 'Grok 2 Vision Latest'
        family: 'grok-2'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.002
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
      'grok-3':
        name: 'Grok 3'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-fast':
        name: 'Grok 3 Fast'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-fast-latest':
        name: 'Grok 3 Fast Latest'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-latest':
        name: 'Grok 3 Latest'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini':
        name: 'Grok 3 Mini'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini-fast':
        name: 'Grok 3 Mini Fast'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini-fast-latest':
        name: 'Grok 3 Mini Fast Latest'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.004
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-3-mini-latest':
        name: 'Grok 3 Mini Latest'
        family: 'grok-3'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 8192
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 7.5e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-11'
      'grok-4':
        name: 'Grok 4'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-07'
      'grok-4-1-fast':
        name: 'Grok 4.1 Fast'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-4-1-fast-non-reasoning':
        name: 'Grok 4.1 Fast (Non-Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-4-fast':
        name: 'Grok 4 Fast'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-4-fast-non-reasoning':
        name: 'Grok 4 Fast (Non-Reasoning)'
        family: 'grok'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 30000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-07'
      'grok-beta':
        name: 'Grok Beta'
        family: 'grok-beta'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 4096
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.005
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2024-08'
      'grok-code-fast-1':
        name: 'Grok Code Fast 1'
        family: 'grok'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 10000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2023-10'
      'grok-vision-beta':
        name: 'Grok Vision Beta'
        family: 'grok-vision'
        mode: chat
        max_input_tokens: 8192
        max_output_tokens: 4096
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.005
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2024-08'
  xiaomi:
    name: 'Xiaomi'
    api_endpoint: 'https://api.xiaomimimo.com/v1'
    logo_url: 'https://models.dev/logos/xiaomi.svg'
    model_count: 1
    models:
      'mimo-v2-flash':
        name: 'MiMo-V2-Flash'
        family: 'mimo-v2-flash'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 32000
        input_cost_per_1k: 7e-05
        output_cost_per_1k: 0.00021
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2024-12-01'
        open_weights: true
  zai:
    name: 'Z.AI'
    api_endpoint: 'https://api.z.ai/api/paas/v4'
    logo_url: 'https://models.dev/logos/zai.svg'
    model_count: 7
    models:
      'glm-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-air':
        name: 'GLM-4.5-Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0011
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-flash':
        name: 'GLM-4.5-Flash'
        family: 'glm-4.5-flash'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5v':
        name: 'GLM-4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v':
        name: 'GLM-4.6V'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  zai_coding_plan:
    name: 'Z.AI Coding Plan'
    api_endpoint: 'https://api.z.ai/api/coding/paas/v4'
    logo_url: 'https://models.dev/logos/zai-coding-plan.svg'
    model_count: 7
    models:
      'glm-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-air':
        name: 'GLM-4.5-Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-flash':
        name: 'GLM-4.5-Flash'
        family: 'glm-4.5-flash'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5v':
        name: 'GLM-4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v':
        name: 'GLM-4.6V'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  zenmux:
    name: 'ZenMux'
    api_endpoint: 'https://zenmux.ai/api/v1'
    logo_url: 'https://models.dev/logos/zenmux.svg'
    model_count: 51
    models:
      'anthropic/claude-haiku-4.5':
        name: 'Claude Haiku 4.5'
        family: 'claude-haiku'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-02-28'
      'anthropic/claude-opus-4':
        name: 'Claude Opus 4'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'anthropic/claude-opus-4.1':
        name: 'Claude Opus 4.1'
        family: 'claude-opus'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 32000
        input_cost_per_1k: 0.015
        output_cost_per_1k: 0.075
        cache_read_cost_per_1k: 0.0015
        cache_write_cost_per_1k: 0.01875
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-03-31'
      'anthropic/claude-opus-4.5':
        name: 'Claude Opus 4.5'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.005
        output_cost_per_1k: 0.025
        cache_read_cost_per_1k: 0.0005
        cache_write_cost_per_1k: 0.00625
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'anthropic/claude-sonnet-4':
        name: 'Claude Sonnet 4'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'anthropic/claude-sonnet-4.5':
        name: 'Claude Sonnet 4.5'
        family: 'claude-sonnet'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.0003
        cache_write_cost_per_1k: 0.00375
        capabilities: [function_calling, pdf_input, reasoning, temperature, vision]
        knowledge_cutoff: '2025-07-31'
      'baidu/ernie-5.0-thinking-preview':
        name: 'ERNIE-5.0-Thinking-Preview'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00084
        output_cost_per_1k: 0.00337
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01-01'
      'deepseek/deepseek-chat':
        name: 'DeepSeek-V3.2 (Non-thinking Mode)'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'deepseek/deepseek-reasoner':
        name: 'DeepSeek-V3.2 (Thinking Mode)'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'deepseek/deepseek-v3.2':
        name: 'DeepSeek V3.2'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00043
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'deepseek/deepseek-v3.2-exp':
        name: 'DeepSeek-V3.2-Exp'
        mode: chat
        max_input_tokens: 163840
        max_output_tokens: 64000
        input_cost_per_1k: 0.00022
        output_cost_per_1k: 0.00033
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'google/gemini-2.5-flash':
        name: 'Gemini 2.5 Flash'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 7e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'google/gemini-2.5-flash-lite':
        name: 'Gemini 2.5 Flash Lite'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.0001
        output_cost_per_1k: 0.0004
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [audio_input, function_calling, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'google/gemini-2.5-pro':
        name: 'Gemini 2.5 Pro'
        family: 'gemini-pro'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 65536
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00031
        cache_write_cost_per_1k: 0.0045
        capabilities: [audio_input, function_calling, pdf_input, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01'
      'google/gemini-3-flash-preview':
        name: 'Gemini 3 Flash Preview'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.0005
        output_cost_per_1k: 0.003
        cache_read_cost_per_1k: 5e-05
        cache_write_cost_per_1k: 0.001
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'google/gemini-3-flash-preview-free':
        name: 'Gemini 3 Flash Preview Free'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [audio_input, function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'google/gemini-3-pro-preview':
        name: 'Gemini 3 Pro Preview'
        mode: chat
        max_input_tokens: 1048576
        max_output_tokens: 64000
        input_cost_per_1k: 0.002
        output_cost_per_1k: 0.012
        cache_read_cost_per_1k: 0.0002
        cache_write_cost_per_1k: 0.0045
        capabilities: [audio_input, function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01-01'
      'inclusionai/ling-1t':
        name: 'Ling-1T'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00224
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'inclusionai/ring-1t':
        name: 'Ring-1T'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00056
        output_cost_per_1k: 0.00224
        cache_read_cost_per_1k: 0.00011
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'kuaishou/kat-coder-pro-v1':
        name: 'KAT-Coder-Pro-V1'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'kuaishou/kat-coder-pro-v1-free':
        name: 'KAT-Coder-Pro-V1 Free'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'minimax/minimax-m2':
        name: 'MiniMax M2'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 64000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'minimax/minimax-m2.1':
        name: 'MiniMax M2.1'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 64000
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0012
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'moonshotai/kimi-k2-0905':
        name: 'Kimi K2 0905'
        mode: chat
        max_input_tokens: 262100
        max_output_tokens: 64000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'moonshotai/kimi-k2-thinking':
        name: 'Kimi K2 Thinking'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 64000
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0025
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'moonshotai/kimi-k2-thinking-turbo':
        name: 'Kimi K2 Thinking Turbo'
        family: 'kimi-k2'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 64000
        input_cost_per_1k: 0.00115
        output_cost_per_1k: 0.008
        cache_read_cost_per_1k: 0.00015
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5':
        name: 'GPT-5'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5-codex':
        name: 'GPT-5 Codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5.1':
        name: 'GPT-5.1'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5.1-chat':
        name: 'GPT-5.1 Chat'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5.1-codex':
        name: 'GPT-5.1-Codex'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00125
        output_cost_per_1k: 0.01
        cache_read_cost_per_1k: 0.00013
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5.1-codex-mini':
        name: 'GPT-5.1-Codex-Mini'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00025
        output_cost_per_1k: 0.002
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'openai/gpt-5.2':
        name: 'GPT-5.2'
        mode: chat
        max_input_tokens: 400000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00175
        output_cost_per_1k: 0.014
        cache_read_cost_per_1k: 0.00017
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'qwen/qwen3-coder-plus':
        name: 'Qwen3-Coder-Plus'
        mode: chat
        max_input_tokens: 1000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.001
        output_cost_per_1k: 0.005
        cache_read_cost_per_1k: 0.0001
        cache_write_cost_per_1k: 0.00125
        capabilities: [function_calling, temperature]
        knowledge_cutoff: '2025-01-01'
      'stepfun/step-3':
        name: 'Step-3'
        mode: chat
        max_input_tokens: 65536
        max_output_tokens: 64000
        input_cost_per_1k: 0.00021
        output_cost_per_1k: 0.00057
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'volcengine/doubao-seed-1.8':
        name: 'Doubao-Seed-1.8'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00028
        cache_read_cost_per_1k: 2e-05
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'volcengine/doubao-seed-code':
        name: 'Doubao-Seed-Code'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00017
        output_cost_per_1k: 0.00112
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'x-ai/grok-4':
        name: 'Grok 4'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.003
        output_cost_per_1k: 0.015
        cache_read_cost_per_1k: 0.00075
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'x-ai/grok-4-fast':
        name: 'Grok 4 Fast'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'x-ai/grok-4.1-fast':
        name: 'Grok 4.1 Fast'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, reasoning, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'x-ai/grok-4.1-fast-non-reasoning':
        name: 'Grok 4.1 Fast Non Reasoning'
        mode: chat
        max_input_tokens: 2000000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0005
        cache_read_cost_per_1k: 5e-05
        capabilities: [function_calling, temperature, vision]
        knowledge_cutoff: '2025-01-01'
      'x-ai/grok-code-fast-1':
        name: 'Grok Code Fast 1'
        mode: chat
        max_input_tokens: 256000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0015
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'xiaomi/mimo-v2-flash':
        name: 'MiMo-V2-Flash'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'xiaomi/mimo-v2-flash-free':
        name: 'MiMo-V2-Flash Free'
        mode: chat
        max_input_tokens: 262144
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.5':
        name: 'GLM 4.5'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00154
        cache_read_cost_per_1k: 7e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.5-air':
        name: 'GLM 4.5 Air'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00011
        output_cost_per_1k: 0.00056
        cache_read_cost_per_1k: 2e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.6':
        name: 'GLM 4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 128000
        input_cost_per_1k: 0.00035
        output_cost_per_1k: 0.00154
        cache_read_cost_per_1k: 7e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-09'
        open_weights: true
      'z-ai/glm-4.6v':
        name: 'GLM 4.6V'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00014
        output_cost_per_1k: 0.00042
        cache_read_cost_per_1k: 3e-05
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.6v-flash':
        name: 'GLM 4.6V FlashX'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.6v-flash-free':
        name: 'GLM 4.6V Flash (Free)'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-01-01'
      'z-ai/glm-4.7':
        name: 'GLM 4.7'
        mode: chat
        max_input_tokens: 200000
        max_output_tokens: 64000
        input_cost_per_1k: 0.00028
        output_cost_per_1k: 0.00114
        cache_read_cost_per_1k: 6e-05
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-01-01'
  zhipuai:
    name: 'Zhipu AI'
    api_endpoint: 'https://open.bigmodel.cn/api/paas/v4'
    logo_url: 'https://models.dev/logos/zhipuai.svg'
    model_count: 8
    models:
      'glm-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-air':
        name: 'GLM-4.5-Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0002
        output_cost_per_1k: 0.0011
        cache_read_cost_per_1k: 3e-05
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-flash':
        name: 'GLM-4.5-Flash'
        family: 'glm-4.5-flash'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5v':
        name: 'GLM-4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0018
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v':
        name: 'GLM-4.6V'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0003
        output_cost_per_1k: 0.0009
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v-flash':
        name: 'GLM-4.6V-Flash'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0006
        output_cost_per_1k: 0.0022
        cache_read_cost_per_1k: 0.00011
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
  zhipuai_coding_plan:
    name: 'Zhipu AI Coding Plan'
    api_endpoint: 'https://open.bigmodel.cn/api/coding/paas/v4'
    logo_url: 'https://models.dev/logos/zhipuai-coding-plan.svg'
    model_count: 8
    models:
      'glm-4.5':
        name: 'GLM-4.5'
        family: 'glm-4.5'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-air':
        name: 'GLM-4.5-Air'
        family: 'glm-4.5-air'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5-flash':
        name: 'GLM-4.5-Flash'
        family: 'glm-4.5-flash'
        mode: chat
        max_input_tokens: 131072
        max_output_tokens: 98304
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.5v':
        name: 'GLM-4.5V'
        family: 'glm-4.5v'
        mode: chat
        max_input_tokens: 64000
        max_output_tokens: 16384
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6':
        name: 'GLM-4.6'
        family: 'glm-4.6'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v':
        name: 'GLM-4.6V'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.6v-flash':
        name: 'GLM-4.6V-Flash'
        family: 'glm-4.6v'
        mode: chat
        max_input_tokens: 128000
        max_output_tokens: 32768
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature, video_input, vision]
        knowledge_cutoff: '2025-04'
        open_weights: true
      'glm-4.7':
        name: 'GLM-4.7'
        family: 'glm-4.7'
        mode: chat
        max_input_tokens: 204800
        max_output_tokens: 131072
        input_cost_per_1k: 0.0
        output_cost_per_1k: 0.0
        cache_read_cost_per_1k: 0.0
        cache_write_cost_per_1k: 0.0
        capabilities: [function_calling, reasoning, temperature]
        knowledge_cutoff: '2025-04'
        open_weights: true
