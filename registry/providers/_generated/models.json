{
  "version": "0.1",
  "generated_at": "2026-01-06T20:38:56.700045+00:00",
  "source": "models.dev",
  "source_url": "https://models.dev/api.json",
  "logos_url": "https://models.dev/logos",
  "stats": {
    "total_models": 2028,
    "providers": 75,
    "api_formats": 5
  },
  "providers": {
    "abacus": {
      "name": "Abacus",
      "api_endpoint": "https://routellm.abacus.ai/v1/chat/completions",
      "api_format": "openai",
      "documentation": "https://abacus.ai/help/api",
      "env_vars": [
        "ABACUS_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/abacus.svg",
      "model_count": 52,
      "models": [
        "Qwen-QwQ-32B",
        "Qwen-Qwen2.5-72B-Instruct",
        "Qwen-Qwen3-235B-A22B-Instruct-2507",
        "Qwen-Qwen3-32B",
        "claude-3-7-sonnet-20250219",
        "claude-haiku-4-5-20251001",
        "claude-opus-4-1-20250805",
        "claude-opus-4-20250514",
        "claude-opus-4-5-20251101",
        "claude-sonnet-4-20250514",
        "claude-sonnet-4-5-20250929",
        "deepseek-ai-DeepSeek-R1",
        "deepseek-ai-DeepSeek-V3.1-Terminus",
        "deepseek-ai-DeepSeek-V3.2",
        "deepseek-deepseek-v3.1",
        "gemini-2.0-flash-001",
        "gemini-2.0-pro-exp-02-05",
        "gemini-2.5-flash",
        "gemini-2.5-pro",
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-5",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5.1",
        "gpt-5.1-chat-latest",
        "gpt-5.2",
        "grok-4-0709",
        "grok-4-1-fast-non-reasoning",
        "grok-4-fast-non-reasoning",
        "grok-code-fast-1",
        "kimi-k2-turbo-preview",
        "llama-3.3-70b-versatile",
        "meta-llama-Llama-4-Maverick-17B-128E-Instruct-FP8",
        "meta-llama-Meta-Llama-3.1-405B-Instruct-Turbo",
        "meta-llama-Meta-Llama-3.1-70B-Instruct",
        "meta-llama-Meta-Llama-3.1-8B-Instruct",
        "o3",
        "o3-mini",
        "o3-pro",
        "o4-mini",
        "openai-gpt-oss-120b",
        "qwen-2.5-coder-32b",
        "qwen-qwen3-Max",
        "qwen-qwen3-coder-480b-a35b-instruct",
        "zai-org-glm-4.5",
        "zai-org-glm-4.6"
      ]
    },
    "aihubmix": {
      "name": "AIHubMix",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://docs.aihubmix.com",
      "env_vars": [
        "AIHUBMIX_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/aihubmix.svg",
      "model_count": 33,
      "models": [
        "Kimi-K2-0905",
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-opus-4-5",
        "claude-sonnet-4-5",
        "coding-glm-4.7-free",
        "deepseek-v3.2",
        "deepseek-v3.2-think",
        "gemini-2.5-flash",
        "gemini-2.5-pro",
        "gemini-3-pro-preview",
        "glm-4.7",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-4o",
        "gpt-4o-2024-11-20",
        "gpt-5",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "minimax-m2.1",
        "minimax-m2.1-free",
        "o4-mini",
        "qwen3-235b-a22b-instruct-2507",
        "qwen3-235b-a22b-thinking-2507",
        "qwen3-coder-480b-a35b-instruct"
      ]
    },
    "alibaba": {
      "name": "Alibaba",
      "api_endpoint": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
      "api_format": "openai",
      "documentation": "https://www.alibabacloud.com/help/en/model-studio/models",
      "env_vars": [
        "DASHSCOPE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/alibaba.svg",
      "model_count": 39,
      "models": [
        "qvq-max",
        "qwen-flash",
        "qwen-max",
        "qwen-mt-plus",
        "qwen-mt-turbo",
        "qwen-omni-turbo",
        "qwen-omni-turbo-realtime",
        "qwen-plus",
        "qwen-plus-character-ja",
        "qwen-turbo",
        "qwen-vl-max",
        "qwen-vl-ocr",
        "qwen-vl-plus",
        "qwen2-5-14b-instruct",
        "qwen2-5-32b-instruct",
        "qwen2-5-72b-instruct",
        "qwen2-5-7b-instruct",
        "qwen2-5-omni-7b",
        "qwen2-5-vl-72b-instruct",
        "qwen2-5-vl-7b-instruct",
        "qwen3-14b",
        "qwen3-235b-a22b",
        "qwen3-32b",
        "qwen3-8b",
        "qwen3-asr-flash",
        "qwen3-coder-30b-a3b-instruct",
        "qwen3-coder-480b-a35b-instruct",
        "qwen3-coder-flash",
        "qwen3-coder-plus",
        "qwen3-livetranslate-flash-realtime",
        "qwen3-max",
        "qwen3-next-80b-a3b-instruct",
        "qwen3-next-80b-a3b-thinking",
        "qwen3-omni-flash",
        "qwen3-omni-flash-realtime",
        "qwen3-vl-235b-a22b",
        "qwen3-vl-30b-a3b",
        "qwen3-vl-plus",
        "qwq-plus"
      ]
    },
    "alibaba_cn": {
      "name": "Alibaba (China)",
      "api_endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1",
      "api_format": "openai",
      "documentation": "https://www.alibabacloud.com/help/en/model-studio/models",
      "env_vars": [
        "DASHSCOPE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/alibaba-cn.svg",
      "model_count": 61,
      "models": [
        "deepseek-r1",
        "deepseek-r1-0528",
        "deepseek-r1-distill-llama-70b",
        "deepseek-r1-distill-llama-8b",
        "deepseek-r1-distill-qwen-1-5b",
        "deepseek-r1-distill-qwen-14b",
        "deepseek-r1-distill-qwen-32b",
        "deepseek-r1-distill-qwen-7b",
        "deepseek-v3",
        "deepseek-v3-1",
        "deepseek-v3-2-exp",
        "moonshot-kimi-k2-instruct",
        "qvq-max",
        "qwen-deep-research",
        "qwen-doc-turbo",
        "qwen-flash",
        "qwen-long",
        "qwen-math-plus",
        "qwen-math-turbo",
        "qwen-max",
        "qwen-mt-plus",
        "qwen-mt-turbo",
        "qwen-omni-turbo",
        "qwen-omni-turbo-realtime",
        "qwen-plus",
        "qwen-plus-character",
        "qwen-turbo",
        "qwen-vl-max",
        "qwen-vl-ocr",
        "qwen-vl-plus",
        "qwen2-5-14b-instruct",
        "qwen2-5-32b-instruct",
        "qwen2-5-72b-instruct",
        "qwen2-5-7b-instruct",
        "qwen2-5-coder-32b-instruct",
        "qwen2-5-coder-7b-instruct",
        "qwen2-5-math-72b-instruct",
        "qwen2-5-math-7b-instruct",
        "qwen2-5-omni-7b",
        "qwen2-5-vl-72b-instruct",
        "qwen2-5-vl-7b-instruct",
        "qwen3-14b",
        "qwen3-235b-a22b",
        "qwen3-32b",
        "qwen3-8b",
        "qwen3-asr-flash",
        "qwen3-coder-30b-a3b-instruct",
        "qwen3-coder-480b-a35b-instruct",
        "qwen3-coder-flash",
        "qwen3-coder-plus",
        "qwen3-max",
        "qwen3-next-80b-a3b-instruct",
        "qwen3-next-80b-a3b-thinking",
        "qwen3-omni-flash",
        "qwen3-omni-flash-realtime",
        "qwen3-vl-235b-a22b",
        "qwen3-vl-30b-a3b",
        "qwen3-vl-plus",
        "qwq-32b",
        "qwq-plus",
        "tongyi-intent-detect-v3"
      ]
    },
    "anthropic": {
      "name": "Anthropic",
      "api_endpoint": "https://api.anthropic.com/v1",
      "api_format": "anthropic",
      "documentation": "https://docs.anthropic.com/en/docs/about-claude/models",
      "env_vars": [
        "ANTHROPIC_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/anthropic.svg",
      "model_count": 21,
      "models": [
        "claude-3-5-haiku-20241022",
        "claude-3-5-haiku-latest",
        "claude-3-5-sonnet-20240620",
        "claude-3-5-sonnet-20241022",
        "claude-3-7-sonnet-20250219",
        "claude-3-7-sonnet-latest",
        "claude-3-haiku-20240307",
        "claude-3-opus-20240229",
        "claude-3-sonnet-20240229",
        "claude-haiku-4-5",
        "claude-haiku-4-5-20251001",
        "claude-opus-4-0",
        "claude-opus-4-1",
        "claude-opus-4-1-20250805",
        "claude-opus-4-20250514",
        "claude-opus-4-5",
        "claude-opus-4-5-20251101",
        "claude-sonnet-4-0",
        "claude-sonnet-4-20250514",
        "claude-sonnet-4-5",
        "claude-sonnet-4-5-20250929"
      ]
    },
    "aws_bedrock": {
      "name": "Amazon Bedrock",
      "api_endpoint": "https://bedrock-runtime.*.amazonaws.com",
      "api_format": "bedrock",
      "documentation": "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html",
      "env_vars": [
        "AWS_ACCESS_KEY_ID",
        "AWS_SECRET_ACCESS_KEY",
        "AWS_REGION"
      ],
      "logo_url": "https://models.dev/logos/amazon-bedrock.svg",
      "model_count": 67,
      "models": [
        "ai21.jamba-1-5-large-v1:0",
        "ai21.jamba-1-5-mini-v1:0",
        "amazon.nova-2-lite-v1:0",
        "amazon.nova-lite-v1:0",
        "amazon.nova-micro-v1:0",
        "amazon.nova-premier-v1:0",
        "amazon.nova-pro-v1:0",
        "amazon.titan-text-express-v1",
        "amazon.titan-text-express-v1:0:8k",
        "anthropic.claude-3-5-haiku-20241022-v1:0",
        "anthropic.claude-3-5-sonnet-20240620-v1:0",
        "anthropic.claude-3-5-sonnet-20241022-v2:0",
        "anthropic.claude-3-7-sonnet-20250219-v1:0",
        "anthropic.claude-3-haiku-20240307-v1:0",
        "anthropic.claude-3-opus-20240229-v1:0",
        "anthropic.claude-3-sonnet-20240229-v1:0",
        "anthropic.claude-haiku-4-5-20251001-v1:0",
        "anthropic.claude-instant-v1",
        "anthropic.claude-opus-4-1-20250805-v1:0",
        "anthropic.claude-opus-4-20250514-v1:0",
        "anthropic.claude-opus-4-5-20251101-v1:0",
        "anthropic.claude-sonnet-4-20250514-v1:0",
        "anthropic.claude-sonnet-4-5-20250929-v1:0",
        "anthropic.claude-v2",
        "anthropic.claude-v2:1",
        "cohere.command-light-text-v14",
        "cohere.command-r-plus-v1:0",
        "cohere.command-r-v1:0",
        "cohere.command-text-v14",
        "deepseek.r1-v1:0",
        "deepseek.v3-v1:0",
        "global.anthropic.claude-opus-4-5-20251101-v1:0",
        "google.gemma-3-12b-it",
        "google.gemma-3-27b-it",
        "google.gemma-3-4b-it",
        "meta.llama3-1-70b-instruct-v1:0",
        "meta.llama3-1-8b-instruct-v1:0",
        "meta.llama3-2-11b-instruct-v1:0",
        "meta.llama3-2-1b-instruct-v1:0",
        "meta.llama3-2-3b-instruct-v1:0",
        "meta.llama3-2-90b-instruct-v1:0",
        "meta.llama3-3-70b-instruct-v1:0",
        "meta.llama3-70b-instruct-v1:0",
        "meta.llama3-8b-instruct-v1:0",
        "meta.llama4-maverick-17b-instruct-v1:0",
        "meta.llama4-scout-17b-instruct-v1:0",
        "minimax.minimax-m2",
        "mistral.ministral-3-14b-instruct",
        "mistral.ministral-3-8b-instruct",
        "mistral.mistral-7b-instruct-v0:2",
        "mistral.mistral-large-2402-v1:0",
        "mistral.mixtral-8x7b-instruct-v0:1",
        "mistral.voxtral-mini-3b-2507",
        "mistral.voxtral-small-24b-2507",
        "moonshot.kimi-k2-thinking",
        "nvidia.nemotron-nano-12b-v2",
        "nvidia.nemotron-nano-9b-v2",
        "openai.gpt-oss-120b-1:0",
        "openai.gpt-oss-20b-1:0",
        "openai.gpt-oss-safeguard-120b",
        "openai.gpt-oss-safeguard-20b",
        "qwen.qwen3-235b-a22b-2507-v1:0",
        "qwen.qwen3-32b-v1:0",
        "qwen.qwen3-coder-30b-a3b-v1:0",
        "qwen.qwen3-coder-480b-a35b-v1:0",
        "qwen.qwen3-next-80b-a3b",
        "qwen.qwen3-vl-235b-a22b"
      ]
    },
    "azure_cognitive_services": {
      "name": "Azure Cognitive Services",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
      "env_vars": [
        "AZURE_COGNITIVE_SERVICES_RESOURCE_NAME",
        "AZURE_COGNITIVE_SERVICES_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/azure-cognitive-services.svg",
      "model_count": 90,
      "models": [
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-opus-4-5",
        "claude-sonnet-4-5",
        "codestral-2501",
        "codex-mini",
        "cohere-command-a",
        "cohere-command-r-08-2024",
        "cohere-command-r-plus-08-2024",
        "cohere-embed-v-4-0",
        "cohere-embed-v3-english",
        "cohere-embed-v3-multilingual",
        "deepseek-r1",
        "deepseek-r1-0528",
        "deepseek-v3-0324",
        "deepseek-v3.1",
        "deepseek-v3.2",
        "deepseek-v3.2-speciale",
        "gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-0301",
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo-instruct",
        "gpt-4",
        "gpt-4-32k",
        "gpt-4-turbo",
        "gpt-4-turbo-vision",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-5",
        "gpt-5-chat",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-chat",
        "gpt-5.1-codex",
        "gpt-5.1-codex-mini",
        "gpt-5.2-chat",
        "grok-3",
        "grok-3-mini",
        "grok-4",
        "grok-4-fast-non-reasoning",
        "grok-4-fast-reasoning",
        "grok-code-fast-1",
        "kimi-k2-thinking",
        "llama-3.2-11b-vision-instruct",
        "llama-3.2-90b-vision-instruct",
        "llama-3.3-70b-instruct",
        "llama-4-maverick-17b-128e-instruct-fp8",
        "llama-4-scout-17b-16e-instruct",
        "mai-ds-r1",
        "meta-llama-3-70b-instruct",
        "meta-llama-3-8b-instruct",
        "meta-llama-3.1-405b-instruct",
        "meta-llama-3.1-70b-instruct",
        "meta-llama-3.1-8b-instruct",
        "ministral-3b",
        "mistral-large-2411",
        "mistral-medium-2505",
        "mistral-nemo",
        "mistral-small-2503",
        "model-router",
        "o1",
        "o1-mini",
        "o1-preview",
        "o3",
        "o3-mini",
        "o4-mini",
        "phi-3-medium-128k-instruct",
        "phi-3-medium-4k-instruct",
        "phi-3-mini-128k-instruct",
        "phi-3-mini-4k-instruct",
        "phi-3-small-128k-instruct",
        "phi-3-small-8k-instruct",
        "phi-3.5-mini-instruct",
        "phi-3.5-moe-instruct",
        "phi-4",
        "phi-4-mini",
        "phi-4-mini-reasoning",
        "phi-4-multimodal",
        "phi-4-reasoning",
        "phi-4-reasoning-plus",
        "text-embedding-3-large",
        "text-embedding-3-small",
        "text-embedding-ada-002"
      ]
    },
    "azure_openai": {
      "name": "Azure",
      "api_endpoint": "https://*.openai.azure.com/openai",
      "api_format": "openai",
      "documentation": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
      "env_vars": [
        "AZURE_RESOURCE_NAME",
        "AZURE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/azure.svg",
      "model_count": 92,
      "models": [
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-opus-4-5",
        "claude-sonnet-4-5",
        "codestral-2501",
        "codex-mini",
        "cohere-command-a",
        "cohere-command-r-08-2024",
        "cohere-command-r-plus-08-2024",
        "cohere-embed-v-4-0",
        "cohere-embed-v3-english",
        "cohere-embed-v3-multilingual",
        "deepseek-r1",
        "deepseek-r1-0528",
        "deepseek-v3-0324",
        "deepseek-v3.1",
        "deepseek-v3.2",
        "deepseek-v3.2-speciale",
        "gpt-3.5-turbo-0125",
        "gpt-3.5-turbo-0301",
        "gpt-3.5-turbo-0613",
        "gpt-3.5-turbo-1106",
        "gpt-3.5-turbo-instruct",
        "gpt-4",
        "gpt-4-32k",
        "gpt-4-turbo",
        "gpt-4-turbo-vision",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-5",
        "gpt-5-chat",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-chat",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "gpt-5.2-chat",
        "grok-3",
        "grok-3-mini",
        "grok-4",
        "grok-4-fast-non-reasoning",
        "grok-4-fast-reasoning",
        "grok-code-fast-1",
        "kimi-k2-thinking",
        "llama-3.2-11b-vision-instruct",
        "llama-3.2-90b-vision-instruct",
        "llama-3.3-70b-instruct",
        "llama-4-maverick-17b-128e-instruct-fp8",
        "llama-4-scout-17b-16e-instruct",
        "mai-ds-r1",
        "meta-llama-3-70b-instruct",
        "meta-llama-3-8b-instruct",
        "meta-llama-3.1-405b-instruct",
        "meta-llama-3.1-70b-instruct",
        "meta-llama-3.1-8b-instruct",
        "ministral-3b",
        "mistral-large-2411",
        "mistral-medium-2505",
        "mistral-nemo",
        "mistral-small-2503",
        "model-router",
        "o1",
        "o1-mini",
        "o1-preview",
        "o3",
        "o3-mini",
        "o4-mini",
        "phi-3-medium-128k-instruct",
        "phi-3-medium-4k-instruct",
        "phi-3-mini-128k-instruct",
        "phi-3-mini-4k-instruct",
        "phi-3-small-128k-instruct",
        "phi-3-small-8k-instruct",
        "phi-3.5-mini-instruct",
        "phi-3.5-moe-instruct",
        "phi-4",
        "phi-4-mini",
        "phi-4-mini-reasoning",
        "phi-4-multimodal",
        "phi-4-reasoning",
        "phi-4-reasoning-plus",
        "text-embedding-3-large",
        "text-embedding-3-small",
        "text-embedding-ada-002"
      ]
    },
    "bailing": {
      "name": "Bailing",
      "api_endpoint": "https://api.tbox.cn/api/llm/v1/chat/completions",
      "api_format": "openai",
      "documentation": "https://alipaytbox.yuque.com/sxs0ba/ling/intro",
      "env_vars": [
        "BAILING_API_TOKEN"
      ],
      "logo_url": "https://models.dev/logos/bailing.svg",
      "model_count": 2,
      "models": [
        "Ling-1T",
        "Ring-1T"
      ]
    },
    "baseten": {
      "name": "Baseten",
      "api_endpoint": "https://inference.baseten.co/v1",
      "api_format": "openai",
      "documentation": "https://docs.baseten.co/development/model-apis/overview",
      "env_vars": [
        "BASETEN_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/baseten.svg",
      "model_count": 6,
      "models": [
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "deepseek-ai/DeepSeek-V3.2",
        "moonshotai/Kimi-K2-Instruct-0905",
        "moonshotai/Kimi-K2-Thinking",
        "zai-org/GLM-4.6",
        "zai-org/GLM-4.7"
      ]
    },
    "cerebras": {
      "name": "Cerebras",
      "api_endpoint": "https://api.cerebras.ai/v1",
      "api_format": "openai",
      "documentation": "https://inference-docs.cerebras.ai/models/overview",
      "env_vars": [
        "CEREBRAS_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/cerebras.svg",
      "model_count": 3,
      "models": [
        "gpt-oss-120b",
        "qwen-3-235b-a22b-instruct-2507",
        "zai-glm-4.6"
      ]
    },
    "chutes": {
      "name": "Chutes",
      "api_endpoint": "https://llm.chutes.ai/v1",
      "api_format": "openai",
      "documentation": "https://llm.chutes.ai/v1/models",
      "env_vars": [
        "CHUTES_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/chutes.svg",
      "model_count": 62,
      "models": [
        "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
        "ArliAI/QwQ-32B-ArliAI-RpR-v1",
        "MiniMaxAI/MiniMax-M2",
        "MiniMaxAI/MiniMax-M2.1-TEE",
        "NousResearch/DeepHermes-3-Mistral-24B-Preview",
        "NousResearch/Hermes-4-14B",
        "NousResearch/Hermes-4-405B-FP8",
        "NousResearch/Hermes-4-405B-FP8-TEE",
        "NousResearch/Hermes-4-70B",
        "NousResearch/Hermes-4.3-36B",
        "OpenGVLab/InternVL3-78B",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct-TEE",
        "Qwen/Qwen3-14B",
        "Qwen/Qwen3-235B-A22B",
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "Qwen/Qwen3-32B",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-VL-235B-A22B-Instruct",
        "Qwen/Qwen3-VL-235B-A22B-Thinking",
        "Qwen/Qwen3Guard-Gen-0.6B",
        "XiaomiMiMo/MiMo-V2-Flash",
        "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
        "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
        "deepseek-ai/DeepSeek-R1-0528-TEE",
        "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
        "deepseek-ai/DeepSeek-R1-TEE",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3-0324-TEE",
        "deepseek-ai/DeepSeek-V3.1",
        "deepseek-ai/DeepSeek-V3.1-TEE",
        "deepseek-ai/DeepSeek-V3.1-Terminus-TEE",
        "deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
        "deepseek-ai/DeepSeek-V3.2-TEE",
        "mistralai/Devstral-2-123B-Instruct-2512",
        "moonshotai/Kimi-K2-Instruct-0905",
        "moonshotai/Kimi-K2-Thinking-TEE",
        "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
        "openai/gpt-oss-120b-TEE",
        "openai/gpt-oss-20b",
        "rednote-hilab/dots.ocr",
        "tngtech/DeepSeek-R1T-Chimera",
        "tngtech/DeepSeek-TNG-R1T2-Chimera",
        "tngtech/TNG-R1T-Chimera-TEE",
        "unsloth/Mistral-Nemo-Instruct-2407",
        "unsloth/Mistral-Small-24B-Instruct-2501",
        "unsloth/gemma-3-12b-it",
        "unsloth/gemma-3-27b-it",
        "unsloth/gemma-3-4b-it",
        "zai-org/GLM-4.5-Air",
        "zai-org/GLM-4.5-TEE",
        "zai-org/GLM-4.6-TEE",
        "zai-org/GLM-4.6V",
        "zai-org/GLM-4.7-TEE"
      ]
    },
    "cloudflare_ai_gateway": {
      "name": "Cloudflare AI Gateway",
      "api_endpoint": "https://gateway.ai.cloudflare.com/v1/${CLOUDFLARE_ACCOUNT_ID}/${CLOUDFLARE_GATEWAY_ID}/compat/",
      "api_format": "openai",
      "documentation": "https://developers.cloudflare.com/ai-gateway/",
      "env_vars": [
        "CLOUDFLARE_API_TOKEN",
        "CLOUDFLARE_ACCOUNT_ID",
        "CLOUDFLARE_GATEWAY_ID"
      ],
      "logo_url": "https://models.dev/logos/cloudflare-ai-gateway.svg",
      "model_count": 64,
      "models": [
        "anthropic/claude-3-5-haiku",
        "anthropic/claude-3-haiku",
        "anthropic/claude-3-opus",
        "anthropic/claude-3-sonnet",
        "anthropic/claude-3.5-haiku",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-haiku-4-5",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4-1",
        "anthropic/claude-opus-4-5",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4-5",
        "openai/gpt-3.5-turbo",
        "openai/gpt-4",
        "openai/gpt-4-turbo",
        "openai/gpt-4o",
        "openai/gpt-4o-mini",
        "openai/gpt-5.1",
        "openai/gpt-5.1-codex",
        "openai/gpt-5.2",
        "openai/o1",
        "openai/o3",
        "openai/o3-mini",
        "openai/o3-pro",
        "openai/o4-mini",
        "workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B",
        "workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it",
        "workers-ai/@cf/baai/bge-base-en-v1.5",
        "workers-ai/@cf/baai/bge-large-en-v1.5",
        "workers-ai/@cf/baai/bge-m3",
        "workers-ai/@cf/baai/bge-reranker-base",
        "workers-ai/@cf/baai/bge-small-en-v1.5",
        "workers-ai/@cf/deepgram/aura-2-en",
        "workers-ai/@cf/deepgram/aura-2-es",
        "workers-ai/@cf/deepgram/nova-3",
        "workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
        "workers-ai/@cf/facebook/bart-large-cnn",
        "workers-ai/@cf/google/gemma-3-12b-it",
        "workers-ai/@cf/huggingface/distilbert-sst-2-int8",
        "workers-ai/@cf/ibm-granite/granite-4.0-h-micro",
        "workers-ai/@cf/meta/llama-2-7b-chat-fp16",
        "workers-ai/@cf/meta/llama-3-8b-instruct",
        "workers-ai/@cf/meta/llama-3-8b-instruct-awq",
        "workers-ai/@cf/meta/llama-3.1-8b-instruct",
        "workers-ai/@cf/meta/llama-3.1-8b-instruct-awq",
        "workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8",
        "workers-ai/@cf/meta/llama-3.2-11b-vision-instruct",
        "workers-ai/@cf/meta/llama-3.2-1b-instruct",
        "workers-ai/@cf/meta/llama-3.2-3b-instruct",
        "workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast",
        "workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct",
        "workers-ai/@cf/meta/llama-guard-3-8b",
        "workers-ai/@cf/meta/m2m100-1.2b",
        "workers-ai/@cf/mistral/mistral-7b-instruct-v0.1",
        "workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct",
        "workers-ai/@cf/myshell-ai/melotts",
        "workers-ai/@cf/openai/gpt-oss-120b",
        "workers-ai/@cf/openai/gpt-oss-20b",
        "workers-ai/@cf/pfnet/plamo-embedding-1b",
        "workers-ai/@cf/pipecat-ai/smart-turn-v2",
        "workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct",
        "workers-ai/@cf/qwen/qwen3-30b-a3b-fp8",
        "workers-ai/@cf/qwen/qwen3-embedding-0.6b",
        "workers-ai/@cf/qwen/qwq-32b"
      ]
    },
    "cloudflare_workers_ai": {
      "name": "Cloudflare Workers AI",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://developers.cloudflare.com/workers-ai/models/",
      "env_vars": [
        "CLOUDFLARE_ACCOUNT_ID",
        "CLOUDFLARE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/cloudflare-workers-ai.svg",
      "model_count": 73,
      "models": [
        "aura-1",
        "bart-large-cnn",
        "deepseek-coder-6.7b-base-awq",
        "deepseek-coder-6.7b-instruct-awq",
        "deepseek-math-7b-instruct",
        "deepseek-r1-distill-qwen-32b",
        "discolm-german-7b-v1-awq",
        "dreamshaper-8-lcm",
        "falcon-7b-instruct",
        "flux-1-schnell",
        "gemma-2b-it-lora",
        "gemma-3-12b-it",
        "gemma-7b-it",
        "gemma-7b-it-lora",
        "gemma-sea-lion-v4-27b-it",
        "gpt-oss-120b",
        "gpt-oss-20b",
        "granite-4.0-h-micro",
        "hermes-2-pro-mistral-7b",
        "llama-2-13b-chat-awq",
        "llama-2-7b-chat-fp16",
        "llama-2-7b-chat-hf-lora",
        "llama-2-7b-chat-int8",
        "llama-3-8b-instruct",
        "llama-3-8b-instruct-awq",
        "llama-3.1-70b-instruct",
        "llama-3.1-8b-instruct",
        "llama-3.1-8b-instruct-awq",
        "llama-3.1-8b-instruct-fast",
        "llama-3.1-8b-instruct-fp8",
        "llama-3.2-11b-vision-instruct",
        "llama-3.2-1b-instruct",
        "llama-3.2-3b-instruct",
        "llama-3.3-70b-instruct-fp8-fast",
        "llama-4-scout-17b-16e-instruct",
        "llama-guard-3-8b",
        "llamaguard-7b-awq",
        "llava-1.5-7b-hf",
        "lucid-origin",
        "m2m100-1.2b",
        "melotts",
        "mistral-7b-instruct-v0.1",
        "mistral-7b-instruct-v0.1-awq",
        "mistral-7b-instruct-v0.2",
        "mistral-7b-instruct-v0.2-lora",
        "mistral-small-3.1-24b-instruct",
        "neural-chat-7b-v3-1-awq",
        "nova-3",
        "openchat-3.5-0106",
        "openhermes-2.5-mistral-7b-awq",
        "phi-2",
        "phoenix-1.0",
        "qwen1.5-0.5b-chat",
        "qwen1.5-1.8b-chat",
        "qwen1.5-14b-chat-awq",
        "qwen1.5-7b-chat-awq",
        "qwen2.5-coder-32b-instruct",
        "qwen3-30b-a3b-fp8",
        "qwq-32b",
        "resnet-50",
        "sqlcoder-7b-2",
        "stable-diffusion-v1-5-img2img",
        "stable-diffusion-v1-5-inpainting",
        "stable-diffusion-xl-base-1.0",
        "stable-diffusion-xl-lightning",
        "starling-lm-7b-beta",
        "tinyllama-1.1b-chat-v1.0",
        "uform-gen2-qwen-500m",
        "una-cybertron-7b-v2-bf16",
        "whisper",
        "whisper-large-v3-turbo",
        "whisper-tiny-en",
        "zephyr-7b-beta-awq"
      ]
    },
    "cohere": {
      "name": "Cohere",
      "api_endpoint": "https://api.cohere.ai/v1",
      "api_format": "cohere",
      "documentation": "https://docs.cohere.com/docs/models",
      "env_vars": [
        "COHERE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/cohere.svg",
      "model_count": 7,
      "models": [
        "command-a-03-2025",
        "command-a-reasoning-08-2025",
        "command-a-translate-08-2025",
        "command-a-vision-07-2025",
        "command-r-08-2024",
        "command-r-plus-08-2024",
        "command-r7b-12-2024"
      ]
    },
    "cortecs": {
      "name": "Cortecs",
      "api_endpoint": "https://api.cortecs.ai/v1",
      "api_format": "openai",
      "documentation": "https://api.cortecs.ai/v1/models",
      "env_vars": [
        "CORTECS_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/cortecs.svg",
      "model_count": 16,
      "models": [
        "claude-4-5-sonnet",
        "claude-sonnet-4",
        "deepseek-v3-0324",
        "devstral-2512",
        "devstral-small-2512",
        "gemini-2.5-pro",
        "gpt-4.1",
        "gpt-oss-120b",
        "intellect-3",
        "kimi-k2-instruct",
        "kimi-k2-thinking",
        "llama-3.1-405b-instruct",
        "nova-pro-v1",
        "qwen3-32b",
        "qwen3-coder-480b-a35b-instruct",
        "qwen3-next-80b-a3b-thinking"
      ]
    },
    "deepinfra": {
      "name": "Deep Infra",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://deepinfra.com/models",
      "env_vars": [
        "DEEPINFRA_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/deepinfra.svg",
      "model_count": 9,
      "models": [
        "MiniMaxAI/MiniMax-M2",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Thinking",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "zai-org/GLM-4.5",
        "zai-org/GLM-4.7"
      ]
    },
    "deepseek": {
      "name": "DeepSeek",
      "api_endpoint": "https://api.deepseek.com",
      "api_format": "openai",
      "documentation": "https://platform.deepseek.com/api-docs/pricing",
      "env_vars": [
        "DEEPSEEK_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/deepseek.svg",
      "model_count": 2,
      "models": [
        "deepseek-chat",
        "deepseek-reasoner"
      ]
    },
    "fastrouter": {
      "name": "FastRouter",
      "api_endpoint": "https://go.fastrouter.ai/api/v1",
      "api_format": "openai",
      "documentation": "https://fastrouter.ai/models",
      "env_vars": [
        "FASTROUTER_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/fastrouter.svg",
      "model_count": 14,
      "models": [
        "anthropic/claude-opus-4.1",
        "anthropic/claude-sonnet-4",
        "deepseek-ai/deepseek-r1-distill-llama-70b",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-pro",
        "moonshotai/kimi-k2",
        "openai/gpt-4.1",
        "openai/gpt-5",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "qwen/qwen3-coder",
        "x-ai/grok-4"
      ]
    },
    "fireworks": {
      "name": "Fireworks AI",
      "api_endpoint": "https://api.fireworks.ai/inference/v1/",
      "api_format": "openai",
      "documentation": "https://fireworks.ai/docs/",
      "env_vars": [
        "FIREWORKS_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/fireworks-ai.svg",
      "model_count": 16,
      "models": [
        "accounts/fireworks/models/deepseek-r1-0528",
        "accounts/fireworks/models/deepseek-v3-0324",
        "accounts/fireworks/models/deepseek-v3p1",
        "accounts/fireworks/models/deepseek-v3p2",
        "accounts/fireworks/models/glm-4p5",
        "accounts/fireworks/models/glm-4p5-air",
        "accounts/fireworks/models/glm-4p6",
        "accounts/fireworks/models/glm-4p7",
        "accounts/fireworks/models/gpt-oss-120b",
        "accounts/fireworks/models/gpt-oss-20b",
        "accounts/fireworks/models/kimi-k2-instruct",
        "accounts/fireworks/models/kimi-k2-thinking",
        "accounts/fireworks/models/minimax-m2",
        "accounts/fireworks/models/minimax-m2p1",
        "accounts/fireworks/models/qwen3-235b-a22b",
        "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct"
      ]
    },
    "friendli": {
      "name": "Friendli",
      "api_endpoint": "https://api.friendli.ai/serverless/v1",
      "api_format": "openai",
      "documentation": "https://friendli.ai/docs/guides/serverless_endpoints/introduction",
      "env_vars": [
        "FRIENDLI_TOKEN"
      ],
      "logo_url": "https://models.dev/logos/friendli.svg",
      "model_count": 11,
      "models": [
        "LGAI-EXAONE/EXAONE-4.0.1-32B",
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-32B",
        "deepseek-ai/DeepSeek-R1-0528",
        "meta-llama-3.1-8b-instruct",
        "meta-llama-3.3-70b-instruct",
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "zai-org/GLM-4.6"
      ]
    },
    "github_copilot": {
      "name": "GitHub Copilot",
      "api_endpoint": "https://api.githubcopilot.com",
      "api_format": "openai",
      "documentation": "https://docs.github.com/en/copilot",
      "env_vars": [
        "GITHUB_TOKEN"
      ],
      "logo_url": "https://models.dev/logos/github-copilot.svg",
      "model_count": 28,
      "models": [
        "claude-3.5-sonnet",
        "claude-3.7-sonnet",
        "claude-3.7-sonnet-thought",
        "claude-haiku-4.5",
        "claude-opus-4",
        "claude-opus-4.5",
        "claude-opus-41",
        "claude-sonnet-4",
        "claude-sonnet-4.5",
        "gemini-2.0-flash-001",
        "gemini-2.5-pro",
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "gpt-4.1",
        "gpt-4o",
        "gpt-5",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5.1",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "grok-code-fast-1",
        "o3",
        "o3-mini",
        "o4-mini",
        "oswe-vscode-prime"
      ]
    },
    "github_models": {
      "name": "GitHub Models",
      "api_endpoint": "https://models.github.ai/inference",
      "api_format": "openai",
      "documentation": "https://docs.github.com/en/github-models",
      "env_vars": [
        "GITHUB_TOKEN"
      ],
      "logo_url": "https://models.dev/logos/github-models.svg",
      "model_count": 55,
      "models": [
        "ai21-labs/ai21-jamba-1.5-large",
        "ai21-labs/ai21-jamba-1.5-mini",
        "cohere/cohere-command-a",
        "cohere/cohere-command-r",
        "cohere/cohere-command-r-08-2024",
        "cohere/cohere-command-r-plus",
        "cohere/cohere-command-r-plus-08-2024",
        "core42/jais-30b-chat",
        "deepseek/deepseek-r1",
        "deepseek/deepseek-r1-0528",
        "deepseek/deepseek-v3-0324",
        "meta/llama-3.2-11b-vision-instruct",
        "meta/llama-3.2-90b-vision-instruct",
        "meta/llama-3.3-70b-instruct",
        "meta/llama-4-maverick-17b-128e-instruct-fp8",
        "meta/llama-4-scout-17b-16e-instruct",
        "meta/meta-llama-3-70b-instruct",
        "meta/meta-llama-3-8b-instruct",
        "meta/meta-llama-3.1-405b-instruct",
        "meta/meta-llama-3.1-70b-instruct",
        "meta/meta-llama-3.1-8b-instruct",
        "microsoft/mai-ds-r1",
        "microsoft/phi-3-medium-128k-instruct",
        "microsoft/phi-3-medium-4k-instruct",
        "microsoft/phi-3-mini-128k-instruct",
        "microsoft/phi-3-mini-4k-instruct",
        "microsoft/phi-3-small-128k-instruct",
        "microsoft/phi-3-small-8k-instruct",
        "microsoft/phi-3.5-mini-instruct",
        "microsoft/phi-3.5-moe-instruct",
        "microsoft/phi-3.5-vision-instruct",
        "microsoft/phi-4",
        "microsoft/phi-4-mini-instruct",
        "microsoft/phi-4-mini-reasoning",
        "microsoft/phi-4-multimodal-instruct",
        "microsoft/phi-4-reasoning",
        "mistral-ai/codestral-2501",
        "mistral-ai/ministral-3b",
        "mistral-ai/mistral-large-2411",
        "mistral-ai/mistral-medium-2505",
        "mistral-ai/mistral-nemo",
        "mistral-ai/mistral-small-2503",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4.1-nano",
        "openai/gpt-4o",
        "openai/gpt-4o-mini",
        "openai/o1",
        "openai/o1-mini",
        "openai/o1-preview",
        "openai/o3",
        "openai/o3-mini",
        "openai/o4-mini",
        "xai/grok-3",
        "xai/grok-3-mini"
      ]
    },
    "google": {
      "name": "Google",
      "api_endpoint": "https://generativelanguage.googleapis.com/v1",
      "api_format": "google",
      "documentation": "https://ai.google.dev/gemini-api/docs/pricing",
      "env_vars": [
        "GOOGLE_GENERATIVE_AI_API_KEY",
        "GEMINI_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/google.svg",
      "model_count": 26,
      "models": [
        "gemini-1.5-flash",
        "gemini-1.5-flash-8b",
        "gemini-1.5-pro",
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
        "gemini-2.5-flash",
        "gemini-2.5-flash-image",
        "gemini-2.5-flash-image-preview",
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash-lite-preview-06-17",
        "gemini-2.5-flash-lite-preview-09-2025",
        "gemini-2.5-flash-preview-04-17",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-flash-preview-09-2025",
        "gemini-2.5-flash-preview-tts",
        "gemini-2.5-pro",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.5-pro-preview-06-05",
        "gemini-2.5-pro-preview-tts",
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "gemini-embedding-001",
        "gemini-flash-latest",
        "gemini-flash-lite-latest",
        "gemini-live-2.5-flash",
        "gemini-live-2.5-flash-preview-native-audio"
      ]
    },
    "google_vertex": {
      "name": "Vertex",
      "api_endpoint": "https://us-central1-aiplatform.googleapis.com/v1",
      "api_format": "google",
      "documentation": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
      "env_vars": [
        "GOOGLE_VERTEX_PROJECT",
        "GOOGLE_VERTEX_LOCATION",
        "GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "logo_url": "https://models.dev/logos/google-vertex.svg",
      "model_count": 19,
      "models": [
        "gemini-2.0-flash",
        "gemini-2.0-flash-lite",
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.5-flash-lite-preview-06-17",
        "gemini-2.5-flash-lite-preview-09-2025",
        "gemini-2.5-flash-preview-04-17",
        "gemini-2.5-flash-preview-05-20",
        "gemini-2.5-flash-preview-09-2025",
        "gemini-2.5-pro",
        "gemini-2.5-pro-preview-05-06",
        "gemini-2.5-pro-preview-06-05",
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "gemini-embedding-001",
        "gemini-flash-latest",
        "gemini-flash-lite-latest",
        "openai/gpt-oss-120b-maas",
        "openai/gpt-oss-20b-maas"
      ]
    },
    "google_vertex_anthropic": {
      "name": "Vertex (Anthropic)",
      "api_endpoint": null,
      "api_format": "anthropic",
      "documentation": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude",
      "env_vars": [
        "GOOGLE_VERTEX_PROJECT",
        "GOOGLE_VERTEX_LOCATION",
        "GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "logo_url": "https://models.dev/logos/google-vertex-anthropic.svg",
      "model_count": 9,
      "models": [
        "claude-3-5-haiku@20241022",
        "claude-3-5-sonnet@20241022",
        "claude-3-7-sonnet@20250219",
        "claude-haiku-4-5@20251001",
        "claude-opus-4-1@20250805",
        "claude-opus-4-5@20251101",
        "claude-opus-4@20250514",
        "claude-sonnet-4-5@20250929",
        "claude-sonnet-4@20250514"
      ]
    },
    "groq": {
      "name": "Groq",
      "api_endpoint": "https://api.groq.com/openai/v1",
      "api_format": "openai",
      "documentation": "https://console.groq.com/docs/models",
      "env_vars": [
        "GROQ_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/groq.svg",
      "model_count": 17,
      "models": [
        "deepseek-r1-distill-llama-70b",
        "gemma2-9b-it",
        "llama-3.1-8b-instant",
        "llama-3.3-70b-versatile",
        "llama-guard-3-8b",
        "llama3-70b-8192",
        "llama3-8b-8192",
        "meta-llama/llama-4-maverick-17b-128e-instruct",
        "meta-llama/llama-4-scout-17b-16e-instruct",
        "meta-llama/llama-guard-4-12b",
        "mistral-saba-24b",
        "moonshotai/kimi-k2-instruct",
        "moonshotai/kimi-k2-instruct-0905",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "qwen-qwq-32b",
        "qwen/qwen3-32b"
      ]
    },
    "helicone": {
      "name": "Helicone",
      "api_endpoint": "https://ai-gateway.helicone.ai/v1",
      "api_format": "openai",
      "documentation": "https://helicone.ai/models",
      "env_vars": [
        "HELICONE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/helicone.svg",
      "model_count": 91,
      "models": [
        "chatgpt-4o-latest",
        "claude-3-haiku-20240307",
        "claude-3.5-haiku",
        "claude-3.5-sonnet-v2",
        "claude-3.7-sonnet",
        "claude-4.5-haiku",
        "claude-4.5-opus",
        "claude-4.5-sonnet",
        "claude-haiku-4-5-20251001",
        "claude-opus-4",
        "claude-opus-4-1",
        "claude-opus-4-1-20250805",
        "claude-sonnet-4",
        "claude-sonnet-4-5-20250929",
        "codex-mini-latest",
        "deepseek-r1-distill-llama-70b",
        "deepseek-reasoner",
        "deepseek-tng-r1t2-chimera",
        "deepseek-v3",
        "deepseek-v3.1-terminus",
        "deepseek-v3.2",
        "ernie-4.5-21b-a3b-thinking",
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.5-pro",
        "gemini-3-pro-preview",
        "gemma-3-12b-it",
        "gemma2-9b-it",
        "glm-4.6",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-mini-2025-04-14",
        "gpt-4.1-nano",
        "gpt-4o",
        "gpt-4o-mini",
        "gpt-5",
        "gpt-5-chat-latest",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-chat-latest",
        "gpt-5.1-codex",
        "gpt-5.1-codex-mini",
        "gpt-oss-120b",
        "gpt-oss-20b",
        "grok-3",
        "grok-3-mini",
        "grok-4",
        "grok-4-1-fast-non-reasoning",
        "grok-4-1-fast-reasoning",
        "grok-4-fast-non-reasoning",
        "grok-4-fast-reasoning",
        "grok-code-fast-1",
        "hermes-2-pro-llama-3-8b",
        "kimi-k2-0711",
        "kimi-k2-0905",
        "kimi-k2-thinking",
        "llama-3.1-8b-instant",
        "llama-3.1-8b-instruct",
        "llama-3.1-8b-instruct-turbo",
        "llama-3.3-70b-instruct",
        "llama-3.3-70b-versatile",
        "llama-4-maverick",
        "llama-4-scout",
        "llama-guard-4",
        "llama-prompt-guard-2-22m",
        "llama-prompt-guard-2-86m",
        "mistral-large-2411",
        "mistral-nemo",
        "mistral-small",
        "o1",
        "o1-mini",
        "o3",
        "o3-mini",
        "o3-pro",
        "o4-mini",
        "qwen2.5-coder-7b-fast",
        "qwen3-235b-a22b-thinking",
        "qwen3-30b-a3b",
        "qwen3-32b",
        "qwen3-coder",
        "qwen3-coder-30b-a3b-instruct",
        "qwen3-next-80b-a3b-instruct",
        "qwen3-vl-235b-a22b-instruct",
        "sonar",
        "sonar-deep-research",
        "sonar-pro",
        "sonar-reasoning",
        "sonar-reasoning-pro"
      ]
    },
    "huggingface": {
      "name": "Hugging Face",
      "api_endpoint": "https://router.huggingface.co/v1",
      "api_format": "openai",
      "documentation": "https://huggingface.co/docs/inference-providers",
      "env_vars": [
        "HF_TOKEN"
      ],
      "logo_url": "https://models.dev/logos/huggingface.svg",
      "model_count": 14,
      "models": [
        "MiniMaxAI/MiniMax-M2",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen3-Embedding-4B",
        "Qwen/Qwen3-Embedding-8B",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/Deepseek-V3-0324",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Instruct-0905",
        "zai-org/GLM-4.5",
        "zai-org/GLM-4.5-Air",
        "zai-org/GLM-4.6"
      ]
    },
    "iflowcn": {
      "name": "iFlow",
      "api_endpoint": "https://apis.iflow.cn/v1",
      "api_format": "openai",
      "documentation": "https://platform.iflow.cn/en/docs",
      "env_vars": [
        "IFLOW_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/iflowcn.svg",
      "model_count": 20,
      "models": [
        "deepseek-r1",
        "deepseek-v3",
        "deepseek-v3.1",
        "deepseek-v3.2",
        "deepseek-v3.2-chat",
        "glm-4.6",
        "kimi-k2",
        "kimi-k2-0905",
        "kimi-k2-thinking",
        "minimax-m2",
        "qwen3-235b",
        "qwen3-235b-a22b-instruct",
        "qwen3-235b-a22b-thinking-2507",
        "qwen3-32b",
        "qwen3-coder",
        "qwen3-coder-plus",
        "qwen3-max",
        "qwen3-max-preview",
        "qwen3-vl-plus",
        "tstars2.0"
      ]
    },
    "inception": {
      "name": "Inception",
      "api_endpoint": "https://api.inceptionlabs.ai/v1/",
      "api_format": "openai",
      "documentation": "https://platform.inceptionlabs.ai/docs",
      "env_vars": [
        "INCEPTION_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/inception.svg",
      "model_count": 2,
      "models": [
        "mercury",
        "mercury-coder"
      ]
    },
    "inference": {
      "name": "Inference",
      "api_endpoint": "https://inference.net/v1",
      "api_format": "openai",
      "documentation": "https://inference.net/models",
      "env_vars": [
        "INFERENCE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/inference.svg",
      "model_count": 9,
      "models": [
        "google/gemma-3",
        "meta/llama-3.1-8b-instruct",
        "meta/llama-3.2-11b-vision-instruct",
        "meta/llama-3.2-1b-instruct",
        "meta/llama-3.2-3b-instruct",
        "mistral/mistral-nemo-12b-instruct",
        "osmosis/osmosis-structure-0.6b",
        "qwen/qwen-2.5-7b-vision-instruct",
        "qwen/qwen3-embedding-4b"
      ]
    },
    "io_net": {
      "name": "IO.NET",
      "api_endpoint": "https://api.intelligence.io.solutions/api/v1",
      "api_format": "openai",
      "documentation": "https://io.net/docs/guides/intelligence/io-intelligence",
      "env_vars": [
        "IOINTELLIGENCE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/io-net.svg",
      "model_count": 17,
      "models": [
        "Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar",
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "deepseek-ai/DeepSeek-R1-0528",
        "meta-llama/Llama-3.2-90B-Vision-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "mistralai/Devstral-Small-2505",
        "mistralai/Magistral-Small-2506",
        "mistralai/Mistral-Large-Instruct-2411",
        "mistralai/Mistral-Nemo-Instruct-2407",
        "moonshotai/Kimi-K2-Instruct-0905",
        "moonshotai/Kimi-K2-Thinking",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "zai-org/GLM-4.6"
      ]
    },
    "kimi_for_coding": {
      "name": "Kimi For Coding",
      "api_endpoint": "https://api.kimi.com/coding/v1",
      "api_format": "openai",
      "documentation": "https://www.kimi.com/coding/docs/en/third-party-agents.html",
      "env_vars": [
        "KIMI_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/kimi-for-coding.svg",
      "model_count": 1,
      "models": [
        "kimi-k2-thinking"
      ]
    },
    "llama": {
      "name": "Llama",
      "api_endpoint": "https://api.llama.com/compat/v1/",
      "api_format": "openai",
      "documentation": "https://llama.developer.meta.com/docs/models",
      "env_vars": [
        "LLAMA_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/llama.svg",
      "model_count": 7,
      "models": [
        "cerebras-llama-4-maverick-17b-128e-instruct",
        "cerebras-llama-4-scout-17b-16e-instruct",
        "groq-llama-4-maverick-17b-128e-instruct",
        "llama-3.3-70b-instruct",
        "llama-3.3-8b-instruct",
        "llama-4-maverick-17b-128e-instruct-fp8",
        "llama-4-scout-17b-16e-instruct-fp8"
      ]
    },
    "lmstudio": {
      "name": "LMStudio",
      "api_endpoint": "http://127.0.0.1:1234/v1",
      "api_format": "openai",
      "documentation": "https://lmstudio.ai/models",
      "env_vars": [
        "LMSTUDIO_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/lmstudio.svg",
      "model_count": 3,
      "models": [
        "openai/gpt-oss-20b",
        "qwen/qwen3-30b-a3b-2507",
        "qwen/qwen3-coder-30b"
      ]
    },
    "lucidquery": {
      "name": "LucidQuery AI",
      "api_endpoint": "https://lucidquery.com/api/v1",
      "api_format": "openai",
      "documentation": "https://lucidquery.com/api/docs",
      "env_vars": [
        "LUCIDQUERY_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/lucidquery.svg",
      "model_count": 2,
      "models": [
        "lucidnova-rf1-100b",
        "lucidquery-nexus-coder"
      ]
    },
    "minimax": {
      "name": "MiniMax",
      "api_endpoint": "https://api.minimax.io/anthropic/v1",
      "api_format": "openai",
      "documentation": "https://platform.minimax.io/docs/guides/quickstart",
      "env_vars": [
        "MINIMAX_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/minimax.svg",
      "model_count": 2,
      "models": [
        "MiniMax-M2",
        "MiniMax-M2.1"
      ]
    },
    "minimax_cn": {
      "name": "MiniMax (China)",
      "api_endpoint": "https://api.minimaxi.com/anthropic/v1",
      "api_format": "openai",
      "documentation": "https://platform.minimaxi.com/docs/guides/quickstart",
      "env_vars": [
        "MINIMAX_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/minimax-cn.svg",
      "model_count": 2,
      "models": [
        "MiniMax-M2",
        "MiniMax-M2.1"
      ]
    },
    "mistral": {
      "name": "Mistral",
      "api_endpoint": "https://api.mistral.ai/v1",
      "api_format": "openai",
      "documentation": "https://docs.mistral.ai/getting-started/models/",
      "env_vars": [
        "MISTRAL_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/mistral.svg",
      "model_count": 26,
      "models": [
        "codestral-latest",
        "devstral-2512",
        "devstral-medium-2507",
        "devstral-medium-latest",
        "devstral-small-2505",
        "devstral-small-2507",
        "labs-devstral-small-2512",
        "magistral-medium-latest",
        "magistral-small",
        "ministral-3b-latest",
        "ministral-8b-latest",
        "mistral-embed",
        "mistral-large-2411",
        "mistral-large-2512",
        "mistral-large-latest",
        "mistral-medium-2505",
        "mistral-medium-2508",
        "mistral-medium-latest",
        "mistral-nemo",
        "mistral-small-2506",
        "mistral-small-latest",
        "open-mistral-7b",
        "open-mixtral-8x22b",
        "open-mixtral-8x7b",
        "pixtral-12b",
        "pixtral-large-latest"
      ]
    },
    "modelscope": {
      "name": "ModelScope",
      "api_endpoint": "https://api-inference.modelscope.cn/v1",
      "api_format": "openai",
      "documentation": "https://modelscope.cn/docs/model-service/API-Inference/intro",
      "env_vars": [
        "MODELSCOPE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/modelscope.svg",
      "model_count": 7,
      "models": [
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "Qwen/Qwen3-30B-A3B-Thinking-2507",
        "Qwen/Qwen3-Coder-30B-A3B-Instruct",
        "ZhipuAI/GLM-4.5",
        "ZhipuAI/GLM-4.6"
      ]
    },
    "moonshotai": {
      "name": "Moonshot AI",
      "api_endpoint": "https://api.moonshot.ai/v1",
      "api_format": "openai",
      "documentation": "https://platform.moonshot.ai/docs/api/chat",
      "env_vars": [
        "MOONSHOT_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/moonshotai.svg",
      "model_count": 5,
      "models": [
        "kimi-k2-0711-preview",
        "kimi-k2-0905-preview",
        "kimi-k2-thinking",
        "kimi-k2-thinking-turbo",
        "kimi-k2-turbo-preview"
      ]
    },
    "moonshotai_cn": {
      "name": "Moonshot AI (China)",
      "api_endpoint": "https://api.moonshot.cn/v1",
      "api_format": "openai",
      "documentation": "https://platform.moonshot.cn/docs/api/chat",
      "env_vars": [
        "MOONSHOT_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/moonshotai-cn.svg",
      "model_count": 5,
      "models": [
        "kimi-k2-0711-preview",
        "kimi-k2-0905-preview",
        "kimi-k2-thinking",
        "kimi-k2-thinking-turbo",
        "kimi-k2-turbo-preview"
      ]
    },
    "morph": {
      "name": "Morph",
      "api_endpoint": "https://api.morphllm.com/v1",
      "api_format": "openai",
      "documentation": "https://docs.morphllm.com/api-reference/introduction",
      "env_vars": [
        "MORPH_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/morph.svg",
      "model_count": 3,
      "models": [
        "auto",
        "morph-v3-fast",
        "morph-v3-large"
      ]
    },
    "nano_gpt": {
      "name": "NanoGPT",
      "api_endpoint": "https://nano-gpt.com/api/v1",
      "api_format": "openai",
      "documentation": "https://docs.nano-gpt.com",
      "env_vars": [
        "NANO_GPT_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/nano-gpt.svg",
      "model_count": 21,
      "models": [
        "deepseek/deepseek-r1",
        "deepseek/deepseek-v3.2:thinking",
        "meta-llama/llama-3.3-70b-instruct",
        "meta-llama/llama-4-maverick",
        "minimax/minimax-m2.1",
        "mistralai/devstral-2-123b-instruct-2512",
        "mistralai/ministral-14b-instruct-2512",
        "mistralai/mistral-large-3-675b-instruct-2512",
        "moonshotai/kimi-k2-instruct",
        "moonshotai/kimi-k2-thinking",
        "nousresearch/hermes-4-405b:thinking",
        "nvidia/llama-3_3-nemotron-super-49b-v1_5",
        "openai/gpt-oss-120b",
        "qwen/qwen3-235b-a22b-thinking-2507",
        "qwen/qwen3-coder",
        "z-ai/glm-4.6",
        "z-ai/glm-4.6:thinking",
        "zai-org/glm-4.5-air",
        "zai-org/glm-4.5-air:thinking",
        "zai-org/glm-4.7",
        "zai-org/glm-4.7:thinking"
      ]
    },
    "nebius": {
      "name": "Nebius Token Factory",
      "api_endpoint": "https://api.tokenfactory.nebius.com/v1",
      "api_format": "openai",
      "documentation": "https://docs.tokenfactory.nebius.com/",
      "env_vars": [
        "NEBIUS_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/nebius.svg",
      "model_count": 15,
      "models": [
        "NousResearch/hermes-4-405b",
        "NousResearch/hermes-4-70b",
        "deepseek-ai/deepseek-v3",
        "meta-llama/llama-3.3-70b-instruct-base",
        "meta-llama/llama-3.3-70b-instruct-fast",
        "meta-llama/llama-3_1-405b-instruct",
        "moonshotai/kimi-k2-instruct",
        "nvidia/llama-3_1-nemotron-ultra-253b-v1",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "qwen/qwen3-235b-a22b-instruct-2507",
        "qwen/qwen3-235b-a22b-thinking-2507",
        "qwen/qwen3-coder-480b-a35b-instruct",
        "zai-org/glm-4.5",
        "zai-org/glm-4.5-air"
      ]
    },
    "nvidia": {
      "name": "Nvidia",
      "api_endpoint": "https://integrate.api.nvidia.com/v1",
      "api_format": "openai",
      "documentation": "https://docs.api.nvidia.com/nim/",
      "env_vars": [
        "NVIDIA_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/nvidia.svg",
      "model_count": 66,
      "models": [
        "black-forest-labs/flux.1-dev",
        "deepseek-ai/deepseek-coder-6.7b-instruct",
        "deepseek-ai/deepseek-r1",
        "deepseek-ai/deepseek-r1-0528",
        "deepseek-ai/deepseek-v3.1",
        "deepseek-ai/deepseek-v3.1-terminus",
        "google/codegemma-1.1-7b",
        "google/codegemma-7b",
        "google/gemma-2-27b-it",
        "google/gemma-2-2b-it",
        "google/gemma-3-12b-it",
        "google/gemma-3-1b-it",
        "google/gemma-3-27b-it",
        "google/gemma-3n-e2b-it",
        "google/gemma-3n-e4b-it",
        "meta/codellama-70b",
        "meta/llama-3.1-405b-instruct",
        "meta/llama-3.1-70b-instruct",
        "meta/llama-3.2-11b-vision-instruct",
        "meta/llama-3.2-1b-instruct",
        "meta/llama-3.3-70b-instruct",
        "meta/llama-4-maverick-17b-128e-instruct",
        "meta/llama-4-scout-17b-16e-instruct",
        "meta/llama3-70b-instruct",
        "meta/llama3-8b-instruct",
        "microsoft/phi-3-medium-128k-instruct",
        "microsoft/phi-3-medium-4k-instruct",
        "microsoft/phi-3-small-128k-instruct",
        "microsoft/phi-3-small-8k-instruct",
        "microsoft/phi-3-vision-128k-instruct",
        "microsoft/phi-3.5-moe-instruct",
        "microsoft/phi-3.5-vision-instruct",
        "microsoft/phi-4-mini-instruct",
        "minimaxai/minimax-m2",
        "mistralai/codestral-22b-instruct-v0.1",
        "mistralai/devstral-2-123b-instruct-2512",
        "mistralai/mamba-codestral-7b-v0.1",
        "mistralai/ministral-14b-instruct-2512",
        "mistralai/mistral-large-2-instruct",
        "mistralai/mistral-large-3-675b-instruct-2512",
        "mistralai/mistral-small-3.1-24b-instruct-2503",
        "moonshotai/kimi-k2-instruct",
        "moonshotai/kimi-k2-instruct-0905",
        "moonshotai/kimi-k2-thinking",
        "nvidia/cosmos-nemotron-34b",
        "nvidia/llama-3.1-nemotron-51b-instruct",
        "nvidia/llama-3.1-nemotron-70b-instruct",
        "nvidia/llama-3.1-nemotron-ultra-253b-v1",
        "nvidia/llama-3.3-nemotron-super-49b-v1",
        "nvidia/llama-3.3-nemotron-super-49b-v1.5",
        "nvidia/llama-embed-nemotron-8b",
        "nvidia/llama3-chatqa-1.5-70b",
        "nvidia/nemoretriever-ocr-v1",
        "nvidia/nemotron-3-nano-30b-a3b",
        "nvidia/nemotron-4-340b-instruct",
        "nvidia/nvidia-nemotron-nano-9b-v2",
        "nvidia/parakeet-tdt-0.6b-v2",
        "openai/gpt-oss-120b",
        "openai/whisper-large-v3",
        "qwen/qwen2.5-coder-32b-instruct",
        "qwen/qwen2.5-coder-7b-instruct",
        "qwen/qwen3-235b-a22b",
        "qwen/qwen3-coder-480b-a35b-instruct",
        "qwen/qwen3-next-80b-a3b-instruct",
        "qwen/qwen3-next-80b-a3b-thinking",
        "qwen/qwq-32b"
      ]
    },
    "ollama": {
      "name": "Ollama Cloud",
      "api_endpoint": "https://ollama.com/v1",
      "api_format": "openai",
      "documentation": "https://docs.ollama.com/cloud",
      "env_vars": [
        "OLLAMA_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/ollama-cloud.svg",
      "model_count": 12,
      "models": [
        "cogito-2.1:671b-cloud",
        "deepseek-v3.1:671b-cloud",
        "gemini-3-pro-preview:latest",
        "glm-4.6:cloud",
        "gpt-oss:120b-cloud",
        "gpt-oss:20b-cloud",
        "kimi-k2-thinking:cloud",
        "kimi-k2:1t-cloud",
        "minimax-m2:cloud",
        "qwen3-coder:480b-cloud",
        "qwen3-vl-235b-cloud",
        "qwen3-vl-235b-instruct-cloud"
      ]
    },
    "openai": {
      "name": "OpenAI",
      "api_endpoint": "https://api.openai.com/v1",
      "api_format": "openai",
      "documentation": "https://platform.openai.com/docs/models",
      "env_vars": [
        "OPENAI_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/openai.svg",
      "model_count": 39,
      "models": [
        "codex-mini-latest",
        "gpt-3.5-turbo",
        "gpt-4",
        "gpt-4-turbo",
        "gpt-4.1",
        "gpt-4.1-mini",
        "gpt-4.1-nano",
        "gpt-4o",
        "gpt-4o-2024-05-13",
        "gpt-4o-2024-08-06",
        "gpt-4o-2024-11-20",
        "gpt-4o-mini",
        "gpt-5",
        "gpt-5-chat-latest",
        "gpt-5-codex",
        "gpt-5-mini",
        "gpt-5-nano",
        "gpt-5-pro",
        "gpt-5.1",
        "gpt-5.1-chat-latest",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "gpt-5.2-chat-latest",
        "gpt-5.2-pro",
        "o1",
        "o1-mini",
        "o1-preview",
        "o1-pro",
        "o3",
        "o3-deep-research",
        "o3-mini",
        "o3-pro",
        "o4-mini",
        "o4-mini-deep-research",
        "text-embedding-3-large",
        "text-embedding-3-small",
        "text-embedding-ada-002"
      ]
    },
    "opencode": {
      "name": "OpenCode Zen",
      "api_endpoint": "https://opencode.ai/zen/v1",
      "api_format": "openai",
      "documentation": "https://opencode.ai/docs/zen",
      "env_vars": [
        "OPENCODE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/opencode.svg",
      "model_count": 26,
      "models": [
        "alpha-gd4",
        "alpha-glm-4.7",
        "big-pickle",
        "claude-3-5-haiku",
        "claude-haiku-4-5",
        "claude-opus-4-1",
        "claude-opus-4-5",
        "claude-sonnet-4",
        "claude-sonnet-4-5",
        "gemini-3-flash",
        "gemini-3-pro",
        "glm-4.6",
        "glm-4.7-free",
        "gpt-5",
        "gpt-5-codex",
        "gpt-5-nano",
        "gpt-5.1",
        "gpt-5.1-codex",
        "gpt-5.1-codex-max",
        "gpt-5.1-codex-mini",
        "gpt-5.2",
        "grok-code",
        "kimi-k2",
        "kimi-k2-thinking",
        "minimax-m2.1-free",
        "qwen3-coder"
      ]
    },
    "openrouter": {
      "name": "OpenRouter",
      "api_endpoint": "https://openrouter.ai/api/v1",
      "api_format": "openai",
      "documentation": "https://openrouter.ai/models",
      "env_vars": [
        "OPENROUTER_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/openrouter.svg",
      "model_count": 137,
      "models": [
        "anthropic/claude-3.5-haiku",
        "anthropic/claude-3.7-sonnet",
        "anthropic/claude-haiku-4.5",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4.1",
        "anthropic/claude-opus-4.5",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4.5",
        "cognitivecomputations/dolphin3.0-mistral-24b",
        "cognitivecomputations/dolphin3.0-r1-mistral-24b",
        "deepseek/deepseek-chat-v3-0324",
        "deepseek/deepseek-chat-v3.1",
        "deepseek/deepseek-r1-0528-qwen3-8b:free",
        "deepseek/deepseek-r1-0528:free",
        "deepseek/deepseek-r1-distill-llama-70b",
        "deepseek/deepseek-r1-distill-qwen-14b",
        "deepseek/deepseek-r1:free",
        "deepseek/deepseek-v3-base:free",
        "deepseek/deepseek-v3.1-terminus",
        "deepseek/deepseek-v3.1-terminus:exacto",
        "deepseek/deepseek-v3.2",
        "deepseek/deepseek-v3.2-speciale",
        "featherless/qwerky-72b",
        "google/gemini-2.0-flash-001",
        "google/gemini-2.0-flash-exp:free",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-flash-lite",
        "google/gemini-2.5-flash-lite-preview-09-2025",
        "google/gemini-2.5-flash-preview-09-2025",
        "google/gemini-2.5-pro",
        "google/gemini-2.5-pro-preview-05-06",
        "google/gemini-2.5-pro-preview-06-05",
        "google/gemini-3-flash-preview",
        "google/gemini-3-pro-preview",
        "google/gemma-2-9b-it:free",
        "google/gemma-3-12b-it",
        "google/gemma-3-27b-it",
        "google/gemma-3n-e4b-it",
        "google/gemma-3n-e4b-it:free",
        "kwaipilot/kat-coder-pro:free",
        "meta-llama/llama-3.2-11b-vision-instruct",
        "meta-llama/llama-3.3-70b-instruct:free",
        "meta-llama/llama-4-scout:free",
        "microsoft/mai-ds-r1:free",
        "minimax/minimax-01",
        "minimax/minimax-m1",
        "minimax/minimax-m2",
        "minimax/minimax-m2.1",
        "mistralai/codestral-2508",
        "mistralai/devstral-2512",
        "mistralai/devstral-2512:free",
        "mistralai/devstral-medium-2507",
        "mistralai/devstral-small-2505",
        "mistralai/devstral-small-2505:free",
        "mistralai/devstral-small-2507",
        "mistralai/mistral-7b-instruct:free",
        "mistralai/mistral-medium-3",
        "mistralai/mistral-medium-3.1",
        "mistralai/mistral-nemo:free",
        "mistralai/mistral-small-3.1-24b-instruct",
        "mistralai/mistral-small-3.2-24b-instruct",
        "mistralai/mistral-small-3.2-24b-instruct:free",
        "moonshotai/kimi-dev-72b:free",
        "moonshotai/kimi-k2",
        "moonshotai/kimi-k2-0905",
        "moonshotai/kimi-k2-0905:exacto",
        "moonshotai/kimi-k2-thinking",
        "moonshotai/kimi-k2:free",
        "nousresearch/deephermes-3-llama-3-8b-preview",
        "nousresearch/hermes-4-405b",
        "nousresearch/hermes-4-70b",
        "nvidia/nemotron-nano-9b-v2",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4o-mini",
        "openai/gpt-5",
        "openai/gpt-5-chat",
        "openai/gpt-5-codex",
        "openai/gpt-5-image",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/gpt-5-pro",
        "openai/gpt-5.1",
        "openai/gpt-5.1-chat",
        "openai/gpt-5.1-codex",
        "openai/gpt-5.1-codex-mini",
        "openai/gpt-5.2",
        "openai/gpt-5.2-chat-latest",
        "openai/gpt-5.2-pro",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-120b:exacto",
        "openai/gpt-oss-20b",
        "openai/gpt-oss-safeguard-20b",
        "openai/o4-mini",
        "openrouter/sherlock-dash-alpha",
        "openrouter/sherlock-think-alpha",
        "qwen/qwen-2.5-coder-32b-instruct",
        "qwen/qwen2.5-vl-32b-instruct:free",
        "qwen/qwen2.5-vl-72b-instruct",
        "qwen/qwen2.5-vl-72b-instruct:free",
        "qwen/qwen3-14b:free",
        "qwen/qwen3-235b-a22b-07-25",
        "qwen/qwen3-235b-a22b-07-25:free",
        "qwen/qwen3-235b-a22b-thinking-2507",
        "qwen/qwen3-235b-a22b:free",
        "qwen/qwen3-30b-a3b-instruct-2507",
        "qwen/qwen3-30b-a3b-thinking-2507",
        "qwen/qwen3-30b-a3b:free",
        "qwen/qwen3-32b:free",
        "qwen/qwen3-8b:free",
        "qwen/qwen3-coder",
        "qwen/qwen3-coder-flash",
        "qwen/qwen3-coder:exacto",
        "qwen/qwen3-coder:free",
        "qwen/qwen3-max",
        "qwen/qwen3-next-80b-a3b-instruct",
        "qwen/qwen3-next-80b-a3b-thinking",
        "qwen/qwq-32b:free",
        "rekaai/reka-flash-3",
        "sarvamai/sarvam-m:free",
        "thudm/glm-z1-32b:free",
        "tngtech/deepseek-r1t2-chimera:free",
        "x-ai/grok-3",
        "x-ai/grok-3-beta",
        "x-ai/grok-3-mini",
        "x-ai/grok-3-mini-beta",
        "x-ai/grok-4",
        "x-ai/grok-4-fast",
        "x-ai/grok-4.1-fast",
        "x-ai/grok-code-fast-1",
        "z-ai/glm-4.5",
        "z-ai/glm-4.5-air",
        "z-ai/glm-4.5-air:free",
        "z-ai/glm-4.5v",
        "z-ai/glm-4.6",
        "z-ai/glm-4.6:exacto",
        "z-ai/glm-4.7"
      ]
    },
    "ovhcloud": {
      "name": "OVHcloud AI Endpoints",
      "api_endpoint": "https://oai.endpoints.kepler.ai.cloud.ovh.net/v1",
      "api_format": "openai",
      "documentation": "https://www.ovhcloud.com/en/public-cloud/ai-endpoints/catalog//",
      "env_vars": [
        "OVHCLOUD_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/ovhcloud.svg",
      "model_count": 15,
      "models": [
        "deepseek-r1-distill-llama-70b",
        "gpt-oss-120b",
        "gpt-oss-20b",
        "llama-3.1-8b-instruct",
        "llava-next-mistral-7b",
        "meta-llama-3_1-70b-instruct",
        "meta-llama-3_3-70b-instruct",
        "mistral-7b-instruct-v0.3",
        "mistral-nemo-instruct-2407",
        "mistral-small-3.2-24b-instruct-2506",
        "mixtral-8x7b-instruct-v0.1",
        "qwen2.5-coder-32b-instruct",
        "qwen2.5-vl-72b-instruct",
        "qwen3-32b",
        "qwen3-coder-30b-a3b-instruct"
      ]
    },
    "perplexity": {
      "name": "Perplexity",
      "api_endpoint": "https://api.perplexity.ai",
      "api_format": "openai",
      "documentation": "https://docs.perplexity.ai",
      "env_vars": [
        "PERPLEXITY_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/perplexity.svg",
      "model_count": 3,
      "models": [
        "sonar",
        "sonar-pro",
        "sonar-reasoning-pro"
      ]
    },
    "poe": {
      "name": "Poe",
      "api_endpoint": "https://api.poe.com/v1",
      "api_format": "openai",
      "documentation": "https://creator.poe.com/docs/external-applications/openai-compatible-api",
      "env_vars": [
        "POE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/poe.svg",
      "model_count": 115,
      "models": [
        "anthropic/claude-haiku-3",
        "anthropic/claude-haiku-3.5",
        "anthropic/claude-haiku-3.5-search",
        "anthropic/claude-haiku-4.5",
        "anthropic/claude-opus-3",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4-reasoning",
        "anthropic/claude-opus-4-search",
        "anthropic/claude-opus-4.1",
        "anthropic/claude-opus-4.5",
        "anthropic/claude-sonnet-3.5",
        "anthropic/claude-sonnet-3.5-june",
        "anthropic/claude-sonnet-3.7",
        "anthropic/claude-sonnet-3.7-reasoning",
        "anthropic/claude-sonnet-3.7-search",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4-reasoning",
        "anthropic/claude-sonnet-4-search",
        "anthropic/claude-sonnet-4.5",
        "cerebras/gpt-oss-120b-cs",
        "cerebras/zai-glm-4.6-cs",
        "elevenlabs/elevenlabs-music",
        "elevenlabs/elevenlabs-v2.5-turbo",
        "elevenlabs/elevenlabs-v3",
        "google/gemini-2.0-flash",
        "google/gemini-2.0-flash-lite",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-flash-lite",
        "google/gemini-2.5-pro",
        "google/gemini-3-flash",
        "google/gemini-3-pro",
        "google/gemini-deep-research",
        "google/imagen-3",
        "google/imagen-3-fast",
        "google/imagen-4",
        "google/imagen-4-fast",
        "google/imagen-4-ultra",
        "google/lyria",
        "google/nano-banana",
        "google/nano-banana-pro",
        "google/veo-2",
        "google/veo-3",
        "google/veo-3-fast",
        "google/veo-3.1",
        "google/veo-3.1-fast",
        "ideogramai/ideogram",
        "ideogramai/ideogram-v2",
        "ideogramai/ideogram-v2a",
        "ideogramai/ideogram-v2a-turbo",
        "lumalabs/dream-machine",
        "lumalabs/ray2",
        "novita/glm-4.6",
        "novita/glm-4.6v",
        "novita/glm-4.7",
        "novita/kat-coder-pro",
        "novita/kimi-k2-thinking",
        "novita/minimax-m2.1",
        "openai/chatgpt-4o-latest",
        "openai/dall-e-3",
        "openai/gpt-3.5-turbo",
        "openai/gpt-3.5-turbo-instruct",
        "openai/gpt-3.5-turbo-raw",
        "openai/gpt-4-classic",
        "openai/gpt-4-classic-0314",
        "openai/gpt-4-turbo",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4.1-nano",
        "openai/gpt-4o",
        "openai/gpt-4o-aug",
        "openai/gpt-4o-mini",
        "openai/gpt-4o-mini-search",
        "openai/gpt-4o-search",
        "openai/gpt-5",
        "openai/gpt-5-chat",
        "openai/gpt-5-codex",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/gpt-5-pro",
        "openai/gpt-5.1",
        "openai/gpt-5.1-codex",
        "openai/gpt-5.1-codex-max",
        "openai/gpt-5.1-codex-mini",
        "openai/gpt-5.1-instant",
        "openai/gpt-5.2",
        "openai/gpt-5.2-instant",
        "openai/gpt-5.2-pro",
        "openai/gpt-image-1",
        "openai/gpt-image-1-mini",
        "openai/gpt-image-1.5",
        "openai/o1",
        "openai/o1-pro",
        "openai/o3",
        "openai/o3-deep-research",
        "openai/o3-mini",
        "openai/o3-mini-high",
        "openai/o3-pro",
        "openai/o4-mini",
        "openai/o4-mini-deep-research",
        "openai/sora-2",
        "openai/sora-2-pro",
        "poetools/claude-code",
        "runwayml/runway",
        "runwayml/runway-gen-4-turbo",
        "stabilityai/stablediffusionxl",
        "topazlabs-co/topazlabs",
        "trytako/tako",
        "xai/grok-3",
        "xai/grok-3-mini",
        "xai/grok-4",
        "xai/grok-4-fast-non-reasoning",
        "xai/grok-4-fast-reasoning",
        "xai/grok-4.1-fast-non-reasoning",
        "xai/grok-4.1-fast-reasoning",
        "xai/grok-code-fast-1"
      ]
    },
    "requesty": {
      "name": "Requesty",
      "api_endpoint": "https://router.requesty.ai/v1",
      "api_format": "openai",
      "documentation": "https://requesty.ai/solution/llm-routing/models",
      "env_vars": [
        "REQUESTY_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/requesty.svg",
      "model_count": 20,
      "models": [
        "anthropic/claude-3-7-sonnet",
        "anthropic/claude-haiku-4-5",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4-1",
        "anthropic/claude-opus-4-5",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4-5",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-pro",
        "google/gemini-3-flash-preview",
        "google/gemini-3-pro-preview",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4o-mini",
        "openai/gpt-5",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/o4-mini",
        "xai/grok-4",
        "xai/grok-4-fast"
      ]
    },
    "sap_ai_core": {
      "name": "SAP AI Core",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://help.sap.com/docs/sap-ai-core",
      "env_vars": [
        "AICORE_SERVICE_KEY"
      ],
      "logo_url": "https://models.dev/logos/sap-ai-core.svg",
      "model_count": 14,
      "models": [
        "anthropic--claude-3-haiku",
        "anthropic--claude-3-opus",
        "anthropic--claude-3-sonnet",
        "anthropic--claude-3.5-sonnet",
        "anthropic--claude-3.7-sonnet",
        "anthropic--claude-4-opus",
        "anthropic--claude-4-sonnet",
        "anthropic--claude-4.5-haiku",
        "anthropic--claude-4.5-sonnet",
        "gemini-2.5-flash",
        "gemini-2.5-pro",
        "gpt-5",
        "gpt-5-mini",
        "gpt-5-nano"
      ]
    },
    "scaleway": {
      "name": "Scaleway",
      "api_endpoint": "https://api.scaleway.ai/v1",
      "api_format": "openai",
      "documentation": "https://www.scaleway.com/en/docs/generative-apis/",
      "env_vars": [
        "SCALEWAY_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/scaleway.svg",
      "model_count": 13,
      "models": [
        "bge-multilingual-gemma2",
        "deepseek-r1-distill-llama-70b",
        "gemma-3-27b-it",
        "gpt-oss-120b",
        "llama-3.1-8b-instruct",
        "llama-3.3-70b-instruct",
        "mistral-nemo-instruct-2407",
        "mistral-small-3.2-24b-instruct-2506",
        "pixtral-12b-2409",
        "qwen3-235b-a22b-instruct-2507",
        "qwen3-coder-30b-a3b-instruct",
        "voxtral-small-24b-2507",
        "whisper-large-v3"
      ]
    },
    "siliconflow": {
      "name": "SiliconFlow",
      "api_endpoint": "https://api.siliconflow.com/v1",
      "api_format": "openai",
      "documentation": "https://cloud.siliconflow.com/models",
      "env_vars": [
        "SILICONFLOW_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/siliconflow.svg",
      "model_count": 72,
      "models": [
        "ByteDance-Seed/Seed-OSS-36B-Instruct",
        "MiniMaxAI/MiniMax-M1-80k",
        "MiniMaxAI/MiniMax-M2",
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-14B-Instruct",
        "Qwen/Qwen2.5-32B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct-128K",
        "Qwen/Qwen2.5-7B-Instruct",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        "Qwen/Qwen2.5-VL-7B-Instruct",
        "Qwen/Qwen3-14B",
        "Qwen/Qwen3-235B-A22B",
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "Qwen/Qwen3-30B-A3B-Thinking-2507",
        "Qwen/Qwen3-32B",
        "Qwen/Qwen3-8B",
        "Qwen/Qwen3-Coder-30B-A3B-Instruct",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "Qwen/Qwen3-Omni-30B-A3B-Captioner",
        "Qwen/Qwen3-Omni-30B-A3B-Instruct",
        "Qwen/Qwen3-Omni-30B-A3B-Thinking",
        "Qwen/Qwen3-VL-235B-A22B-Instruct",
        "Qwen/Qwen3-VL-235B-A22B-Thinking",
        "Qwen/Qwen3-VL-30B-A3B-Instruct",
        "Qwen/Qwen3-VL-30B-A3B-Thinking",
        "Qwen/Qwen3-VL-32B-Instruct",
        "Qwen/Qwen3-VL-32B-Thinking",
        "Qwen/Qwen3-VL-8B-Instruct",
        "Qwen/Qwen3-VL-8B-Thinking",
        "THUDM/GLM-4-32B-0414",
        "THUDM/GLM-4-9B-0414",
        "THUDM/GLM-4.1V-9B-Thinking",
        "THUDM/GLM-Z1-32B-0414",
        "THUDM/GLM-Z1-9B-0414",
        "baidu/ERNIE-4.5-300B-A47B",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3.1",
        "deepseek-ai/DeepSeek-V3.1-Terminus",
        "deepseek-ai/DeepSeek-V3.2-Exp",
        "deepseek-ai/deepseek-vl2",
        "inclusionAI/Ling-flash-2.0",
        "inclusionAI/Ling-mini-2.0",
        "inclusionAI/Ring-flash-2.0",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "moonshotai/Kimi-Dev-72B",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Instruct-0905",
        "moonshotai/Kimi-K2-Thinking",
        "nex-agi/DeepSeek-V3.1-Nex-N1",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "stepfun-ai/step3",
        "tencent/Hunyuan-A13B-Instruct",
        "tencent/Hunyuan-MT-7B",
        "z-ai/GLM-4.5",
        "z-ai/GLM-4.5-Air",
        "zai-org/GLM-4.5",
        "zai-org/GLM-4.5-Air",
        "zai-org/GLM-4.5V",
        "zai-org/GLM-4.6"
      ]
    },
    "siliconflow_cn": {
      "name": "SiliconFlow (China)",
      "api_endpoint": "https://api.siliconflow.cn/v1",
      "api_format": "openai",
      "documentation": "https://cloud.siliconflow.com/models",
      "env_vars": [
        "SILICONFLOW_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/siliconflow-cn.svg",
      "model_count": 72,
      "models": [
        "ByteDance-Seed/Seed-OSS-36B-Instruct",
        "MiniMaxAI/MiniMax-M1-80k",
        "MiniMaxAI/MiniMax-M2",
        "Qwen/QwQ-32B",
        "Qwen/Qwen2.5-14B-Instruct",
        "Qwen/Qwen2.5-32B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct",
        "Qwen/Qwen2.5-72B-Instruct-128K",
        "Qwen/Qwen2.5-7B-Instruct",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/Qwen2.5-VL-32B-Instruct",
        "Qwen/Qwen2.5-VL-72B-Instruct",
        "Qwen/Qwen2.5-VL-7B-Instruct",
        "Qwen/Qwen3-14B",
        "Qwen/Qwen3-235B-A22B",
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-30B-A3B-Instruct-2507",
        "Qwen/Qwen3-30B-A3B-Thinking-2507",
        "Qwen/Qwen3-32B",
        "Qwen/Qwen3-8B",
        "Qwen/Qwen3-Coder-30B-A3B-Instruct",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Instruct",
        "Qwen/Qwen3-Next-80B-A3B-Thinking",
        "Qwen/Qwen3-Omni-30B-A3B-Captioner",
        "Qwen/Qwen3-Omni-30B-A3B-Instruct",
        "Qwen/Qwen3-Omni-30B-A3B-Thinking",
        "Qwen/Qwen3-VL-235B-A22B-Instruct",
        "Qwen/Qwen3-VL-235B-A22B-Thinking",
        "Qwen/Qwen3-VL-30B-A3B-Instruct",
        "Qwen/Qwen3-VL-30B-A3B-Thinking",
        "Qwen/Qwen3-VL-32B-Instruct",
        "Qwen/Qwen3-VL-32B-Thinking",
        "Qwen/Qwen3-VL-8B-Instruct",
        "Qwen/Qwen3-VL-8B-Thinking",
        "THUDM/GLM-4-32B-0414",
        "THUDM/GLM-4-9B-0414",
        "THUDM/GLM-4.1V-9B-Thinking",
        "THUDM/GLM-Z1-32B-0414",
        "THUDM/GLM-Z1-9B-0414",
        "baidu/ERNIE-4.5-300B-A47B",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3.1",
        "deepseek-ai/DeepSeek-V3.1-Terminus",
        "deepseek-ai/DeepSeek-V3.2-Exp",
        "deepseek-ai/deepseek-vl2",
        "inclusionAI/Ling-flash-2.0",
        "inclusionAI/Ling-mini-2.0",
        "inclusionAI/Ring-flash-2.0",
        "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "moonshotai/Kimi-Dev-72B",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Instruct-0905",
        "moonshotai/Kimi-K2-Thinking",
        "nex-agi/DeepSeek-V3.1-Nex-N1",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "stepfun-ai/step3",
        "tencent/Hunyuan-A13B-Instruct",
        "tencent/Hunyuan-MT-7B",
        "z-ai/GLM-4.5",
        "z-ai/GLM-4.5-Air",
        "zai-org/GLM-4.5",
        "zai-org/GLM-4.5-Air",
        "zai-org/GLM-4.5V",
        "zai-org/GLM-4.6"
      ]
    },
    "submodel": {
      "name": "submodel",
      "api_endpoint": "https://llm.submodel.ai/v1",
      "api_format": "openai",
      "documentation": "https://submodel.gitbook.io",
      "env_vars": [
        "SUBMODEL_INSTAGEN_ACCESS_KEY"
      ],
      "logo_url": "https://models.dev/logos/submodel.svg",
      "model_count": 9,
      "models": [
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/DeepSeek-V3-0324",
        "deepseek-ai/DeepSeek-V3.1",
        "openai/gpt-oss-120b",
        "zai-org/GLM-4.5-Air",
        "zai-org/GLM-4.5-FP8"
      ]
    },
    "synthetic": {
      "name": "Synthetic",
      "api_endpoint": "https://api.synthetic.new/v1",
      "api_format": "openai",
      "documentation": "https://synthetic.new/pricing",
      "env_vars": [
        "SYNTHETIC_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/synthetic.svg",
      "model_count": 25,
      "models": [
        "hf:MiniMaxAI/MiniMax-M2",
        "hf:MiniMaxAI/MiniMax-M2.1",
        "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
        "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
        "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
        "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "hf:deepseek-ai/DeepSeek-R1",
        "hf:deepseek-ai/DeepSeek-R1-0528",
        "hf:deepseek-ai/DeepSeek-V3",
        "hf:deepseek-ai/DeepSeek-V3-0324",
        "hf:deepseek-ai/DeepSeek-V3.1",
        "hf:deepseek-ai/DeepSeek-V3.1-Terminus",
        "hf:deepseek-ai/DeepSeek-V3.2",
        "hf:meta-llama/Llama-3.1-405B-Instruct",
        "hf:meta-llama/Llama-3.1-70B-Instruct",
        "hf:meta-llama/Llama-3.1-8B-Instruct",
        "hf:meta-llama/Llama-3.3-70B-Instruct",
        "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
        "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "hf:moonshotai/Kimi-K2-Instruct-0905",
        "hf:moonshotai/Kimi-K2-Thinking",
        "hf:openai/gpt-oss-120b",
        "hf:zai-org/GLM-4.5",
        "hf:zai-org/GLM-4.6",
        "hf:zai-org/GLM-4.7"
      ]
    },
    "togetherai": {
      "name": "Together AI",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://docs.together.ai/docs/serverless-models",
      "env_vars": [
        "TOGETHER_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/togetherai.svg",
      "model_count": 10,
      "models": [
        "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
        "deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3-1",
        "essentialai/Rnj-1-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "moonshotai/Kimi-K2-Instruct",
        "moonshotai/Kimi-K2-Thinking",
        "openai/gpt-oss-120b",
        "zai-org/GLM-4.6"
      ]
    },
    "upstage": {
      "name": "Upstage",
      "api_endpoint": "https://api.upstage.ai",
      "api_format": "openai",
      "documentation": "https://developers.upstage.ai/docs/apis/chat",
      "env_vars": [
        "UPSTAGE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/upstage.svg",
      "model_count": 2,
      "models": [
        "solar-mini",
        "solar-pro2"
      ]
    },
    "v0": {
      "name": "v0",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://sdk.vercel.ai/providers/ai-sdk-providers/vercel",
      "env_vars": [
        "V0_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/v0.svg",
      "model_count": 3,
      "models": [
        "v0-1.0-md",
        "v0-1.5-lg",
        "v0-1.5-md"
      ]
    },
    "venice": {
      "name": "Venice AI",
      "api_endpoint": "https://api.venice.ai/api/v1",
      "api_format": "openai",
      "documentation": "https://docs.venice.ai",
      "env_vars": [
        "VENICE_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/venice.svg",
      "model_count": 24,
      "models": [
        "claude-opus-45",
        "deepseek-v3.2",
        "gemini-3-flash-preview",
        "gemini-3-pro-preview",
        "google-gemma-3-27b-it",
        "grok-41-fast",
        "grok-code-fast-1",
        "hermes-3-llama-3.1-405b",
        "kimi-k2-thinking",
        "llama-3.2-3b",
        "llama-3.3-70b",
        "minimax-m21",
        "mistral-31-24b",
        "openai-gpt-52",
        "openai-gpt-oss-120b",
        "qwen3-235b-a22b-instruct-2507",
        "qwen3-235b-a22b-thinking-2507",
        "qwen3-4b",
        "qwen3-coder-480b-a35b-instruct",
        "qwen3-next-80b",
        "venice-uncensored",
        "zai-org-glm-4.6",
        "zai-org-glm-4.6v",
        "zai-org-glm-4.7"
      ]
    },
    "vercel": {
      "name": "Vercel AI Gateway",
      "api_endpoint": null,
      "api_format": "openai",
      "documentation": "https://github.com/vercel/ai/tree/5eb85cc45a259553501f535b8ac79a77d0e79223/packages/gateway",
      "env_vars": [
        "AI_GATEWAY_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/vercel.svg",
      "model_count": 86,
      "models": [
        "alibaba/qwen3-coder-plus",
        "alibaba/qwen3-max",
        "alibaba/qwen3-next-80b-a3b-instruct",
        "alibaba/qwen3-next-80b-a3b-thinking",
        "alibaba/qwen3-vl-instruct",
        "alibaba/qwen3-vl-thinking",
        "amazon/nova-lite",
        "amazon/nova-micro",
        "amazon/nova-pro",
        "anthropic/claude-3-haiku",
        "anthropic/claude-3-opus",
        "anthropic/claude-3.5-haiku",
        "anthropic/claude-3.5-sonnet",
        "anthropic/claude-3.7-sonnet",
        "anthropic/claude-4-1-opus",
        "anthropic/claude-4-opus",
        "anthropic/claude-4-sonnet",
        "anthropic/claude-4.5-sonnet",
        "anthropic/claude-haiku-4.5",
        "anthropic/claude-opus-4.5",
        "deepseek/deepseek-r1",
        "deepseek/deepseek-r1-distill-llama-70b",
        "deepseek/deepseek-v3.1-terminus",
        "deepseek/deepseek-v3.2-exp",
        "deepseek/deepseek-v3.2-exp-thinking",
        "google/gemini-2.0-flash",
        "google/gemini-2.0-flash-lite",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-flash-lite",
        "google/gemini-2.5-flash-lite-preview-09-2025",
        "google/gemini-2.5-flash-preview-09-2025",
        "google/gemini-2.5-pro",
        "google/gemini-3-pro-preview",
        "meta/llama-3.3-70b",
        "meta/llama-4-maverick",
        "meta/llama-4-scout",
        "minimax/minimax-m2",
        "mistral/codestral",
        "mistral/magistral-medium",
        "mistral/magistral-small",
        "mistral/ministral-3b",
        "mistral/ministral-8b",
        "mistral/mistral-large",
        "mistral/mistral-small",
        "mistral/mixtral-8x22b-instruct",
        "mistral/pixtral-12b",
        "mistral/pixtral-large",
        "moonshotai/kimi-k2",
        "morph/morph-v3-fast",
        "morph/morph-v3-large",
        "openai/gpt-4-turbo",
        "openai/gpt-4.1",
        "openai/gpt-4.1-mini",
        "openai/gpt-4.1-nano",
        "openai/gpt-4o",
        "openai/gpt-4o-mini",
        "openai/gpt-5",
        "openai/gpt-5-codex",
        "openai/gpt-5-mini",
        "openai/gpt-5-nano",
        "openai/gpt-oss-120b",
        "openai/gpt-oss-20b",
        "openai/o1",
        "openai/o3",
        "openai/o3-mini",
        "openai/o4-mini",
        "perplexity/sonar",
        "perplexity/sonar-pro",
        "perplexity/sonar-reasoning",
        "perplexity/sonar-reasoning-pro",
        "vercel/v0-1.0-md",
        "vercel/v0-1.5-md",
        "xai/grok-2",
        "xai/grok-2-vision",
        "xai/grok-3",
        "xai/grok-3-fast",
        "xai/grok-3-mini",
        "xai/grok-3-mini-fast",
        "xai/grok-4",
        "xai/grok-4-fast",
        "xai/grok-4-fast-non-reasoning",
        "xai/grok-code-fast-1",
        "zai/glm-4.5",
        "zai/glm-4.5-air",
        "zai/glm-4.5v",
        "zai/glm-4.6"
      ]
    },
    "vultr": {
      "name": "Vultr",
      "api_endpoint": "https://api.vultrinference.com/v1",
      "api_format": "openai",
      "documentation": "https://api.vultrinference.com/",
      "env_vars": [
        "VULTR_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/vultr.svg",
      "model_count": 5,
      "models": [
        "deepseek-r1-distill-llama-70b",
        "deepseek-r1-distill-qwen-32b",
        "gpt-oss-120b",
        "kimi-k2-instruct",
        "qwen2.5-coder-32b-instruct"
      ]
    },
    "wandb": {
      "name": "Weights & Biases",
      "api_endpoint": "https://api.inference.wandb.ai/v1",
      "api_format": "openai",
      "documentation": "https://weave-docs.wandb.ai/guides/integrations/inference/",
      "env_vars": [
        "WANDB_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/wandb.svg",
      "model_count": 10,
      "models": [
        "Qwen/Qwen3-235B-A22B-Instruct-2507",
        "Qwen/Qwen3-235B-A22B-Thinking-2507",
        "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "deepseek-ai/DeepSeek-R1-0528",
        "deepseek-ai/DeepSeek-V3-0324",
        "meta-llama/Llama-3.1-8B-Instruct",
        "meta-llama/Llama-3.3-70B-Instruct",
        "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "microsoft/Phi-4-mini-instruct",
        "moonshotai/Kimi-K2-Instruct"
      ]
    },
    "xai": {
      "name": "xAI",
      "api_endpoint": "https://api.x.ai/v1",
      "api_format": "openai",
      "documentation": "https://docs.x.ai/docs/models",
      "env_vars": [
        "XAI_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/xai.svg",
      "model_count": 22,
      "models": [
        "grok-2",
        "grok-2-1212",
        "grok-2-latest",
        "grok-2-vision",
        "grok-2-vision-1212",
        "grok-2-vision-latest",
        "grok-3",
        "grok-3-fast",
        "grok-3-fast-latest",
        "grok-3-latest",
        "grok-3-mini",
        "grok-3-mini-fast",
        "grok-3-mini-fast-latest",
        "grok-3-mini-latest",
        "grok-4",
        "grok-4-1-fast",
        "grok-4-1-fast-non-reasoning",
        "grok-4-fast",
        "grok-4-fast-non-reasoning",
        "grok-beta",
        "grok-code-fast-1",
        "grok-vision-beta"
      ]
    },
    "xiaomi": {
      "name": "Xiaomi",
      "api_endpoint": "https://api.xiaomimimo.com/v1",
      "api_format": "openai",
      "documentation": "https://platform.xiaomimimo.com/#/docs",
      "env_vars": [
        "XIAOMI_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/xiaomi.svg",
      "model_count": 1,
      "models": [
        "mimo-v2-flash"
      ]
    },
    "zai": {
      "name": "Z.AI",
      "api_endpoint": "https://api.z.ai/api/paas/v4",
      "api_format": "openai",
      "documentation": "https://docs.z.ai/guides/overview/pricing",
      "env_vars": [
        "ZHIPU_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/zai.svg",
      "model_count": 7,
      "models": [
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-flash",
        "glm-4.5v",
        "glm-4.6",
        "glm-4.6v",
        "glm-4.7"
      ]
    },
    "zai_coding_plan": {
      "name": "Z.AI Coding Plan",
      "api_endpoint": "https://api.z.ai/api/coding/paas/v4",
      "api_format": "openai",
      "documentation": "https://docs.z.ai/devpack/overview",
      "env_vars": [
        "ZHIPU_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/zai-coding-plan.svg",
      "model_count": 7,
      "models": [
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-flash",
        "glm-4.5v",
        "glm-4.6",
        "glm-4.6v",
        "glm-4.7"
      ]
    },
    "zenmux": {
      "name": "ZenMux",
      "api_endpoint": "https://zenmux.ai/api/v1",
      "api_format": "openai",
      "documentation": "https://docs.zenmux.ai",
      "env_vars": [
        "ZENMUX_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/zenmux.svg",
      "model_count": 51,
      "models": [
        "anthropic/claude-haiku-4.5",
        "anthropic/claude-opus-4",
        "anthropic/claude-opus-4.1",
        "anthropic/claude-opus-4.5",
        "anthropic/claude-sonnet-4",
        "anthropic/claude-sonnet-4.5",
        "baidu/ernie-5.0-thinking-preview",
        "deepseek/deepseek-chat",
        "deepseek/deepseek-reasoner",
        "deepseek/deepseek-v3.2",
        "deepseek/deepseek-v3.2-exp",
        "google/gemini-2.5-flash",
        "google/gemini-2.5-flash-lite",
        "google/gemini-2.5-pro",
        "google/gemini-3-flash-preview",
        "google/gemini-3-flash-preview-free",
        "google/gemini-3-pro-preview",
        "inclusionai/ling-1t",
        "inclusionai/ring-1t",
        "kuaishou/kat-coder-pro-v1",
        "kuaishou/kat-coder-pro-v1-free",
        "minimax/minimax-m2",
        "minimax/minimax-m2.1",
        "moonshotai/kimi-k2-0905",
        "moonshotai/kimi-k2-thinking",
        "moonshotai/kimi-k2-thinking-turbo",
        "openai/gpt-5",
        "openai/gpt-5-codex",
        "openai/gpt-5.1",
        "openai/gpt-5.1-chat",
        "openai/gpt-5.1-codex",
        "openai/gpt-5.1-codex-mini",
        "openai/gpt-5.2",
        "qwen/qwen3-coder-plus",
        "stepfun/step-3",
        "volcengine/doubao-seed-1.8",
        "volcengine/doubao-seed-code",
        "x-ai/grok-4",
        "x-ai/grok-4-fast",
        "x-ai/grok-4.1-fast",
        "x-ai/grok-4.1-fast-non-reasoning",
        "x-ai/grok-code-fast-1",
        "xiaomi/mimo-v2-flash",
        "xiaomi/mimo-v2-flash-free",
        "z-ai/glm-4.5",
        "z-ai/glm-4.5-air",
        "z-ai/glm-4.6",
        "z-ai/glm-4.6v",
        "z-ai/glm-4.6v-flash",
        "z-ai/glm-4.6v-flash-free",
        "z-ai/glm-4.7"
      ]
    },
    "zhipuai": {
      "name": "Zhipu AI",
      "api_endpoint": "https://open.bigmodel.cn/api/paas/v4",
      "api_format": "openai",
      "documentation": "https://docs.z.ai/guides/overview/pricing",
      "env_vars": [
        "ZHIPU_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/zhipuai.svg",
      "model_count": 8,
      "models": [
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-flash",
        "glm-4.5v",
        "glm-4.6",
        "glm-4.6v",
        "glm-4.6v-flash",
        "glm-4.7"
      ]
    },
    "zhipuai_coding_plan": {
      "name": "Zhipu AI Coding Plan",
      "api_endpoint": "https://open.bigmodel.cn/api/coding/paas/v4",
      "api_format": "openai",
      "documentation": "https://docs.bigmodel.cn/cn/coding-plan/overview",
      "env_vars": [
        "ZHIPU_API_KEY"
      ],
      "logo_url": "https://models.dev/logos/zhipuai-coding-plan.svg",
      "model_count": 8,
      "models": [
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-flash",
        "glm-4.5v",
        "glm-4.6",
        "glm-4.6v",
        "glm-4.6v-flash",
        "glm-4.7"
      ]
    }
  },
  "models": {
    "moonshotai_cn/kimi-k2-thinking-turbo": {
      "id": "kimi-k2-thinking-turbo",
      "provider": "moonshotai_cn",
      "name": "Kimi K2 Thinking Turbo",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00115,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "moonshotai_cn/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "moonshotai_cn",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "moonshotai_cn/kimi-k2-0905-preview": {
      "id": "kimi-k2-0905-preview",
      "provider": "moonshotai_cn",
      "name": "Kimi K2 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "moonshotai_cn/kimi-k2-0711-preview": {
      "id": "kimi-k2-0711-preview",
      "provider": "moonshotai_cn",
      "name": "Kimi K2 0711",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true
    },
    "moonshotai_cn/kimi-k2-turbo-preview": {
      "id": "kimi-k2-turbo-preview",
      "provider": "moonshotai_cn",
      "name": "Kimi K2 Turbo",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0024,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "lucidquery/lucidquery-nexus-coder": {
      "id": "lucidquery-nexus-coder",
      "provider": "lucidquery",
      "name": "LucidQuery Nexus Coder",
      "family": "lucidquery-nexus-coder",
      "mode": "chat",
      "max_input_tokens": 250000,
      "max_output_tokens": 60000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-01",
      "release_date": "2025-09-01"
    },
    "lucidquery/lucidnova-rf1-100b": {
      "id": "lucidnova-rf1-100b",
      "provider": "lucidquery",
      "name": "LucidNova RF1 100B",
      "family": "nova",
      "mode": "chat",
      "max_input_tokens": 120000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-09-16",
      "release_date": "2024-12-28"
    },
    "moonshotai/kimi-k2-thinking-turbo": {
      "id": "kimi-k2-thinking-turbo",
      "provider": "moonshotai",
      "name": "Kimi K2 Thinking Turbo",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00115,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "moonshotai/kimi-k2-turbo-preview": {
      "id": "kimi-k2-turbo-preview",
      "provider": "moonshotai",
      "name": "Kimi K2 Turbo",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0024,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "moonshotai/kimi-k2-0711-preview": {
      "id": "kimi-k2-0711-preview",
      "provider": "moonshotai",
      "name": "Kimi K2 0711",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true
    },
    "moonshotai/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "moonshotai",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "moonshotai/kimi-k2-0905-preview": {
      "id": "kimi-k2-0905-preview",
      "provider": "moonshotai",
      "name": "Kimi K2 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.7": {
      "id": "glm-4.7",
      "provider": "zai_coding_plan",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.5-flash": {
      "id": "glm-4.5-flash",
      "provider": "zai_coding_plan",
      "name": "GLM-4.5-Flash",
      "family": "glm-4.5-flash",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.5": {
      "id": "glm-4.5",
      "provider": "zai_coding_plan",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.5-air": {
      "id": "glm-4.5-air",
      "provider": "zai_coding_plan",
      "name": "GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.5v": {
      "id": "glm-4.5v",
      "provider": "zai_coding_plan",
      "name": "GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.6": {
      "id": "glm-4.6",
      "provider": "zai_coding_plan",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "zai_coding_plan/glm-4.6v": {
      "id": "glm-4.6v",
      "provider": "zai_coding_plan",
      "name": "GLM-4.6V",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "ollama/kimi-k2-thinking:cloud": {
      "id": "kimi-k2-thinking:cloud",
      "provider": "ollama",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "ollama/qwen3-vl-235b-cloud": {
      "id": "qwen3-vl-235b-cloud",
      "provider": "ollama",
      "name": "Qwen3-VL 235B Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-09-22",
      "open_weights": true
    },
    "ollama/qwen3-coder:480b-cloud": {
      "id": "qwen3-coder:480b-cloud",
      "provider": "ollama",
      "name": "Qwen3 Coder 480B",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-22",
      "open_weights": true
    },
    "ollama/gpt-oss:120b-cloud": {
      "id": "gpt-oss:120b-cloud",
      "provider": "ollama",
      "name": "GPT-OSS 120B",
      "family": "gpt-oss:120b",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "ollama/deepseek-v3.1:671b-cloud": {
      "id": "deepseek-v3.1:671b-cloud",
      "provider": "ollama",
      "name": "DeepSeek-V3.1 671B",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "ollama/glm-4.6:cloud": {
      "id": "glm-4.6:cloud",
      "provider": "ollama",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-29",
      "open_weights": true
    },
    "ollama/cogito-2.1:671b-cloud": {
      "id": "cogito-2.1:671b-cloud",
      "provider": "ollama",
      "name": "Cogito 2.1 671B",
      "family": "cogito-2.1:671b-cloud",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-11-19",
      "open_weights": true
    },
    "ollama/gpt-oss:20b-cloud": {
      "id": "gpt-oss:20b-cloud",
      "provider": "ollama",
      "name": "GPT-OSS 20B",
      "family": "gpt-oss:20b",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "ollama/qwen3-vl-235b-instruct-cloud": {
      "id": "qwen3-vl-235b-instruct-cloud",
      "provider": "ollama",
      "name": "Qwen3-VL 235B Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-09-22",
      "open_weights": true
    },
    "ollama/kimi-k2:1t-cloud": {
      "id": "kimi-k2:1t-cloud",
      "provider": "ollama",
      "name": "Kimi K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "ollama/minimax-m2:cloud": {
      "id": "minimax-m2:cloud",
      "provider": "ollama",
      "name": "MiniMax M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "ollama/gemini-3-pro-preview:latest": {
      "id": "gemini-3-pro-preview:latest",
      "provider": "ollama",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "video_input",
        "vision"
      ],
      "release_date": "2025-11-18"
    },
    "xiaomi/mimo-v2-flash": {
      "id": "mimo-v2-flash",
      "provider": "xiaomi",
      "name": "MiMo-V2-Flash",
      "family": "mimo-v2-flash",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00021,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12-01",
      "release_date": "2025-12-17",
      "open_weights": true
    },
    "alibaba/qwen3-livetranslate-flash-realtime": {
      "id": "qwen3-livetranslate-flash-realtime",
      "provider": "alibaba",
      "name": "Qwen3-LiveTranslate Flash Realtime",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "audio_input",
        "audio_output",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-22"
    },
    "alibaba/qwen3-asr-flash": {
      "id": "qwen3-asr-flash",
      "provider": "alibaba",
      "name": "Qwen3-ASR Flash",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 3.5e-05,
      "capabilities": [
        "audio_input"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-08"
    },
    "alibaba/qwen-omni-turbo": {
      "id": "qwen-omni-turbo",
      "provider": "alibaba",
      "name": "Qwen-Omni Turbo",
      "family": "qwen-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-19"
    },
    "alibaba/qwen-vl-max": {
      "id": "qwen-vl-max",
      "provider": "alibaba",
      "name": "Qwen-VL Max",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-08"
    },
    "alibaba/qwen3-next-80b-a3b-instruct": {
      "id": "qwen3-next-80b-a3b-instruct",
      "provider": "alibaba",
      "name": "Qwen3-Next 80B-A3B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09",
      "open_weights": true
    },
    "alibaba/qwen-turbo": {
      "id": "qwen-turbo",
      "provider": "alibaba",
      "name": "Qwen Turbo",
      "family": "qwen-turbo",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-11-01"
    },
    "alibaba/qwen3-vl-235b-a22b": {
      "id": "qwen3-vl-235b-a22b",
      "provider": "alibaba",
      "name": "Qwen3-VL 235B-A22B",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "reasoning_cost_per_1k": 0.0084,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen3-coder-flash": {
      "id": "qwen3-coder-flash",
      "provider": "alibaba",
      "name": "Qwen3 Coder Flash",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28"
    },
    "alibaba/qwen3-vl-30b-a3b": {
      "id": "qwen3-vl-30b-a3b",
      "provider": "alibaba",
      "name": "Qwen3-VL 30B-A3B",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "reasoning_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen3-14b": {
      "id": "qwen3-14b",
      "provider": "alibaba",
      "name": "Qwen3 14B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0014,
      "reasoning_cost_per_1k": 0.0042,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qvq-max": {
      "id": "qvq-max",
      "provider": "alibaba",
      "name": "QVQ Max",
      "family": "qvq-max",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0048,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-03-25"
    },
    "alibaba/qwen-plus-character-ja": {
      "id": "qwen-plus-character-ja",
      "provider": "alibaba",
      "name": "Qwen Plus Character (Japanese)",
      "family": "qwen-plus",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 512,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01"
    },
    "alibaba/qwen2-5-14b-instruct": {
      "id": "qwen2-5-14b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5 14B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwq-plus": {
      "id": "qwq-plus",
      "provider": "alibaba",
      "name": "QwQ Plus",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-03-05"
    },
    "alibaba/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen3-coder-30b-a3b-instruct",
      "provider": "alibaba",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.00225,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen-vl-ocr": {
      "id": "qwen-vl-ocr",
      "provider": "alibaba",
      "name": "Qwen-VL OCR",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 34096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-10-28"
    },
    "alibaba/qwen2-5-72b-instruct": {
      "id": "qwen2-5-72b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5 72B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0014,
      "output_cost_per_1k": 0.0056,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwen3-omni-flash": {
      "id": "qwen3-omni-flash",
      "provider": "alibaba",
      "name": "Qwen3-Omni Flash",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00043,
      "output_cost_per_1k": 0.00166,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-15"
    },
    "alibaba/qwen-flash": {
      "id": "qwen-flash",
      "provider": "alibaba",
      "name": "Qwen Flash",
      "family": "qwen-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-07-28"
    },
    "alibaba/qwen3-8b": {
      "id": "qwen3-8b",
      "provider": "alibaba",
      "name": "Qwen3 8B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.0007,
      "reasoning_cost_per_1k": 0.0021,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen3-omni-flash-realtime": {
      "id": "qwen3-omni-flash-realtime",
      "provider": "alibaba",
      "name": "Qwen3-Omni Flash Realtime",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00052,
      "output_cost_per_1k": 0.00199,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-15"
    },
    "alibaba/qwen2-5-vl-72b-instruct": {
      "id": "qwen2-5-vl-72b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5-VL 72B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0028,
      "output_cost_per_1k": 0.0084,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwen3-vl-plus": {
      "id": "qwen3-vl-plus",
      "provider": "alibaba",
      "name": "Qwen3-VL Plus",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0016,
      "reasoning_cost_per_1k": 0.0048,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-23"
    },
    "alibaba/qwen-plus": {
      "id": "qwen-plus",
      "provider": "alibaba",
      "name": "Qwen Plus",
      "family": "qwen-plus",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0012,
      "reasoning_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01-25"
    },
    "alibaba/qwen2-5-32b-instruct": {
      "id": "qwen2-5-32b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5 32B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwen2-5-omni-7b": {
      "id": "qwen2-5-omni-7b",
      "provider": "alibaba",
      "name": "Qwen2.5-Omni 7B",
      "family": "qwen2.5-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-12",
      "open_weights": true
    },
    "alibaba/qwen-max": {
      "id": "qwen-max",
      "provider": "alibaba",
      "name": "Qwen Max",
      "family": "qwen-max",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.0064,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-03"
    },
    "alibaba/qwen2-5-7b-instruct": {
      "id": "qwen2-5-7b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5 7B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000175,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwen2-5-vl-7b-instruct": {
      "id": "qwen2-5-vl-7b-instruct",
      "provider": "alibaba",
      "name": "Qwen2.5-VL 7B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00105,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba/qwen3-235b-a22b": {
      "id": "qwen3-235b-a22b",
      "provider": "alibaba",
      "name": "Qwen3 235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "reasoning_cost_per_1k": 0.0084,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen-omni-turbo-realtime": {
      "id": "qwen-omni-turbo-realtime",
      "provider": "alibaba",
      "name": "Qwen-Omni Turbo Realtime",
      "family": "qwen-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00107,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-08"
    },
    "alibaba/qwen-mt-turbo": {
      "id": "qwen-mt-turbo",
      "provider": "alibaba",
      "name": "Qwen-MT Turbo",
      "family": "qwen-mt",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00049,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01"
    },
    "alibaba/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen3-coder-480b-a35b-instruct",
      "provider": "alibaba",
      "name": "Qwen3-Coder 480B-A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen-mt-plus": {
      "id": "qwen-mt-plus",
      "provider": "alibaba",
      "name": "Qwen-MT Plus",
      "family": "qwen-mt",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00246,
      "output_cost_per_1k": 0.00737,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01"
    },
    "alibaba/qwen3-max": {
      "id": "qwen3-max",
      "provider": "alibaba",
      "name": "Qwen3 Max",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-23"
    },
    "alibaba/qwen3-coder-plus": {
      "id": "qwen3-coder-plus",
      "provider": "alibaba",
      "name": "Qwen3 Coder Plus",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "alibaba/qwen3-next-80b-a3b-thinking": {
      "id": "qwen3-next-80b-a3b-thinking",
      "provider": "alibaba",
      "name": "Qwen3-Next 80B-A3B (Thinking)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09",
      "open_weights": true
    },
    "alibaba/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "alibaba",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "reasoning_cost_per_1k": 0.0084,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba/qwen-vl-plus": {
      "id": "qwen-vl-plus",
      "provider": "alibaba",
      "name": "Qwen-VL Plus",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00063,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01-25"
    },
    "xai/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "provider": "xai",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "xai/grok-3-fast": {
      "id": "grok-3-fast",
      "provider": "xai",
      "name": "Grok 3 Fast",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-4": {
      "id": "grok-4",
      "provider": "xai",
      "name": "Grok 4",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "reasoning_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "xai/grok-2-vision": {
      "id": "grok-2-vision",
      "provider": "xai",
      "name": "Grok 2 Vision",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "xai/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "xai",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-08-28"
    },
    "xai/grok-2": {
      "id": "grok-2",
      "provider": "xai",
      "name": "Grok 2",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "xai/grok-3-mini-fast-latest": {
      "id": "grok-3-mini-fast-latest",
      "provider": "xai",
      "name": "Grok 3 Mini Fast Latest",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 0.00015,
      "reasoning_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-2-vision-1212": {
      "id": "grok-2-vision-1212",
      "provider": "xai",
      "name": "Grok 2 Vision (1212)",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "xai/grok-3": {
      "id": "grok-3",
      "provider": "xai",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-4-fast": {
      "id": "grok-4-fast",
      "provider": "xai",
      "name": "Grok 4 Fast",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "xai/grok-2-latest": {
      "id": "grok-2-latest",
      "provider": "xai",
      "name": "Grok 2 Latest",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "xai/grok-4-1-fast": {
      "id": "grok-4-1-fast",
      "provider": "xai",
      "name": "Grok 4.1 Fast",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11-19"
    },
    "xai/grok-2-1212": {
      "id": "grok-2-1212",
      "provider": "xai",
      "name": "Grok 2 (1212)",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-12-12"
    },
    "xai/grok-3-fast-latest": {
      "id": "grok-3-fast-latest",
      "provider": "xai",
      "name": "Grok 3 Fast Latest",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-3-latest": {
      "id": "grok-3-latest",
      "provider": "xai",
      "name": "Grok 3 Latest",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-2-vision-latest": {
      "id": "grok-2-vision-latest",
      "provider": "xai",
      "name": "Grok 2 Vision Latest",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "xai/grok-vision-beta": {
      "id": "grok-vision-beta",
      "provider": "xai",
      "name": "Grok Vision Beta",
      "family": "grok-vision",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-11-01"
    },
    "xai/grok-3-mini": {
      "id": "grok-3-mini",
      "provider": "xai",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-beta": {
      "id": "grok-beta",
      "provider": "xai",
      "name": "Grok Beta",
      "family": "grok-beta",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-11-01"
    },
    "xai/grok-3-mini-latest": {
      "id": "grok-3-mini-latest",
      "provider": "xai",
      "name": "Grok 3 Mini Latest",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "xai/grok-4-1-fast-non-reasoning": {
      "id": "grok-4-1-fast-non-reasoning",
      "provider": "xai",
      "name": "Grok 4.1 Fast (Non-Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11-19"
    },
    "xai/grok-3-mini-fast": {
      "id": "grok-3-mini-fast",
      "provider": "xai",
      "name": "Grok 3 Mini Fast",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 0.00015,
      "reasoning_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "vultr/deepseek-r1-distill-qwen-32b": {
      "id": "deepseek-r1-distill-qwen-32b",
      "provider": "vultr",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "vultr/qwen2.5-coder-32b-instruct": {
      "id": "qwen2.5-coder-32b-instruct",
      "provider": "vultr",
      "name": "Qwen2.5 Coder 32B Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 12952,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-06",
      "open_weights": true
    },
    "vultr/kimi-k2-instruct": {
      "id": "kimi-k2-instruct",
      "provider": "vultr",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 58904,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "vultr/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "vultr",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "vultr/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "vultr",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 121808,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-06-23",
      "open_weights": true
    },
    "nvidia/moonshotai/kimi-k2-instruct-0905": {
      "id": "moonshotai/kimi-k2-instruct-0905",
      "provider": "nvidia",
      "name": "Kimi K2 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "nvidia/moonshotai/kimi-k2-thinking": {
      "id": "moonshotai/kimi-k2-thinking",
      "provider": "nvidia",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11",
      "open_weights": true
    },
    "nvidia/moonshotai/kimi-k2-instruct": {
      "id": "moonshotai/kimi-k2-instruct",
      "provider": "nvidia",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2025-01-01"
    },
    "nvidia/nvidia/nvidia-nemotron-nano-9b-v2": {
      "id": "nvidia/nvidia-nemotron-nano-9b-v2",
      "provider": "nvidia",
      "name": "nvidia-nemotron-nano-9b-v2",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-08-18",
      "open_weights": true
    },
    "nvidia/nvidia/cosmos-nemotron-34b": {
      "id": "nvidia/cosmos-nemotron-34b",
      "provider": "nvidia",
      "name": "Cosmos Nemotron 34B",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "nvidia/nvidia/llama-embed-nemotron-8b": {
      "id": "nvidia/llama-embed-nemotron-8b",
      "provider": "nvidia",
      "name": "Llama Embed Nemotron 8B",
      "family": "llama",
      "mode": "embedding",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-03-18"
    },
    "nvidia/nvidia/nemotron-3-nano-30b-a3b": {
      "id": "nvidia/nemotron-3-nano-30b-a3b",
      "provider": "nvidia",
      "name": "nemotron-3-nano-30b-a3b",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-12",
      "open_weights": true
    },
    "nvidia/nvidia/parakeet-tdt-0.6b-v2": {
      "id": "nvidia/parakeet-tdt-0.6b-v2",
      "provider": "nvidia",
      "name": "Parakeet TDT 0.6B v2",
      "family": "parakeet-tdt-0.6b",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "nvidia/nvidia/nemoretriever-ocr-v1": {
      "id": "nvidia/nemoretriever-ocr-v1",
      "provider": "nvidia",
      "name": "NeMo Retriever OCR v1",
      "family": "nemoretriever-ocr",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "nvidia/nvidia/llama-3.3-nemotron-super-49b-v1": {
      "id": "nvidia/llama-3.3-nemotron-super-49b-v1",
      "provider": "nvidia",
      "name": "Llama 3.3 Nemotron Super 49b V1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-03-16"
    },
    "nvidia/nvidia/llama-3.1-nemotron-51b-instruct": {
      "id": "nvidia/llama-3.1-nemotron-51b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.1 Nemotron 51b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-22"
    },
    "nvidia/nvidia/llama3-chatqa-1.5-70b": {
      "id": "nvidia/llama3-chatqa-1.5-70b",
      "provider": "nvidia",
      "name": "Llama3 Chatqa 1.5 70b",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-04-28"
    },
    "nvidia/nvidia/llama-3.1-nemotron-ultra-253b-v1": {
      "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
      "provider": "nvidia",
      "name": "Llama-3.1-Nemotron-Ultra-253B-v1",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-01"
    },
    "nvidia/nvidia/llama-3.1-nemotron-70b-instruct": {
      "id": "nvidia/llama-3.1-nemotron-70b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.1 Nemotron 70b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-10-12"
    },
    "nvidia/nvidia/nemotron-4-340b-instruct": {
      "id": "nvidia/nemotron-4-340b-instruct",
      "provider": "nvidia",
      "name": "Nemotron 4 340b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-06-13"
    },
    "nvidia/nvidia/llama-3.3-nemotron-super-49b-v1.5": {
      "id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
      "provider": "nvidia",
      "name": "Llama 3.3 Nemotron Super 49b V1.5",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-03-16"
    },
    "nvidia/minimaxai/minimax-m2": {
      "id": "minimaxai/minimax-m2",
      "provider": "nvidia",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "nvidia/google/gemma-3n-e2b-it": {
      "id": "google/gemma-3n-e2b-it",
      "provider": "nvidia",
      "name": "Gemma 3n E2b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-06-12",
      "open_weights": true
    },
    "nvidia/google/codegemma-1.1-7b": {
      "id": "google/codegemma-1.1-7b",
      "provider": "nvidia",
      "name": "Codegemma 1.1 7b",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-04-30",
      "open_weights": true
    },
    "nvidia/google/gemma-3n-e4b-it": {
      "id": "google/gemma-3n-e4b-it",
      "provider": "nvidia",
      "name": "Gemma 3n E4b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-06-03",
      "open_weights": true
    },
    "nvidia/google/gemma-2-2b-it": {
      "id": "google/gemma-2-2b-it",
      "provider": "nvidia",
      "name": "Gemma 2 2b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-07-16",
      "open_weights": true
    },
    "nvidia/google/gemma-3-12b-it": {
      "id": "google/gemma-3-12b-it",
      "provider": "nvidia",
      "name": "Gemma 3 12b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-03-01",
      "open_weights": true
    },
    "nvidia/google/codegemma-7b": {
      "id": "google/codegemma-7b",
      "provider": "nvidia",
      "name": "Codegemma 7b",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-03-21",
      "open_weights": true
    },
    "nvidia/google/gemma-3-1b-it": {
      "id": "google/gemma-3-1b-it",
      "provider": "nvidia",
      "name": "Gemma 3 1b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-03-10",
      "open_weights": true
    },
    "nvidia/google/gemma-2-27b-it": {
      "id": "google/gemma-2-27b-it",
      "provider": "nvidia",
      "name": "Gemma 2 27b It",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-06-24",
      "open_weights": true
    },
    "nvidia/google/gemma-3-27b-it": {
      "id": "google/gemma-3-27b-it",
      "provider": "nvidia",
      "name": "Gemma-3-27B-IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "nvidia/microsoft/phi-3-medium-128k-instruct": {
      "id": "microsoft/phi-3-medium-128k-instruct",
      "provider": "nvidia",
      "name": "Phi 3 Medium 128k Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-05-07",
      "open_weights": true
    },
    "nvidia/microsoft/phi-3-small-128k-instruct": {
      "id": "microsoft/phi-3-small-128k-instruct",
      "provider": "nvidia",
      "name": "Phi 3 Small 128k Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-05-07",
      "open_weights": true
    },
    "nvidia/microsoft/phi-3.5-vision-instruct": {
      "id": "microsoft/phi-3.5-vision-instruct",
      "provider": "nvidia",
      "name": "Phi 3.5 Vision Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2024-08-16",
      "open_weights": true
    },
    "nvidia/microsoft/phi-3-small-8k-instruct": {
      "id": "microsoft/phi-3-small-8k-instruct",
      "provider": "nvidia",
      "name": "Phi 3 Small 8k Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-05-07",
      "open_weights": true
    },
    "nvidia/microsoft/phi-3.5-moe-instruct": {
      "id": "microsoft/phi-3.5-moe-instruct",
      "provider": "nvidia",
      "name": "Phi 3.5 Moe Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-08-17",
      "open_weights": true
    },
    "nvidia/microsoft/phi-4-mini-instruct": {
      "id": "microsoft/phi-4-mini-instruct",
      "provider": "nvidia",
      "name": "Phi-4-Mini",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "nvidia/microsoft/phi-3-medium-4k-instruct": {
      "id": "microsoft/phi-3-medium-4k-instruct",
      "provider": "nvidia",
      "name": "Phi 3 Medium 4k Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 4000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-05-07",
      "open_weights": true
    },
    "nvidia/microsoft/phi-3-vision-128k-instruct": {
      "id": "microsoft/phi-3-vision-128k-instruct",
      "provider": "nvidia",
      "name": "Phi 3 Vision 128k Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2024-05-19",
      "open_weights": true
    },
    "nvidia/openai/whisper-large-v3": {
      "id": "openai/whisper-large-v3",
      "provider": "nvidia",
      "name": "Whisper Large v3",
      "family": "whisper-large",
      "mode": "audio_transcription",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2023-09-01",
      "open_weights": true
    },
    "nvidia/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "nvidia",
      "name": "GPT-OSS-120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-04"
    },
    "nvidia/qwen/qwen3-next-80b-a3b-instruct": {
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "provider": "nvidia",
      "name": "Qwen3-Next-80B-A3B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "nvidia/qwen/qwen2.5-coder-32b-instruct": {
      "id": "qwen/qwen2.5-coder-32b-instruct",
      "provider": "nvidia",
      "name": "Qwen2.5 Coder 32b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-11-06",
      "open_weights": true
    },
    "nvidia/qwen/qwen2.5-coder-7b-instruct": {
      "id": "qwen/qwen2.5-coder-7b-instruct",
      "provider": "nvidia",
      "name": "Qwen2.5 Coder 7b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-17",
      "open_weights": true
    },
    "nvidia/qwen/qwen3-235b-a22b": {
      "id": "qwen/qwen3-235b-a22b",
      "provider": "nvidia",
      "name": "Qwen3-235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "nvidia/qwen/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen/qwen3-coder-480b-a35b-instruct",
      "provider": "nvidia",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23"
    },
    "nvidia/qwen/qwq-32b": {
      "id": "qwen/qwq-32b",
      "provider": "nvidia",
      "name": "Qwq 32b",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-03-05",
      "open_weights": true
    },
    "nvidia/qwen/qwen3-next-80b-a3b-thinking": {
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "provider": "nvidia",
      "name": "Qwen3-Next-80B-A3B-Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01",
      "open_weights": true
    },
    "nvidia/mistralai/devstral-2-123b-instruct-2512": {
      "id": "mistralai/devstral-2-123b-instruct-2512",
      "provider": "nvidia",
      "name": "Devstral-2-123B-Instruct-2512",
      "family": "devstral",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "nvidia/mistralai/mistral-large-3-675b-instruct-2512": {
      "id": "mistralai/mistral-large-3-675b-instruct-2512",
      "provider": "nvidia",
      "name": "Mistral Large 3 675B Instruct 2512",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-02",
      "open_weights": true
    },
    "nvidia/mistralai/ministral-14b-instruct-2512": {
      "id": "mistralai/ministral-14b-instruct-2512",
      "provider": "nvidia",
      "name": "Ministral 3 14B Instruct 2512",
      "family": "ministral",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "nvidia/mistralai/mamba-codestral-7b-v0.1": {
      "id": "mistralai/mamba-codestral-7b-v0.1",
      "provider": "nvidia",
      "name": "Mamba Codestral 7b V0.1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-07-16",
      "open_weights": true
    },
    "nvidia/mistralai/mistral-large-2-instruct": {
      "id": "mistralai/mistral-large-2-instruct",
      "provider": "nvidia",
      "name": "Mistral Large 2 Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-07-24",
      "open_weights": true
    },
    "nvidia/mistralai/codestral-22b-instruct-v0.1": {
      "id": "mistralai/codestral-22b-instruct-v0.1",
      "provider": "nvidia",
      "name": "Codestral 22b Instruct V0.1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-05-29",
      "open_weights": true
    },
    "nvidia/mistralai/mistral-small-3.1-24b-instruct-2503": {
      "id": "mistralai/mistral-small-3.1-24b-instruct-2503",
      "provider": "nvidia",
      "name": "Mistral Small 3.1 24b Instruct 2503",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-03-11",
      "open_weights": true
    },
    "nvidia/meta/llama-3.2-11b-vision-instruct": {
      "id": "meta/llama-3.2-11b-vision-instruct",
      "provider": "nvidia",
      "name": "Llama 3.2 11b Vision Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-18",
      "open_weights": true
    },
    "nvidia/meta/llama3-70b-instruct": {
      "id": "meta/llama3-70b-instruct",
      "provider": "nvidia",
      "name": "Llama3 70b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-04-17",
      "open_weights": true
    },
    "nvidia/meta/llama-3.3-70b-instruct": {
      "id": "meta/llama-3.3-70b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.3 70b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-11-26",
      "open_weights": true
    },
    "nvidia/meta/llama-3.2-1b-instruct": {
      "id": "meta/llama-3.2-1b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.2 1b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-18",
      "open_weights": true
    },
    "nvidia/meta/llama-4-scout-17b-16e-instruct": {
      "id": "meta/llama-4-scout-17b-16e-instruct",
      "provider": "nvidia",
      "name": "Llama 4 Scout 17b 16e Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-02",
      "release_date": "2025-04-02",
      "open_weights": true
    },
    "nvidia/meta/llama-4-maverick-17b-128e-instruct": {
      "id": "meta/llama-4-maverick-17b-128e-instruct",
      "provider": "nvidia",
      "name": "Llama 4 Maverick 17b 128e Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-02",
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "nvidia/meta/codellama-70b": {
      "id": "meta/codellama-70b",
      "provider": "nvidia",
      "name": "Codellama 70b",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-01-29",
      "open_weights": true
    },
    "nvidia/meta/llama-3.1-405b-instruct": {
      "id": "meta/llama-3.1-405b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.1 405b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-07-16",
      "open_weights": true
    },
    "nvidia/meta/llama3-8b-instruct": {
      "id": "meta/llama3-8b-instruct",
      "provider": "nvidia",
      "name": "Llama3 8b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-04-17",
      "open_weights": true
    },
    "nvidia/meta/llama-3.1-70b-instruct": {
      "id": "meta/llama-3.1-70b-instruct",
      "provider": "nvidia",
      "name": "Llama 3.1 70b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-07-16",
      "open_weights": true
    },
    "nvidia/deepseek-ai/deepseek-r1-0528": {
      "id": "deepseek-ai/deepseek-r1-0528",
      "provider": "nvidia",
      "name": "Deepseek R1 0528",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "nvidia/deepseek-ai/deepseek-r1": {
      "id": "deepseek-ai/deepseek-r1",
      "provider": "nvidia",
      "name": "Deepseek R1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "nvidia/deepseek-ai/deepseek-v3.1-terminus": {
      "id": "deepseek-ai/deepseek-v3.1-terminus",
      "provider": "nvidia",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-22"
    },
    "nvidia/deepseek-ai/deepseek-v3.1": {
      "id": "deepseek-ai/deepseek-v3.1",
      "provider": "nvidia",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-08-20"
    },
    "nvidia/deepseek-ai/deepseek-coder-6.7b-instruct": {
      "id": "deepseek-ai/deepseek-coder-6.7b-instruct",
      "provider": "nvidia",
      "name": "Deepseek Coder 6.7b Instruct",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2023-10-29",
      "open_weights": true
    },
    "nvidia/black-forest-labs/flux.1-dev": {
      "id": "black-forest-labs/flux.1-dev",
      "provider": "nvidia",
      "name": "FLUX.1-dev",
      "family": "flux",
      "mode": "image",
      "max_input_tokens": 4096,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-01"
    },
    "cohere/command-a-translate-08-2025": {
      "id": "command-a-translate-08-2025",
      "provider": "cohere",
      "name": "Command A Translate",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-08-28",
      "open_weights": true
    },
    "cohere/command-a-03-2025": {
      "id": "command-a-03-2025",
      "provider": "cohere",
      "name": "Command A",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-03-13",
      "open_weights": true
    },
    "cohere/command-r-08-2024": {
      "id": "command-r-08-2024",
      "provider": "cohere",
      "name": "Command R",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "cohere/command-r-plus-08-2024": {
      "id": "command-r-plus-08-2024",
      "provider": "cohere",
      "name": "Command R+",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "cohere/command-r7b-12-2024": {
      "id": "command-r7b-12-2024",
      "provider": "cohere",
      "name": "Command R7B",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 3.75e-05,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-02-27",
      "open_weights": true
    },
    "cohere/command-a-reasoning-08-2025": {
      "id": "command-a-reasoning-08-2025",
      "provider": "cohere",
      "name": "Command A Reasoning",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "cohere/command-a-vision-07-2025": {
      "id": "command-a-vision-07-2025",
      "provider": "cohere",
      "name": "Command A Vision",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-07-31",
      "open_weights": true
    },
    "upstage/solar-mini": {
      "id": "solar-mini",
      "provider": "upstage",
      "name": "solar-mini",
      "family": "solar-mini",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-06-12"
    },
    "upstage/solar-pro2": {
      "id": "solar-pro2",
      "provider": "upstage",
      "name": "solar-pro2",
      "family": "solar-pro",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-05-20"
    },
    "groq/llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "provider": "groq",
      "name": "Llama 3.1 8B Instant",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "groq/mistral-saba-24b": {
      "id": "mistral-saba-24b",
      "provider": "groq",
      "name": "Mistral Saba 24B",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00079,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-02-06",
      "deprecated": true
    },
    "groq/llama3-8b-8192": {
      "id": "llama3-8b-8192",
      "provider": "groq",
      "name": "Llama 3 8B",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-03",
      "release_date": "2024-04-18",
      "open_weights": true,
      "deprecated": true
    },
    "groq/qwen-qwq-32b": {
      "id": "qwen-qwq-32b",
      "provider": "groq",
      "name": "Qwen QwQ 32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00039,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-11-27",
      "open_weights": true,
      "deprecated": true
    },
    "groq/llama3-70b-8192": {
      "id": "llama3-70b-8192",
      "provider": "groq",
      "name": "Llama 3 70B",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-03",
      "release_date": "2024-04-18",
      "open_weights": true,
      "deprecated": true
    },
    "groq/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "groq",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.00099,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true,
      "deprecated": true
    },
    "groq/llama-guard-3-8b": {
      "id": "llama-guard-3-8b",
      "provider": "groq",
      "name": "Llama Guard 3 8B",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-07-23",
      "open_weights": true,
      "deprecated": true
    },
    "groq/gemma2-9b-it": {
      "id": "gemma2-9b-it",
      "provider": "groq",
      "name": "Gemma 2 9B",
      "family": "gemma-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-27",
      "open_weights": true,
      "deprecated": true
    },
    "groq/llama-3.3-70b-versatile": {
      "id": "llama-3.3-70b-versatile",
      "provider": "groq",
      "name": "Llama 3.3 70B Versatile",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "groq/moonshotai/kimi-k2-instruct-0905": {
      "id": "moonshotai/kimi-k2-instruct-0905",
      "provider": "groq",
      "name": "Kimi K2 Instruct 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "groq/moonshotai/kimi-k2-instruct": {
      "id": "moonshotai/kimi-k2-instruct",
      "provider": "groq",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true,
      "deprecated": true
    },
    "groq/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "groq",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "groq/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "groq",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "groq/qwen/qwen3-32b": {
      "id": "qwen/qwen3-32b",
      "provider": "groq",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11-08",
      "release_date": "2024-12-23",
      "open_weights": true
    },
    "groq/meta-llama/llama-4-scout-17b-16e-instruct": {
      "id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider": "groq",
      "name": "Llama 4 Scout 17B",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "groq/meta-llama/llama-4-maverick-17b-128e-instruct": {
      "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
      "provider": "groq",
      "name": "Llama 4 Maverick 17B",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "groq/meta-llama/llama-guard-4-12b": {
      "id": "meta-llama/llama-guard-4-12b",
      "provider": "groq",
      "name": "Llama Guard 4 12B",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "bailing/Ling-1T": {
      "id": "Ling-1T",
      "provider": "bailing",
      "name": "Ling-1T",
      "family": "ling-1t",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00057,
      "output_cost_per_1k": 0.00229,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-10",
      "open_weights": true
    },
    "bailing/Ring-1T": {
      "id": "Ring-1T",
      "provider": "bailing",
      "name": "Ring-1T",
      "family": "ring-1t",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00057,
      "output_cost_per_1k": 0.00229,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-10",
      "open_weights": true
    },
    "github_copilot/gemini-2.0-flash-001": {
      "id": "gemini-2.0-flash-001",
      "provider": "github_copilot",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11",
      "deprecated": true
    },
    "github_copilot/claude-opus-4": {
      "id": "claude-opus-4",
      "provider": "github_copilot",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 80000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22",
      "deprecated": true
    },
    "github_copilot/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "provider": "github_copilot",
      "name": "Gemini 3 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "github_copilot/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "github_copilot",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-27"
    },
    "github_copilot/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "github_copilot",
      "name": "GPT-5.1-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "github_copilot/claude-haiku-4.5": {
      "id": "claude-haiku-4.5",
      "provider": "github_copilot",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "github_copilot/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "github_copilot",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "github_copilot/oswe-vscode-prime": {
      "id": "oswe-vscode-prime",
      "provider": "github_copilot",
      "name": "Raptor Mini (Preview)",
      "family": "oswe-vscode-prime",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-11-10"
    },
    "github_copilot/claude-3.5-sonnet": {
      "id": "claude-3.5-sonnet",
      "provider": "github_copilot",
      "name": "Claude Sonnet 3.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 90000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-10-22",
      "deprecated": true
    },
    "github_copilot/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "github_copilot",
      "name": "GPT-5.1-Codex-mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "github_copilot/o3-mini": {
      "id": "o3-mini",
      "provider": "github_copilot",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-20",
      "deprecated": true
    },
    "github_copilot/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "github_copilot",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "github_copilot/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "github_copilot",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "github_copilot/gpt-4o": {
      "id": "gpt-4o",
      "provider": "github_copilot",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "github_copilot/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "github_copilot",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "github_copilot/o4-mini": {
      "id": "o4-mini",
      "provider": "github_copilot",
      "name": "o4-mini (Preview)",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-04-16",
      "deprecated": true
    },
    "github_copilot/claude-opus-41": {
      "id": "claude-opus-41",
      "provider": "github_copilot",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 80000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "github_copilot/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "github_copilot",
      "name": "GPT-5-mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-08-13"
    },
    "github_copilot/claude-3.7-sonnet": {
      "id": "claude-3.7-sonnet",
      "provider": "github_copilot",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-02-19",
      "deprecated": true
    },
    "github_copilot/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "github_copilot",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "github_copilot/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "provider": "github_copilot",
      "name": "GPT-5.1-Codex-max",
      "family": "gpt-5-codex-max",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-12-04"
    },
    "github_copilot/o3": {
      "id": "o3",
      "provider": "github_copilot",
      "name": "o3 (Preview)",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16",
      "deprecated": true
    },
    "github_copilot/claude-sonnet-4": {
      "id": "claude-sonnet-4",
      "provider": "github_copilot",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "github_copilot/gpt-5": {
      "id": "gpt-5",
      "provider": "github_copilot",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-08-07"
    },
    "github_copilot/claude-3.7-sonnet-thought": {
      "id": "claude-3.7-sonnet-thought",
      "provider": "github_copilot",
      "name": "Claude Sonnet 3.7 Thinking",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-02-19",
      "deprecated": true
    },
    "github_copilot/claude-opus-4.5": {
      "id": "claude-opus-4.5",
      "provider": "github_copilot",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "github_copilot/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "github_copilot",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "github_copilot/claude-sonnet-4.5": {
      "id": "claude-sonnet-4.5",
      "provider": "github_copilot",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-09-29"
    },
    "mistral/devstral-medium-2507": {
      "id": "devstral-medium-2507",
      "provider": "mistral",
      "name": "Devstral Medium",
      "family": "devstral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-07-10",
      "open_weights": true
    },
    "mistral/mistral-large-2512": {
      "id": "mistral-large-2512",
      "provider": "mistral",
      "name": "Mistral Large 3",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "mistral/open-mixtral-8x22b": {
      "id": "open-mixtral-8x22b",
      "provider": "mistral",
      "name": "Mixtral 8x22B",
      "family": "mixtral-8x22b",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-17",
      "open_weights": true
    },
    "mistral/ministral-8b-latest": {
      "id": "ministral-8b-latest",
      "provider": "mistral",
      "name": "Ministral 8B",
      "family": "ministral-8b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01",
      "open_weights": true
    },
    "mistral/pixtral-large-latest": {
      "id": "pixtral-large-latest",
      "provider": "mistral",
      "name": "Pixtral Large",
      "family": "pixtral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "mistral/mistral-small-2506": {
      "id": "mistral-small-2506",
      "provider": "mistral",
      "name": "Mistral Small 3.2",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-06-20",
      "open_weights": true
    },
    "mistral/devstral-2512": {
      "id": "devstral-2512",
      "provider": "mistral",
      "name": "Devstral 2",
      "family": "devstral-medium",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-09",
      "open_weights": true
    },
    "mistral/ministral-3b-latest": {
      "id": "ministral-3b-latest",
      "provider": "mistral",
      "name": "Ministral 3B",
      "family": "ministral-3b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01",
      "open_weights": true
    },
    "mistral/pixtral-12b": {
      "id": "pixtral-12b",
      "provider": "mistral",
      "name": "Pixtral 12B",
      "family": "pixtral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-09-01",
      "open_weights": true
    },
    "mistral/mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "provider": "mistral",
      "name": "Mistral Medium 3",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07"
    },
    "mistral/labs-devstral-small-2512": {
      "id": "labs-devstral-small-2512",
      "provider": "mistral",
      "name": "Devstral Small 2",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-09",
      "open_weights": true
    },
    "mistral/devstral-medium-latest": {
      "id": "devstral-medium-latest",
      "provider": "mistral",
      "name": "Devstral 2",
      "family": "devstral-medium",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-02",
      "open_weights": true
    },
    "mistral/devstral-small-2505": {
      "id": "devstral-small-2505",
      "provider": "mistral",
      "name": "Devstral Small 2505",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07",
      "open_weights": true
    },
    "mistral/mistral-medium-2508": {
      "id": "mistral-medium-2508",
      "provider": "mistral",
      "name": "Mistral Medium 3.1",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-08-12"
    },
    "mistral/mistral-embed": {
      "id": "mistral-embed",
      "provider": "mistral",
      "name": "Mistral Embed",
      "family": "mistral-embed",
      "mode": "embedding",
      "max_input_tokens": 8000,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2023-12-11"
    },
    "mistral/mistral-small-latest": {
      "id": "mistral-small-latest",
      "provider": "mistral",
      "name": "Mistral Small",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2024-09-01",
      "open_weights": true
    },
    "mistral/magistral-small": {
      "id": "magistral-small",
      "provider": "mistral",
      "name": "Magistral Small",
      "family": "magistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-03-17",
      "open_weights": true
    },
    "mistral/devstral-small-2507": {
      "id": "devstral-small-2507",
      "provider": "mistral",
      "name": "Devstral Small",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-07-10",
      "open_weights": true
    },
    "mistral/codestral-latest": {
      "id": "codestral-latest",
      "provider": "mistral",
      "name": "Codestral",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-05-29",
      "open_weights": true
    },
    "mistral/open-mixtral-8x7b": {
      "id": "open-mixtral-8x7b",
      "provider": "mistral",
      "name": "Mixtral 8x7B",
      "family": "mixtral-8x7b",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2023-12-11",
      "open_weights": true
    },
    "mistral/mistral-nemo": {
      "id": "mistral-nemo",
      "provider": "mistral",
      "name": "Mistral Nemo",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-01",
      "open_weights": true
    },
    "mistral/open-mistral-7b": {
      "id": "open-mistral-7b",
      "provider": "mistral",
      "name": "Mistral 7B",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 8000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2023-09-27",
      "open_weights": true
    },
    "mistral/mistral-large-latest": {
      "id": "mistral-large-latest",
      "provider": "mistral",
      "name": "Mistral Large",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "mistral/mistral-medium-latest": {
      "id": "mistral-medium-latest",
      "provider": "mistral",
      "name": "Mistral Medium",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07",
      "open_weights": true
    },
    "mistral/mistral-large-2411": {
      "id": "mistral-large-2411",
      "provider": "mistral",
      "name": "Mistral Large 2.1",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "mistral/magistral-medium-latest": {
      "id": "magistral-medium-latest",
      "provider": "mistral",
      "name": "Magistral Medium",
      "family": "magistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-03-17",
      "open_weights": true
    },
    "abacus/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "abacus",
      "name": "GPT-4.1 Nano",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "abacus/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "provider": "abacus",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-09"
    },
    "abacus/gemini-2.0-flash-001": {
      "id": "gemini-2.0-flash-001",
      "provider": "abacus",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "release_date": "2025-02-05"
    },
    "abacus/deepseek-ai-DeepSeek-V3.2": {
      "id": "deepseek-ai-DeepSeek-V3.2",
      "provider": "abacus",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-15",
      "open_weights": true
    },
    "abacus/meta-llama-Meta-Llama-3.1-405B-Instruct-Turbo": {
      "id": "meta-llama-Meta-Llama-3.1-405B-Instruct-Turbo",
      "provider": "abacus",
      "name": "Llama 3.1 405B Instruct Turbo",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0035,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "abacus/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "provider": "abacus",
      "name": "Gemini 3 Flash Preview",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "abacus/Qwen-Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen-Qwen3-235B-A22B-Instruct-2507",
      "provider": "abacus",
      "name": "Qwen3 235B A22B Instruct",
      "family": "qwen-3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "abacus/meta-llama-Meta-Llama-3.1-8B-Instruct": {
      "id": "meta-llama-Meta-Llama-3.1-8B-Instruct",
      "provider": "abacus",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "abacus/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "abacus",
      "name": "Grok Code Fast 1",
      "family": "grok-code",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-09-01"
    },
    "abacus/deepseek-ai-DeepSeek-R1": {
      "id": "deepseek-ai-DeepSeek-R1",
      "provider": "abacus",
      "name": "DeepSeek R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.007,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "abacus/kimi-k2-turbo-preview": {
      "id": "kimi-k2-turbo-preview",
      "provider": "abacus",
      "name": "Kimi K2 Turbo Preview",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-07-08"
    },
    "abacus/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "abacus",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "release_date": "2025-06-01"
    },
    "abacus/qwen-qwen3-coder-480b-a35b-instruct": {
      "id": "qwen-qwen3-coder-480b-a35b-instruct",
      "provider": "abacus",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen-3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-22",
      "open_weights": true
    },
    "abacus/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "abacus",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "abacus/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "abacus",
      "name": "GPT-4.1 Mini",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "abacus/claude-opus-4-5-20251101": {
      "id": "claude-opus-4-5-20251101",
      "provider": "abacus",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-01"
    },
    "abacus/qwen-2.5-coder-32b": {
      "id": "qwen-2.5-coder-32b",
      "provider": "abacus",
      "name": "Qwen 2.5 Coder 32B",
      "family": "qwen-2.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00079,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-11-11",
      "open_weights": true
    },
    "abacus/claude-sonnet-4-5-20250929": {
      "id": "claude-sonnet-4-5-20250929",
      "provider": "abacus",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "abacus/openai-gpt-oss-120b": {
      "id": "openai-gpt-oss-120b",
      "provider": "abacus",
      "name": "GPT-OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00044,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "abacus/qwen-qwen3-Max": {
      "id": "qwen-qwen3-Max",
      "provider": "abacus",
      "name": "Qwen3 Max",
      "family": "qwen-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-05-28"
    },
    "abacus/grok-4-0709": {
      "id": "grok-4-0709",
      "provider": "abacus",
      "name": "Grok 4",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-09"
    },
    "abacus/meta-llama-Meta-Llama-3.1-70B-Instruct": {
      "id": "meta-llama-Meta-Llama-3.1-70B-Instruct",
      "provider": "abacus",
      "name": "Llama 3.1 70B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "abacus/o3-mini": {
      "id": "o3-mini",
      "provider": "abacus",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "abacus/zai-org-glm-4.5": {
      "id": "zai-org-glm-4.5",
      "provider": "abacus",
      "name": "GLM-4.5",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "abacus/gemini-2.0-pro-exp-02-05": {
      "id": "gemini-2.0-pro-exp-02-05",
      "provider": "abacus",
      "name": "Gemini 2.0 Pro Exp",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 8192,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "release_date": "2025-02-05"
    },
    "abacus/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "abacus",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "abacus/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "abacus",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "abacus/claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "provider": "abacus",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-05-14"
    },
    "abacus/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "abacus",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "abacus/o4-mini": {
      "id": "o4-mini",
      "provider": "abacus",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "abacus/Qwen-Qwen3-32B": {
      "id": "Qwen-Qwen3-32B",
      "provider": "abacus",
      "name": "Qwen3 32B",
      "family": "qwen-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "abacus/claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "provider": "abacus",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-05-14"
    },
    "abacus/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "abacus",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "abacus/meta-llama-Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "meta-llama-Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "abacus",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "family": "llama-4",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "abacus/o3-pro": {
      "id": "o3-pro",
      "provider": "abacus",
      "name": "o3-pro",
      "family": "o3-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-06-10"
    },
    "abacus/claude-3-7-sonnet-20250219": {
      "id": "claude-3-7-sonnet-20250219",
      "provider": "abacus",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-19"
    },
    "abacus/deepseek-ai-DeepSeek-V3.1-Terminus": {
      "id": "deepseek-ai-DeepSeek-V3.1-Terminus",
      "provider": "abacus",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-01",
      "open_weights": true
    },
    "abacus/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "abacus",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-25"
    },
    "abacus/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "provider": "abacus",
      "name": "GPT-4o (2024-11-20)",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-20"
    },
    "abacus/o3": {
      "id": "o3",
      "provider": "abacus",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "abacus/Qwen-Qwen2.5-72B-Instruct": {
      "id": "Qwen-Qwen2.5-72B-Instruct",
      "provider": "abacus",
      "name": "Qwen 2.5 72B Instruct",
      "family": "qwen-2.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00038,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-09-19",
      "open_weights": true
    },
    "abacus/zai-org-glm-4.6": {
      "id": "zai-org-glm-4.6",
      "provider": "abacus",
      "name": "GLM-4.6",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-03-01",
      "open_weights": true
    },
    "abacus/deepseek-deepseek-v3.1": {
      "id": "deepseek-deepseek-v3.1",
      "provider": "abacus",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00166,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-01",
      "open_weights": true
    },
    "abacus/Qwen-QwQ-32B": {
      "id": "Qwen-QwQ-32B",
      "provider": "abacus",
      "name": "QwQ 32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2024-11-28",
      "open_weights": true
    },
    "abacus/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "provider": "abacus",
      "name": "GPT-4o Mini",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-07-18"
    },
    "abacus/gpt-5": {
      "id": "gpt-5",
      "provider": "abacus",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "abacus/grok-4-1-fast-non-reasoning": {
      "id": "grok-4-1-fast-non-reasoning",
      "provider": "abacus",
      "name": "Grok 4.1 Fast (Non-Reasoning)",
      "family": "grok-4.1",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-11-17"
    },
    "abacus/llama-3.3-70b-versatile": {
      "id": "llama-3.3-70b-versatile",
      "provider": "abacus",
      "name": "Llama 3.3 70B Versatile",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "abacus/claude-opus-4-1-20250805": {
      "id": "claude-opus-4-1-20250805",
      "provider": "abacus",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-05"
    },
    "abacus/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "abacus",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "abacus/gpt-5.1-chat-latest": {
      "id": "gpt-5.1-chat-latest",
      "provider": "abacus",
      "name": "GPT-5.1 Chat Latest",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "abacus/claude-haiku-4-5-20251001": {
      "id": "claude-haiku-4-5-20251001",
      "provider": "abacus",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "vercel/moonshotai/kimi-k2": {
      "id": "moonshotai/kimi-k2",
      "provider": "vercel",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true,
      "deprecated": true
    },
    "vercel/alibaba/qwen3-next-80b-a3b-instruct": {
      "id": "alibaba/qwen3-next-80b-a3b-instruct",
      "provider": "vercel",
      "name": "Qwen3 Next 80B A3B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-12",
      "open_weights": true
    },
    "vercel/alibaba/qwen3-vl-instruct": {
      "id": "alibaba/qwen3-vl-instruct",
      "provider": "vercel",
      "name": "Qwen3 VL Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 129024,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-24",
      "open_weights": true
    },
    "vercel/alibaba/qwen3-vl-thinking": {
      "id": "alibaba/qwen3-vl-thinking",
      "provider": "vercel",
      "name": "Qwen3 VL Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 129024,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0084,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-24",
      "open_weights": true
    },
    "vercel/alibaba/qwen3-max": {
      "id": "alibaba/qwen3-max",
      "provider": "vercel",
      "name": "Qwen3 Max",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-23"
    },
    "vercel/alibaba/qwen3-coder-plus": {
      "id": "alibaba/qwen3-coder-plus",
      "provider": "vercel",
      "name": "Qwen3 Coder Plus",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "vercel/alibaba/qwen3-next-80b-a3b-thinking": {
      "id": "alibaba/qwen3-next-80b-a3b-thinking",
      "provider": "vercel",
      "name": "Qwen3 Next 80B A3B Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-12",
      "open_weights": true
    },
    "vercel/xai/grok-3-mini-fast": {
      "id": "xai/grok-3-mini-fast",
      "provider": "vercel",
      "name": "Grok 3 Mini Fast",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 0.00015,
      "reasoning_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-3-mini": {
      "id": "xai/grok-3-mini",
      "provider": "vercel",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-4-fast": {
      "id": "xai/grok-4-fast",
      "provider": "vercel",
      "name": "Grok 4 Fast",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "vercel/xai/grok-3": {
      "id": "xai/grok-3",
      "provider": "vercel",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-2": {
      "id": "xai/grok-2",
      "provider": "vercel",
      "name": "Grok 2",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "vercel/xai/grok-code-fast-1": {
      "id": "xai/grok-code-fast-1",
      "provider": "vercel",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-08-28"
    },
    "vercel/xai/grok-2-vision": {
      "id": "xai/grok-2-vision",
      "provider": "vercel",
      "name": "Grok 2 Vision",
      "family": "grok-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-20"
    },
    "vercel/xai/grok-4": {
      "id": "xai/grok-4",
      "provider": "vercel",
      "name": "Grok 4",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "reasoning_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "vercel/xai/grok-3-fast": {
      "id": "xai/grok-3-fast",
      "provider": "vercel",
      "name": "Grok 3 Fast",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "vercel/xai/grok-4-fast-non-reasoning": {
      "id": "xai/grok-4-fast-non-reasoning",
      "provider": "vercel",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "vercel/mistral/codestral": {
      "id": "mistral/codestral",
      "provider": "vercel",
      "name": "Codestral",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-05-29",
      "open_weights": true
    },
    "vercel/mistral/magistral-medium": {
      "id": "mistral/magistral-medium",
      "provider": "vercel",
      "name": "Magistral Medium",
      "family": "magistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-03-17",
      "open_weights": true
    },
    "vercel/mistral/mistral-large": {
      "id": "mistral/mistral-large",
      "provider": "vercel",
      "name": "Mistral Large",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "vercel/mistral/pixtral-large": {
      "id": "mistral/pixtral-large",
      "provider": "vercel",
      "name": "Pixtral Large",
      "family": "pixtral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "vercel/mistral/ministral-8b": {
      "id": "mistral/ministral-8b",
      "provider": "vercel",
      "name": "Ministral 8B",
      "family": "ministral-8b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01",
      "open_weights": true
    },
    "vercel/mistral/ministral-3b": {
      "id": "mistral/ministral-3b",
      "provider": "vercel",
      "name": "Ministral 3B",
      "family": "ministral-3b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01",
      "open_weights": true
    },
    "vercel/mistral/magistral-small": {
      "id": "mistral/magistral-small",
      "provider": "vercel",
      "name": "Magistral Small",
      "family": "magistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-03-17",
      "open_weights": true
    },
    "vercel/mistral/mistral-small": {
      "id": "mistral/mistral-small",
      "provider": "vercel",
      "name": "Mistral Small",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2024-09-01",
      "open_weights": true
    },
    "vercel/mistral/pixtral-12b": {
      "id": "mistral/pixtral-12b",
      "provider": "vercel",
      "name": "Pixtral 12B",
      "family": "pixtral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-09-01",
      "open_weights": true
    },
    "vercel/mistral/mixtral-8x22b-instruct": {
      "id": "mistral/mixtral-8x22b-instruct",
      "provider": "vercel",
      "name": "Mixtral 8x22B",
      "family": "mixtral-8x22b",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-17",
      "open_weights": true
    },
    "vercel/vercel/v0-1.0-md": {
      "id": "vercel/v0-1.0-md",
      "provider": "vercel",
      "name": "v0-1.0-md",
      "family": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-05-22"
    },
    "vercel/vercel/v0-1.5-md": {
      "id": "vercel/v0-1.5-md",
      "provider": "vercel",
      "name": "v0-1.5-md",
      "family": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-06-09"
    },
    "vercel/deepseek/deepseek-v3.2-exp-thinking": {
      "id": "deepseek/deepseek-v3.2-exp-thinking",
      "provider": "vercel",
      "name": "DeepSeek V3.2 Exp Thinking",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-29"
    },
    "vercel/deepseek/deepseek-v3.1-terminus": {
      "id": "deepseek/deepseek-v3.1-terminus",
      "provider": "vercel",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-22",
      "open_weights": true
    },
    "vercel/deepseek/deepseek-v3.2-exp": {
      "id": "deepseek/deepseek-v3.2-exp",
      "provider": "vercel",
      "name": "DeepSeek V3.2 Exp",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-29"
    },
    "vercel/deepseek/deepseek-r1-distill-llama-70b": {
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "provider": "vercel",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.00099,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true,
      "deprecated": true
    },
    "vercel/deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "provider": "vercel",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20"
    },
    "vercel/minimax/minimax-m2": {
      "id": "minimax/minimax-m2",
      "provider": "vercel",
      "name": "MiniMax M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 205000,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.00038,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "vercel/google/gemini-3-pro-preview": {
      "id": "google/gemini-3-pro-preview",
      "provider": "vercel",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "vercel/google/gemini-2.5-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "vercel",
      "name": "Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "vercel/google/gemini-2.5-flash-preview-09-2025": {
      "id": "google/gemini-2.5-flash-preview-09-2025",
      "provider": "vercel",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "vercel/google/gemini-2.5-flash-lite-preview-09-2025": {
      "id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "provider": "vercel",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "vercel/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "vercel",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "vercel/google/gemini-2.0-flash": {
      "id": "google/gemini-2.0-flash",
      "provider": "vercel",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "vercel/google/gemini-2.0-flash-lite": {
      "id": "google/gemini-2.0-flash-lite",
      "provider": "vercel",
      "name": "Gemini 2.0 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "vercel/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "vercel",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "vercel/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "vercel",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "vercel/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "vercel",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "vercel/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "vercel",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "vercel/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "vercel",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-07-18"
    },
    "vercel/openai/o3": {
      "id": "openai/o3",
      "provider": "vercel",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "vercel/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "provider": "vercel",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "vercel/openai/o1": {
      "id": "openai/o1",
      "provider": "vercel",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-12-05"
    },
    "vercel/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "vercel",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "vercel/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "vercel",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "vercel/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "provider": "vercel",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "vercel/openai/gpt-5-codex": {
      "id": "openai/gpt-5-codex",
      "provider": "vercel",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "vercel/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "provider": "vercel",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "vercel/openai/o3-mini": {
      "id": "openai/o3-mini",
      "provider": "vercel",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "vercel/openai/gpt-4-turbo": {
      "id": "openai/gpt-4-turbo",
      "provider": "vercel",
      "name": "GPT-4 Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2023-11-06"
    },
    "vercel/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "provider": "vercel",
      "name": "GPT-4.1 mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "vercel/openai/gpt-4.1-nano": {
      "id": "openai/gpt-4.1-nano",
      "provider": "vercel",
      "name": "GPT-4.1 nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "vercel/perplexity/sonar-reasoning": {
      "id": "perplexity/sonar-reasoning",
      "provider": "vercel",
      "name": "Sonar Reasoning",
      "family": "sonar-reasoning",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar": {
      "id": "perplexity/sonar",
      "provider": "vercel",
      "name": "Sonar",
      "family": "sonar",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar-pro": {
      "id": "perplexity/sonar-pro",
      "provider": "vercel",
      "name": "Sonar Pro",
      "family": "sonar-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-02-19"
    },
    "vercel/perplexity/sonar-reasoning-pro": {
      "id": "perplexity/sonar-reasoning-pro",
      "provider": "vercel",
      "name": "Sonar Reasoning Pro",
      "family": "sonar-reasoning",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-02-19"
    },
    "vercel/zai/glm-4.5": {
      "id": "zai/glm-4.5",
      "provider": "vercel",
      "name": "GLM 4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "vercel/zai/glm-4.5-air": {
      "id": "zai/glm-4.5-air",
      "provider": "vercel",
      "name": "GLM 4.5 Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "vercel/zai/glm-4.5v": {
      "id": "zai/glm-4.5v",
      "provider": "vercel",
      "name": "GLM 4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "vercel/zai/glm-4.6": {
      "id": "zai/glm-4.6",
      "provider": "vercel",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "vercel/amazon/nova-micro": {
      "id": "amazon/nova-micro",
      "provider": "vercel",
      "name": "Nova Micro",
      "family": "nova-micro",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "cache_read_cost_per_1k": 8.75e-06,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "vercel/amazon/nova-pro": {
      "id": "amazon/nova-pro",
      "provider": "vercel",
      "name": "Nova Pro",
      "family": "nova-pro",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "vercel/amazon/nova-lite": {
      "id": "amazon/nova-lite",
      "provider": "vercel",
      "name": "Nova Lite",
      "family": "nova-lite",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "cache_read_cost_per_1k": 1.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "vercel/morph/morph-v3-fast": {
      "id": "morph/morph-v3-fast",
      "provider": "vercel",
      "name": "Morph v3 Fast",
      "family": "morph-v3-fast",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0012,
      "release_date": "2024-08-15"
    },
    "vercel/morph/morph-v3-large": {
      "id": "morph/morph-v3-large",
      "provider": "vercel",
      "name": "Morph v3 Large",
      "family": "morph-v3-large",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0019,
      "release_date": "2024-08-15"
    },
    "vercel/meta/llama-4-scout": {
      "id": "meta/llama-4-scout",
      "provider": "vercel",
      "name": "Llama-4-Scout-17B-16E-Instruct-FP8",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "vercel/meta/llama-3.3-70b": {
      "id": "meta/llama-3.3-70b",
      "provider": "vercel",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "vercel/meta/llama-4-maverick": {
      "id": "meta/llama-4-maverick",
      "provider": "vercel",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "vercel/anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "provider": "vercel",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "vercel/anthropic/claude-opus-4.5": {
      "id": "anthropic/claude-opus-4.5",
      "provider": "vercel",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "vercel/anthropic/claude-3.5-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "provider": "vercel",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "vercel/anthropic/claude-3.7-sonnet": {
      "id": "anthropic/claude-3.7-sonnet",
      "provider": "vercel",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-19"
    },
    "vercel/anthropic/claude-4.5-sonnet": {
      "id": "anthropic/claude-4.5-sonnet",
      "provider": "vercel",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "vercel/anthropic/claude-3.5-sonnet": {
      "id": "anthropic/claude-3.5-sonnet",
      "provider": "vercel",
      "name": "Claude Sonnet 3.5 v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-10-22"
    },
    "vercel/anthropic/claude-4-1-opus": {
      "id": "anthropic/claude-4-1-opus",
      "provider": "vercel",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "vercel/anthropic/claude-4-sonnet": {
      "id": "anthropic/claude-4-sonnet",
      "provider": "vercel",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "vercel/anthropic/claude-3-opus": {
      "id": "anthropic/claude-3-opus",
      "provider": "vercel",
      "name": "Claude Opus 3",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-02-29"
    },
    "vercel/anthropic/claude-3-haiku": {
      "id": "anthropic/claude-3-haiku",
      "provider": "vercel",
      "name": "Claude Haiku 3",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-13"
    },
    "vercel/anthropic/claude-4-opus": {
      "id": "anthropic/claude-4-opus",
      "provider": "vercel",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "nebius/NousResearch/hermes-4-70b": {
      "id": "NousResearch/hermes-4-70b",
      "provider": "nebius",
      "name": "Hermes 4 70B",
      "family": "hermes",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-08-01"
    },
    "nebius/NousResearch/hermes-4-405b": {
      "id": "NousResearch/hermes-4-405b",
      "provider": "nebius",
      "name": "Hermes-4 405B",
      "family": "hermes",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-08-01"
    },
    "nebius/moonshotai/kimi-k2-instruct": {
      "id": "moonshotai/kimi-k2-instruct",
      "provider": "nebius",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2025-01-01"
    },
    "nebius/nvidia/llama-3_1-nemotron-ultra-253b-v1": {
      "id": "nvidia/llama-3_1-nemotron-ultra-253b-v1",
      "provider": "nebius",
      "name": "Llama 3.1 Nemotron Ultra 253B v1",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-01"
    },
    "nebius/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "nebius",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "nebius/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "nebius",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "nebius/qwen/qwen3-235b-a22b-instruct-2507": {
      "id": "qwen/qwen3-235b-a22b-instruct-2507",
      "provider": "nebius",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-25"
    },
    "nebius/qwen/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "provider": "nebius",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-25"
    },
    "nebius/qwen/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen/qwen3-coder-480b-a35b-instruct",
      "provider": "nebius",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23"
    },
    "nebius/meta-llama/llama-3_1-405b-instruct": {
      "id": "meta-llama/llama-3_1-405b-instruct",
      "provider": "nebius",
      "name": "Llama 3.1 405B Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-07-23"
    },
    "nebius/meta-llama/llama-3.3-70b-instruct-fast": {
      "id": "meta-llama/llama-3.3-70b-instruct-fast",
      "provider": "nebius",
      "name": "Llama-3.3-70B-Instruct (Fast)",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-22"
    },
    "nebius/meta-llama/llama-3.3-70b-instruct-base": {
      "id": "meta-llama/llama-3.3-70b-instruct-base",
      "provider": "nebius",
      "name": "Llama-3.3-70B-Instruct (Base)",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-22"
    },
    "nebius/zai-org/glm-4.5": {
      "id": "zai-org/glm-4.5",
      "provider": "nebius",
      "name": "GLM 4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-06-01"
    },
    "nebius/zai-org/glm-4.5-air": {
      "id": "zai-org/glm-4.5-air",
      "provider": "nebius",
      "name": "GLM 4.5 Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-06-01"
    },
    "nebius/deepseek-ai/deepseek-v3": {
      "id": "deepseek-ai/deepseek-v3",
      "provider": "nebius",
      "name": "DeepSeek V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-05-07"
    },
    "deepseek/deepseek-chat": {
      "id": "deepseek-chat",
      "provider": "deepseek",
      "name": "DeepSeek Chat",
      "family": "deepseek-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-12-26"
    },
    "deepseek/deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "provider": "deepseek",
      "name": "DeepSeek Reasoner",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-7b": {
      "id": "deepseek-r1-distill-qwen-7b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Qwen 7B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 7.2e-05,
      "output_cost_per_1k": 0.000144,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen3-asr-flash": {
      "id": "qwen3-asr-flash",
      "provider": "alibaba_cn",
      "name": "Qwen3-ASR Flash",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 53248,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3.2e-05,
      "output_cost_per_1k": 3.2e-05,
      "capabilities": [
        "audio_input"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-08"
    },
    "alibaba_cn/deepseek-r1-0528": {
      "id": "deepseek-r1-0528",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.002294,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-05-28"
    },
    "alibaba_cn/deepseek-v3": {
      "id": "deepseek-v3",
      "provider": "alibaba_cn",
      "name": "DeepSeek V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.001147,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "alibaba_cn/qwen-omni-turbo": {
      "id": "qwen-omni-turbo",
      "provider": "alibaba_cn",
      "name": "Qwen-Omni Turbo",
      "family": "qwen-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 5.8e-05,
      "output_cost_per_1k": 0.00023,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-19"
    },
    "alibaba_cn/qwen-vl-max": {
      "id": "qwen-vl-max",
      "provider": "alibaba_cn",
      "name": "Qwen-VL Max",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.000574,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-08"
    },
    "alibaba_cn/deepseek-v3-2-exp": {
      "id": "deepseek-v3-2-exp",
      "provider": "alibaba_cn",
      "name": "DeepSeek V3.2 Exp",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000431,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen3-next-80b-a3b-instruct": {
      "id": "qwen3-next-80b-a3b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen3-Next 80B-A3B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000574,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09",
      "open_weights": true
    },
    "alibaba_cn/deepseek-r1": {
      "id": "deepseek-r1",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.002294,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen-turbo": {
      "id": "qwen-turbo",
      "provider": "alibaba_cn",
      "name": "Qwen Turbo",
      "family": "qwen-turbo",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 4.4e-05,
      "output_cost_per_1k": 8.7e-05,
      "reasoning_cost_per_1k": 0.000431,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-11-01"
    },
    "alibaba_cn/qwen3-vl-235b-a22b": {
      "id": "qwen3-vl-235b-a22b",
      "provider": "alibaba_cn",
      "name": "Qwen3-VL 235B-A22B",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00028671,
      "output_cost_per_1k": 0.00114682,
      "reasoning_cost_per_1k": 0.00286705,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen3-coder-flash": {
      "id": "qwen3-coder-flash",
      "provider": "alibaba_cn",
      "name": "Qwen3 Coder Flash",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000574,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28"
    },
    "alibaba_cn/qwen3-vl-30b-a3b": {
      "id": "qwen3-vl-30b-a3b",
      "provider": "alibaba_cn",
      "name": "Qwen3-VL 30B-A3B",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.000108,
      "output_cost_per_1k": 0.000431,
      "reasoning_cost_per_1k": 0.001076,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen3-14b": {
      "id": "qwen3-14b",
      "provider": "alibaba_cn",
      "name": "Qwen3 14B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000574,
      "reasoning_cost_per_1k": 0.001434,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qvq-max": {
      "id": "qvq-max",
      "provider": "alibaba_cn",
      "name": "QVQ Max",
      "family": "qvq-max",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001147,
      "output_cost_per_1k": 0.004588,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-03-25"
    },
    "alibaba_cn/deepseek-r1-distill-qwen-32b": {
      "id": "deepseek-r1-distill-qwen-32b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen-plus-character": {
      "id": "qwen-plus-character",
      "provider": "alibaba_cn",
      "name": "Qwen Plus Character",
      "family": "qwen-plus",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000115,
      "output_cost_per_1k": 0.000287,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen2-5-14b-instruct": {
      "id": "qwen2-5-14b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5 14B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000431,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwq-plus": {
      "id": "qwq-plus",
      "provider": "alibaba_cn",
      "name": "QwQ Plus",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.000574,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-03-05"
    },
    "alibaba_cn/qwen2-5-coder-32b-instruct": {
      "id": "qwen2-5-coder-32b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-Coder 32B Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-11",
      "open_weights": true
    },
    "alibaba_cn/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen3-coder-30b-a3b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000216,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen-math-plus": {
      "id": "qwen-math-plus",
      "provider": "alibaba_cn",
      "name": "Qwen Math Plus",
      "family": "qwen-math",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.001721,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-08-16"
    },
    "alibaba_cn/qwen-vl-ocr": {
      "id": "qwen-vl-ocr",
      "provider": "alibaba_cn",
      "name": "Qwen-VL OCR",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 34096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000717,
      "output_cost_per_1k": 0.000717,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-10-28"
    },
    "alibaba_cn/qwen-doc-turbo": {
      "id": "qwen-doc-turbo",
      "provider": "alibaba_cn",
      "name": "Qwen Doc Turbo",
      "family": "qwen-doc",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 8.7e-05,
      "output_cost_per_1k": 0.000144,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen-deep-research": {
      "id": "qwen-deep-research",
      "provider": "alibaba_cn",
      "name": "Qwen Deep Research",
      "family": "qwen-deep-research",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.007742,
      "output_cost_per_1k": 0.023367,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen2-5-72b-instruct": {
      "id": "qwen2-5-72b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5 72B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.001721,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwen3-omni-flash": {
      "id": "qwen3-omni-flash",
      "provider": "alibaba_cn",
      "name": "Qwen3-Omni Flash",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5.8e-05,
      "output_cost_per_1k": 0.00023,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-15"
    },
    "alibaba_cn/qwen-flash": {
      "id": "qwen-flash",
      "provider": "alibaba_cn",
      "name": "Qwen Flash",
      "family": "qwen-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 2.2e-05,
      "output_cost_per_1k": 0.000216,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-07-28"
    },
    "alibaba_cn/qwen3-8b": {
      "id": "qwen3-8b",
      "provider": "alibaba_cn",
      "name": "Qwen3 8B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.2e-05,
      "output_cost_per_1k": 0.000287,
      "reasoning_cost_per_1k": 0.000717,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen3-omni-flash-realtime": {
      "id": "qwen3-omni-flash-realtime",
      "provider": "alibaba_cn",
      "name": "Qwen3-Omni Flash Realtime",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.000918,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-15"
    },
    "alibaba_cn/qwen2-5-vl-72b-instruct": {
      "id": "qwen2-5-vl-72b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-VL 72B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.002294,
      "output_cost_per_1k": 0.006881,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwen3-vl-plus": {
      "id": "qwen3-vl-plus",
      "provider": "alibaba_cn",
      "name": "Qwen3-VL Plus",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00014335,
      "output_cost_per_1k": 0.00143352,
      "reasoning_cost_per_1k": 0.00430058,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-23"
    },
    "alibaba_cn/qwen-plus": {
      "id": "qwen-plus",
      "provider": "alibaba_cn",
      "name": "Qwen Plus",
      "family": "qwen-plus",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.000115,
      "output_cost_per_1k": 0.000287,
      "reasoning_cost_per_1k": 0.001147,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01-25"
    },
    "alibaba_cn/qwen2-5-32b-instruct": {
      "id": "qwen2-5-32b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5 32B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwen2-5-omni-7b": {
      "id": "qwen2-5-omni-7b",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-Omni 7B",
      "family": "qwen2.5-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 8.7e-05,
      "output_cost_per_1k": 0.000345,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-12",
      "open_weights": true
    },
    "alibaba_cn/qwen-max": {
      "id": "qwen-max",
      "provider": "alibaba_cn",
      "name": "Qwen Max",
      "family": "qwen-max",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000345,
      "output_cost_per_1k": 0.001377,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-03"
    },
    "alibaba_cn/qwen-long": {
      "id": "qwen-long",
      "provider": "alibaba_cn",
      "name": "Qwen Long",
      "family": "qwen-long",
      "mode": "chat",
      "max_input_tokens": 10000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.2e-05,
      "output_cost_per_1k": 0.000287,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-25"
    },
    "alibaba_cn/qwen2-5-math-72b-instruct": {
      "id": "qwen2-5-math-72b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-Math 72B Instruct",
      "family": "qwen2.5-math",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.001721,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/moonshot-kimi-k2-instruct": {
      "id": "moonshot-kimi-k2-instruct",
      "provider": "alibaba_cn",
      "name": "Moonshot Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.002294,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/tongyi-intent-detect-v3": {
      "id": "tongyi-intent-detect-v3",
      "provider": "alibaba_cn",
      "name": "Tongyi Intent Detect V3",
      "family": "yi",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 5.8e-05,
      "output_cost_per_1k": 0.000144,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01"
    },
    "alibaba_cn/qwen2-5-7b-instruct": {
      "id": "qwen2-5-7b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5 7B Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.2e-05,
      "output_cost_per_1k": 0.000144,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwen2-5-vl-7b-instruct": {
      "id": "qwen2-5-vl-7b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-VL 7B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000717,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/deepseek-v3-1": {
      "id": "deepseek-v3-1",
      "provider": "alibaba_cn",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000574,
      "output_cost_per_1k": 0.001721,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen3-235b-a22b": {
      "id": "qwen3-235b-a22b",
      "provider": "alibaba_cn",
      "name": "Qwen3 235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.001147,
      "reasoning_cost_per_1k": 0.002868,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen2-5-coder-7b-instruct": {
      "id": "qwen2-5-coder-7b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-Coder 7B Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000287,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-11",
      "open_weights": true
    },
    "alibaba_cn/deepseek-r1-distill-qwen-14b": {
      "id": "deepseek-r1-distill-qwen-14b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Qwen 14B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000431,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen-omni-turbo-realtime": {
      "id": "qwen-omni-turbo-realtime",
      "provider": "alibaba_cn",
      "name": "Qwen-Omni Turbo Realtime",
      "family": "qwen-omni",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.000918,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-08"
    },
    "alibaba_cn/qwen-math-turbo": {
      "id": "qwen-math-turbo",
      "provider": "alibaba_cn",
      "name": "Qwen Math Turbo",
      "family": "qwen-math",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09-19"
    },
    "alibaba_cn/qwen-mt-turbo": {
      "id": "qwen-mt-turbo",
      "provider": "alibaba_cn",
      "name": "Qwen-MT Turbo",
      "family": "qwen-mt",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000101,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01"
    },
    "alibaba_cn/deepseek-r1-distill-llama-8b": {
      "id": "deepseek-r1-distill-llama-8b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Llama 8B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen3-coder-480b-a35b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen3-Coder 480B-A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000861,
      "output_cost_per_1k": 0.003441,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen-mt-plus": {
      "id": "qwen-mt-plus",
      "provider": "alibaba_cn",
      "name": "Qwen-MT Plus",
      "family": "qwen-mt",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000259,
      "output_cost_per_1k": 0.000775,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01"
    },
    "alibaba_cn/qwen3-max": {
      "id": "qwen3-max",
      "provider": "alibaba_cn",
      "name": "Qwen3 Max",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.000861,
      "output_cost_per_1k": 0.003441,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-23"
    },
    "alibaba_cn/qwq-32b": {
      "id": "qwq-32b",
      "provider": "alibaba_cn",
      "name": "QwQ 32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.000861,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-12",
      "open_weights": true
    },
    "alibaba_cn/qwen2-5-math-7b-instruct": {
      "id": "qwen2-5-math-7b-instruct",
      "provider": "alibaba_cn",
      "name": "Qwen2.5-Math 7B Instruct",
      "family": "qwen2.5-math",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.000287,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-09",
      "open_weights": true
    },
    "alibaba_cn/qwen3-next-80b-a3b-thinking": {
      "id": "qwen3-next-80b-a3b-thinking",
      "provider": "alibaba_cn",
      "name": "Qwen3-Next 80B-A3B (Thinking)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.000144,
      "output_cost_per_1k": 0.001434,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09",
      "open_weights": true
    },
    "alibaba_cn/deepseek-r1-distill-qwen-1-5b": {
      "id": "deepseek-r1-distill-qwen-1-5b",
      "provider": "alibaba_cn",
      "name": "DeepSeek R1 Distill Qwen 1.5B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "alibaba_cn/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "alibaba_cn",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.000287,
      "output_cost_per_1k": 0.001147,
      "reasoning_cost_per_1k": 0.002868,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "alibaba_cn/qwen-vl-plus": {
      "id": "qwen-vl-plus",
      "provider": "alibaba_cn",
      "name": "Qwen-VL Plus",
      "family": "qwen-vl",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000115,
      "output_cost_per_1k": 0.000287,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-01-25"
    },
    "alibaba_cn/qwen3-coder-plus": {
      "id": "qwen3-coder-plus",
      "provider": "alibaba_cn",
      "name": "Qwen3 Coder Plus",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "google_vertex_anthropic/claude-opus-4-5@20251101": {
      "id": "claude-opus-4-5@20251101",
      "provider": "google_vertex_anthropic",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "google_vertex_anthropic/claude-3-5-sonnet@20241022": {
      "id": "claude-3-5-sonnet@20241022",
      "provider": "google_vertex_anthropic",
      "name": "Claude Sonnet 3.5 v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-10-22"
    },
    "google_vertex_anthropic/claude-3-5-haiku@20241022": {
      "id": "claude-3-5-haiku@20241022",
      "provider": "google_vertex_anthropic",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "google_vertex_anthropic/claude-sonnet-4@20250514": {
      "id": "claude-sonnet-4@20250514",
      "provider": "google_vertex_anthropic",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "google_vertex_anthropic/claude-sonnet-4-5@20250929": {
      "id": "claude-sonnet-4-5@20250929",
      "provider": "google_vertex_anthropic",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "google_vertex_anthropic/claude-opus-4-1@20250805": {
      "id": "claude-opus-4-1@20250805",
      "provider": "google_vertex_anthropic",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "google_vertex_anthropic/claude-haiku-4-5@20251001": {
      "id": "claude-haiku-4-5@20251001",
      "provider": "google_vertex_anthropic",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "google_vertex_anthropic/claude-3-7-sonnet@20250219": {
      "id": "claude-3-7-sonnet@20250219",
      "provider": "google_vertex_anthropic",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-19"
    },
    "google_vertex_anthropic/claude-opus-4@20250514": {
      "id": "claude-opus-4@20250514",
      "provider": "google_vertex_anthropic",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "venice/grok-41-fast": {
      "id": "grok-41-fast",
      "provider": "venice",
      "name": "Grok 4.1 Fast",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-12-01"
    },
    "venice/qwen3-235b-a22b-instruct-2507": {
      "id": "qwen3-235b-a22b-instruct-2507",
      "provider": "venice",
      "name": "Qwen 3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "venice/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "provider": "venice",
      "name": "Gemini 3 Flash Preview",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.00375,
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-19"
    },
    "venice/claude-opus-45": {
      "id": "claude-opus-45",
      "provider": "venice",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "input_cost_per_1k": 0.006,
      "output_cost_per_1k": 0.03,
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-12-06"
    },
    "venice/mistral-31-24b": {
      "id": "mistral-31-24b",
      "provider": "venice",
      "name": "Venice Medium",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-03-18",
      "open_weights": true
    },
    "venice/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "venice",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00187,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-01"
    },
    "venice/zai-org-glm-4.7": {
      "id": "zai-org-glm-4.7",
      "provider": "venice",
      "name": "GLM 4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-24",
      "open_weights": true
    },
    "venice/venice-uncensored": {
      "id": "venice-uncensored",
      "provider": "venice",
      "name": "Venice Uncensored 1.1",
      "family": "venice-uncensored",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-03-18",
      "open_weights": true
    },
    "venice/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "venice",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.000625,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-12-02"
    },
    "venice/openai-gpt-52": {
      "id": "openai-gpt-52",
      "provider": "venice",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00219,
      "output_cost_per_1k": 0.0175,
      "cache_read_cost_per_1k": 0.000219,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-13"
    },
    "venice/qwen3-4b": {
      "id": "qwen3-4b",
      "provider": "venice",
      "name": "Venice Small",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "venice/llama-3.3-70b": {
      "id": "llama-3.3-70b",
      "provider": "venice",
      "name": "Llama 3.3 70B",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0028,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-04-06",
      "open_weights": true
    },
    "venice/openai-gpt-oss-120b": {
      "id": "openai-gpt-oss-120b",
      "provider": "venice",
      "name": "OpenAI GPT OSS 120B",
      "family": "openai-gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "venice/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "venice",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.0032,
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-12-10",
      "open_weights": true
    },
    "venice/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen3-235b-a22b-thinking-2507",
      "provider": "venice",
      "name": "Qwen 3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "venice/llama-3.2-3b": {
      "id": "llama-3.2-3b",
      "provider": "venice",
      "name": "Llama 3.2 3B",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-10-03",
      "open_weights": true
    },
    "venice/google-gemma-3-27b-it": {
      "id": "google-gemma-3-27b-it",
      "provider": "venice",
      "name": "Google Gemma 3 27B Instruct",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11-04",
      "open_weights": true
    },
    "venice/hermes-3-llama-3.1-405b": {
      "id": "hermes-3-llama-3.1-405b",
      "provider": "venice",
      "name": "Hermes 3 Llama 3.1 405b",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-25",
      "open_weights": true
    },
    "venice/zai-org-glm-4.6v": {
      "id": "zai-org-glm-4.6v",
      "provider": "venice",
      "name": "GLM 4.6V",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00039,
      "output_cost_per_1k": 0.00113,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-11",
      "open_weights": true
    },
    "venice/minimax-m21": {
      "id": "minimax-m21",
      "provider": "venice",
      "name": "MiniMax M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-01"
    },
    "venice/qwen3-next-80b": {
      "id": "qwen3-next-80b",
      "provider": "venice",
      "name": "Qwen 3 Next 80b",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0019,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "venice/zai-org-glm-4.6": {
      "id": "zai-org-glm-4.6",
      "provider": "venice",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 50688,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-10-18",
      "open_weights": true
    },
    "venice/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen3-coder-480b-a35b-instruct",
      "provider": "venice",
      "name": "Qwen 3 Coder 480b",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "venice/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "venice",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.001,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-10",
      "release_date": "2025-12-04",
      "open_weights": true
    },
    "siliconflow_cn/inclusionAI/Ring-flash-2.0": {
      "id": "inclusionAI/Ring-flash-2.0",
      "provider": "siliconflow_cn",
      "name": "inclusionAI/Ring-flash-2.0",
      "family": "inclusionai-ring-flash",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-29"
    },
    "siliconflow_cn/inclusionAI/Ling-flash-2.0": {
      "id": "inclusionAI/Ling-flash-2.0",
      "provider": "siliconflow_cn",
      "name": "inclusionAI/Ling-flash-2.0",
      "family": "inclusionai-ling-flash",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/inclusionAI/Ling-mini-2.0": {
      "id": "inclusionAI/Ling-mini-2.0",
      "provider": "siliconflow_cn",
      "name": "inclusionAI/Ling-mini-2.0",
      "family": "inclusionai-ling-mini",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-10"
    },
    "siliconflow_cn/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "siliconflow_cn",
      "name": "moonshotai/Kimi-K2-Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-11-07"
    },
    "siliconflow_cn/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "siliconflow_cn",
      "name": "moonshotai/Kimi-K2-Instruct-0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-08"
    },
    "siliconflow_cn/moonshotai/Kimi-Dev-72B": {
      "id": "moonshotai/Kimi-Dev-72B",
      "provider": "siliconflow_cn",
      "name": "moonshotai/Kimi-Dev-72B",
      "family": "kimi",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-06-19"
    },
    "siliconflow_cn/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "siliconflow_cn",
      "name": "moonshotai/Kimi-K2-Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00229,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-13"
    },
    "siliconflow_cn/tencent/Hunyuan-A13B-Instruct": {
      "id": "tencent/Hunyuan-A13B-Instruct",
      "provider": "siliconflow_cn",
      "name": "tencent/Hunyuan-A13B-Instruct",
      "family": "hunyuan",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-06-30"
    },
    "siliconflow_cn/tencent/Hunyuan-MT-7B": {
      "id": "tencent/Hunyuan-MT-7B",
      "provider": "siliconflow_cn",
      "name": "tencent/Hunyuan-MT-7B",
      "family": "hunyuan",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/MiniMaxAI/MiniMax-M1-80k": {
      "id": "MiniMaxAI/MiniMax-M1-80k",
      "provider": "siliconflow_cn",
      "name": "MiniMaxAI/MiniMax-M1-80k",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-17"
    },
    "siliconflow_cn/MiniMaxAI/MiniMax-M2": {
      "id": "MiniMaxAI/MiniMax-M2",
      "provider": "siliconflow_cn",
      "name": "MiniMaxAI/MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 197000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-28"
    },
    "siliconflow_cn/THUDM/GLM-Z1-32B-0414": {
      "id": "THUDM/GLM-Z1-32B-0414",
      "provider": "siliconflow_cn",
      "name": "THUDM/GLM-Z1-32B-0414",
      "family": "glm-z1",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/THUDM/GLM-4-9B-0414": {
      "id": "THUDM/GLM-4-9B-0414",
      "provider": "siliconflow_cn",
      "name": "THUDM/GLM-4-9B-0414",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 8.6e-05,
      "output_cost_per_1k": 8.6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/THUDM/GLM-Z1-9B-0414": {
      "id": "THUDM/GLM-Z1-9B-0414",
      "provider": "siliconflow_cn",
      "name": "THUDM/GLM-Z1-9B-0414",
      "family": "glm-z1",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 8.6e-05,
      "output_cost_per_1k": 8.6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/THUDM/GLM-4.1V-9B-Thinking": {
      "id": "THUDM/GLM-4.1V-9B-Thinking",
      "provider": "siliconflow_cn",
      "name": "THUDM/GLM-4.1V-9B-Thinking",
      "family": "glm-4v",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-04"
    },
    "siliconflow_cn/THUDM/GLM-4-32B-0414": {
      "id": "THUDM/GLM-4-32B-0414",
      "provider": "siliconflow_cn",
      "name": "THUDM/GLM-4-32B-0414",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow_cn/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "siliconflow_cn",
      "name": "openai/gpt-oss-120b",
      "family": "openai-gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "siliconflow_cn",
      "name": "openai/gpt-oss-20b",
      "family": "openai-gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/stepfun-ai/step3": {
      "id": "stepfun-ai/step3",
      "provider": "siliconflow_cn",
      "name": "stepfun-ai/step3",
      "family": "stepfun-ai-step3",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.00057,
      "output_cost_per_1k": 0.00142,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-06"
    },
    "siliconflow_cn/nex-agi/DeepSeek-V3.1-Nex-N1": {
      "id": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "provider": "siliconflow_cn",
      "name": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "siliconflow_cn/baidu/ERNIE-4.5-300B-A47B": {
      "id": "baidu/ERNIE-4.5-300B-A47B",
      "provider": "siliconflow_cn",
      "name": "baidu/ERNIE-4.5-300B-A47B",
      "family": "ernie-4",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-02"
    },
    "siliconflow_cn/z-ai/GLM-4.5-Air": {
      "id": "z-ai/GLM-4.5-Air",
      "provider": "siliconflow_cn",
      "name": "z-ai/GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/z-ai/GLM-4.5": {
      "id": "z-ai/GLM-4.5",
      "provider": "siliconflow_cn",
      "name": "z-ai/GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/ByteDance-Seed/Seed-OSS-36B-Instruct": {
      "id": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "provider": "siliconflow_cn",
      "name": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "family": "bytedance-seed-seed-oss",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-04"
    },
    "siliconflow_cn/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "provider": "siliconflow_cn",
      "name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-23"
    },
    "siliconflow_cn/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-25"
    },
    "siliconflow_cn/Qwen/Qwen2.5-14B-Instruct": {
      "id": "Qwen/Qwen2.5-14B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-14B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-32B-Instruct": {
      "id": "Qwen/Qwen3-VL-32B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-32B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-21"
    },
    "siliconflow_cn/Qwen/Qwen3-Omni-30B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-32B-Thinking": {
      "id": "Qwen/Qwen3-VL-32B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-32B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-21"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-30B-A3B-Thinking": {
      "id": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-11"
    },
    "siliconflow_cn/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-30"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-235B-A22B-Thinking": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-31"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-235B-A22B-Instruct": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-8B-Instruct": {
      "id": "Qwen/Qwen3-VL-8B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-8B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "siliconflow_cn/Qwen/Qwen3-32B": {
      "id": "Qwen/Qwen3-32B",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/Qwen/Qwen2.5-VL-7B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-7B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-VL-7B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-28"
    },
    "siliconflow_cn/Qwen/QwQ-32B": {
      "id": "Qwen/QwQ-32B",
      "provider": "siliconflow_cn",
      "name": "Qwen/QwQ-32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00058,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-03-06"
    },
    "siliconflow_cn/Qwen/Qwen2.5-VL-72B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-28"
    },
    "siliconflow_cn/Qwen/Qwen3-235B-A22B": {
      "id": "Qwen/Qwen3-235B-A22B",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00142,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/Qwen/Qwen2.5-7B-Instruct": {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-7B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-08-01"
    },
    "siliconflow_cn/Qwen/Qwen2.5-72B-Instruct": {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-72B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/Qwen/Qwen2.5-72B-Instruct-128K": {
      "id": "Qwen/Qwen2.5-72B-Instruct-128K",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-72B-Instruct-128K",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow_cn/Qwen/Qwen2.5-32B-Instruct": {
      "id": "Qwen/Qwen2.5-32B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-32B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-19"
    },
    "siliconflow_cn/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-11-11"
    },
    "siliconflow_cn/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-23"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-8B-Thinking": {
      "id": "Qwen/Qwen3-VL-8B-Thinking",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-8B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "siliconflow_cn/Qwen/Qwen3-Omni-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/Qwen/Qwen3-8B": {
      "id": "Qwen/Qwen3-8B",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-8B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/Qwen/Qwen3-Omni-30B-A3B-Captioner": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/Qwen/Qwen2.5-VL-32B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen2.5-VL-32B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-03-24"
    },
    "siliconflow_cn/Qwen/Qwen3-14B": {
      "id": "Qwen/Qwen3-14B",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-14B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/Qwen/Qwen3-VL-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-05"
    },
    "siliconflow_cn/Qwen/Qwen3-30B-A3B-Thinking-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-31"
    },
    "siliconflow_cn/Qwen/Qwen3-30B-A3B": {
      "id": "Qwen/Qwen3-30B-A3B",
      "provider": "siliconflow_cn",
      "name": "Qwen/Qwen3-30B-A3B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow_cn/zai-org/GLM-4.5-Air": {
      "id": "zai-org/GLM-4.5-Air",
      "provider": "siliconflow_cn",
      "name": "zai-org/GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/zai-org/GLM-4.5V": {
      "id": "zai-org/GLM-4.5V",
      "provider": "siliconflow_cn",
      "name": "zai-org/GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow_cn/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "siliconflow_cn",
      "name": "zai-org/GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 205000,
      "max_output_tokens": 205000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0019,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow_cn/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "provider": "siliconflow_cn",
      "name": "zai-org/GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-25"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-12-26"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-29"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-V3.2-Exp": {
      "id": "deepseek-ai/DeepSeek-V3.2-Exp",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-V3.2-Exp",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-10"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai/deepseek-vl2": {
      "id": "deepseek-ai/deepseek-vl2",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/deepseek-vl2",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 4000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2024-12-13"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow_cn/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "provider": "siliconflow_cn",
      "name": "deepseek-ai/DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00218,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-05-28"
    },
    "chutes/NousResearch/Hermes-4.3-36B": {
      "id": "NousResearch/Hermes-4.3-36B",
      "provider": "chutes",
      "name": "Hermes 4.3 36B",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00039,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/NousResearch/Hermes-4-70B": {
      "id": "NousResearch/Hermes-4-70B",
      "provider": "chutes",
      "name": "Hermes 4 70B",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00038,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/NousResearch/Hermes-4-14B": {
      "id": "NousResearch/Hermes-4-14B",
      "provider": "chutes",
      "name": "Hermes 4 14B",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 5e-05,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/NousResearch/Hermes-4-405B-FP8-TEE": {
      "id": "NousResearch/Hermes-4-405B-FP8-TEE",
      "provider": "chutes",
      "name": "Hermes 4 405B FP8 TEE",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/NousResearch/Hermes-4-405B-FP8": {
      "id": "NousResearch/Hermes-4-405B-FP8",
      "provider": "chutes",
      "name": "Hermes 4 405B FP8",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/NousResearch/DeepHermes-3-Mistral-24B-Preview": {
      "id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
      "provider": "chutes",
      "name": "DeepHermes 3 Mistral 24B Preview",
      "family": "nousresearch",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0001,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/rednote-hilab/dots.ocr": {
      "id": "rednote-hilab/dots.ocr",
      "provider": "chutes",
      "name": "dots.ocr",
      "family": "rednote-hilab",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 1e-05,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "chutes",
      "name": "Kimi K2 Instruct 0905",
      "family": "moonshotai",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00039,
      "output_cost_per_1k": 0.0019,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/moonshotai/Kimi-K2-Thinking-TEE": {
      "id": "moonshotai/Kimi-K2-Thinking-TEE",
      "provider": "chutes",
      "name": "Kimi K2 Thinking TEE",
      "family": "moonshotai",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.00175,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.002625,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/MiniMaxAI/MiniMax-M2": {
      "id": "MiniMaxAI/MiniMax-M2",
      "provider": "chutes",
      "name": "MiniMax M2",
      "family": "minimaxai",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 196608,
      "input_cost_per_1k": 0.00026,
      "output_cost_per_1k": 0.00102,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00153,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/MiniMaxAI/MiniMax-M2.1-TEE": {
      "id": "MiniMaxAI/MiniMax-M2.1-TEE",
      "provider": "chutes",
      "name": "MiniMax M2.1 TEE",
      "family": "minimaxai",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16": {
      "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
      "provider": "chutes",
      "name": "NVIDIA Nemotron 3 Nano 30B A3B BF16",
      "family": "nvidia",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/ArliAI/QwQ-32B-ArliAI-RpR-v1": {
      "id": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
      "provider": "chutes",
      "name": "QwQ 32B ArliAI RpR v1",
      "family": "arliai",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00011,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000165,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/tngtech/DeepSeek-R1T-Chimera": {
      "id": "tngtech/DeepSeek-R1T-Chimera",
      "provider": "chutes",
      "name": "DeepSeek R1T Chimera",
      "family": "tngtech",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/tngtech/DeepSeek-TNG-R1T2-Chimera": {
      "id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
      "provider": "chutes",
      "name": "DeepSeek TNG R1T2 Chimera",
      "family": "tngtech",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/tngtech/TNG-R1T-Chimera-TEE": {
      "id": "tngtech/TNG-R1T-Chimera-TEE",
      "provider": "chutes",
      "name": "TNG R1T Chimera TEE",
      "family": "tngtech",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/XiaomiMiMo/MiMo-V2-Flash": {
      "id": "XiaomiMiMo/MiMo-V2-Flash",
      "provider": "chutes",
      "name": "MiMo V2 Flash",
      "family": "xiaomimimo",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00065,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/OpenGVLab/InternVL3-78B": {
      "id": "OpenGVLab/InternVL3-78B",
      "provider": "chutes",
      "name": "InternVL3 78B",
      "family": "opengvlab",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00039,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/openai/gpt-oss-120b-TEE": {
      "id": "openai/gpt-oss-120b-TEE",
      "provider": "chutes",
      "name": "gpt oss 120b TEE",
      "family": "openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00025,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "chutes",
      "name": "gpt oss 20b",
      "family": "openai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0001,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/chutesai/Mistral-Small-3.1-24B-Instruct-2503": {
      "id": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
      "provider": "chutes",
      "name": "Mistral Small 3.1 24B Instruct 2503",
      "family": "chutesai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00011,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/chutesai/Mistral-Small-3.2-24B-Instruct-2506": {
      "id": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
      "provider": "chutes",
      "name": "Mistral Small 3.2 24B Instruct 2506",
      "family": "chutesai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00018,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B": {
      "id": "Alibaba-NLP/Tongyi-DeepResearch-30B-A3B",
      "provider": "chutes",
      "name": "Tongyi DeepResearch 30B A3B",
      "family": "alibaba-nlp",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00039,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000585,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/mistralai/Devstral-2-123B-Instruct-2512": {
      "id": "mistralai/Devstral-2-123B-Instruct-2512",
      "provider": "chutes",
      "name": "Devstral 2 123B Instruct 2512",
      "family": "mistralai",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/unsloth/Mistral-Nemo-Instruct-2407": {
      "id": "unsloth/Mistral-Nemo-Instruct-2407",
      "provider": "chutes",
      "name": "Mistral Nemo Instruct 2407",
      "family": "unsloth",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 4e-05,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/unsloth/gemma-3-4b-it": {
      "id": "unsloth/gemma-3-4b-it",
      "provider": "chutes",
      "name": "gemma 3 4b it",
      "family": "unsloth",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 3e-05,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/unsloth/Mistral-Small-24B-Instruct-2501": {
      "id": "unsloth/Mistral-Small-24B-Instruct-2501",
      "provider": "chutes",
      "name": "Mistral Small 24B Instruct 2501",
      "family": "unsloth",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00011,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/unsloth/gemma-3-12b-it": {
      "id": "unsloth/gemma-3-12b-it",
      "provider": "chutes",
      "name": "gemma 3 12b it",
      "family": "unsloth",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.0001,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/unsloth/gemma-3-27b-it": {
      "id": "unsloth/gemma-3-27b-it",
      "provider": "chutes",
      "name": "gemma 3 27b it",
      "family": "unsloth",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00015,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-30B-A3B": {
      "id": "Qwen/Qwen3-30B-A3B",
      "provider": "chutes",
      "name": "Qwen3 30B A3B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00033,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-14B": {
      "id": "Qwen/Qwen3-14B",
      "provider": "chutes",
      "name": "Qwen3 14B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00033,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen2.5-VL-32B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "provider": "chutes",
      "name": "Qwen2.5 VL 32B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3Guard-Gen-0.6B": {
      "id": "Qwen/Qwen3Guard-Gen-0.6B",
      "provider": "chutes",
      "name": "Qwen3Guard Gen 0.6B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 1e-05,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "chutes",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00055,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "chutes",
      "name": "Qwen2.5 Coder 32B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00011,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen2.5-72B-Instruct": {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "provider": "chutes",
      "name": "Qwen2.5 72B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen2.5-VL-72B-Instruct-TEE": {
      "id": "Qwen/Qwen2.5-VL-72B-Instruct-TEE",
      "provider": "chutes",
      "name": "Qwen2.5 VL 72B Instruct TEE",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-235B-A22B": {
      "id": "Qwen/Qwen3-235B-A22B",
      "provider": "chutes",
      "name": "Qwen3 235B A22B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen2.5-VL-72B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "provider": "chutes",
      "name": "Qwen2.5 VL 72B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00026,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-235B-A22B-Instruct-2507-TEE": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
      "provider": "chutes",
      "name": "Qwen3 235B A22B Instruct 2507 TEE",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00055,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-32B": {
      "id": "Qwen/Qwen3-32B",
      "provider": "chutes",
      "name": "Qwen3 32B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00024,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00036,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-VL-235B-A22B-Instruct": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "provider": "chutes",
      "name": "Qwen3 VL 235B A22B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-VL-235B-A22B-Thinking": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "provider": "chutes",
      "name": "Qwen3 VL 235B A22B Thinking",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "provider": "chutes",
      "name": "Qwen3 30B A3B Instruct 2507",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00033,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
      "provider": "chutes",
      "name": "Qwen3 Coder 480B A35B Instruct FP8 TEE",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00095,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "chutes",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "chutes",
      "name": "Qwen3 Next 80B A3B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0008,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/zai-org/GLM-4.6-TEE": {
      "id": "zai-org/GLM-4.6-TEE",
      "provider": "chutes",
      "name": "GLM 4.6 TEE",
      "family": "zai-org",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.00175,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.002625,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/zai-org/GLM-4.5-TEE": {
      "id": "zai-org/GLM-4.5-TEE",
      "provider": "chutes",
      "name": "GLM 4.5 TEE",
      "family": "zai-org",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00155,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.002325,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/zai-org/GLM-4.6V": {
      "id": "zai-org/GLM-4.6V",
      "provider": "chutes",
      "name": "GLM 4.6V",
      "family": "zai-org",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00135,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/zai-org/GLM-4.7-TEE": {
      "id": "zai-org/GLM-4.7-TEE",
      "provider": "chutes",
      "name": "GLM 4.7 TEE",
      "family": "zai-org",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00225,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/zai-org/GLM-4.5-Air": {
      "id": "zai-org/GLM-4.5-Air",
      "provider": "chutes",
      "name": "GLM 4.5 Air",
      "family": "zai-org",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00033,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3-0324-TEE": {
      "id": "deepseek-ai/DeepSeek-V3-0324-TEE",
      "provider": "chutes",
      "name": "DeepSeek V3 0324 TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00024,
      "output_cost_per_1k": 0.00084,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3.2-Speciale-TEE": {
      "id": "deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
      "provider": "chutes",
      "name": "DeepSeek V3.2 Speciale TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000615,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3.1-Terminus-TEE": {
      "id": "deepseek-ai/DeepSeek-V3.1-Terminus-TEE",
      "provider": "chutes",
      "name": "DeepSeek V3.1 Terminus TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00023,
      "output_cost_per_1k": 0.0009,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.00135,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "provider": "chutes",
      "name": "DeepSeek V3",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-R1-TEE": {
      "id": "deepseek-ai/DeepSeek-R1-TEE",
      "provider": "chutes",
      "name": "DeepSeek R1 TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0018,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
      "provider": "chutes",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00011,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000165,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "provider": "chutes",
      "name": "DeepSeek V3.1",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-R1-0528-TEE": {
      "id": "deepseek-ai/DeepSeek-R1-0528-TEE",
      "provider": "chutes",
      "name": "DeepSeek R1 0528 TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.00175,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.002625,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3.2-TEE": {
      "id": "deepseek-ai/DeepSeek-V3.2-TEE",
      "provider": "chutes",
      "name": "DeepSeek V3.2 TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.000615,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "chutes/deepseek-ai/DeepSeek-V3.1-TEE": {
      "id": "deepseek-ai/DeepSeek-V3.1-TEE",
      "provider": "chutes",
      "name": "DeepSeek V3.1 TEE",
      "family": "deepseek-ai",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "reasoning_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-29",
      "open_weights": true
    },
    "kimi_for_coding/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "kimi_for_coding",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11",
      "open_weights": true
    },
    "cortecs/nova-pro-v1": {
      "id": "nova-pro-v1",
      "provider": "cortecs",
      "name": "Nova Pro 1.0",
      "family": "nova-pro",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 5000,
      "input_cost_per_1k": 0.001016,
      "output_cost_per_1k": 0.004061,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-12-03"
    },
    "cortecs/devstral-2512": {
      "id": "devstral-2512",
      "provider": "cortecs",
      "name": "Devstral 2 2512",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-09",
      "open_weights": true
    },
    "cortecs/intellect-3": {
      "id": "intellect-3",
      "provider": "cortecs",
      "name": "INTELLECT 3",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000219,
      "output_cost_per_1k": 0.001202,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-26",
      "open_weights": true
    },
    "cortecs/claude-4-5-sonnet": {
      "id": "claude-4-5-sonnet",
      "provider": "cortecs",
      "name": "Claude 4.5 Sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.003259,
      "output_cost_per_1k": 0.016296,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "cortecs/deepseek-v3-0324": {
      "id": "deepseek-v3-0324",
      "provider": "cortecs",
      "name": "DeepSeek V3 0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000551,
      "output_cost_per_1k": 0.001654,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "cortecs/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "cortecs",
      "name": "Kimi K2 Thinking",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.000656,
      "output_cost_per_1k": 0.002731,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "cortecs/kimi-k2-instruct": {
      "id": "kimi-k2-instruct",
      "provider": "cortecs",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.000551,
      "output_cost_per_1k": 0.002646,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "cortecs/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "cortecs",
      "name": "GPT 4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002354,
      "output_cost_per_1k": 0.009417,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-04-14"
    },
    "cortecs/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "cortecs",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.001654,
      "output_cost_per_1k": 0.011024,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "cortecs/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "cortecs",
      "name": "GPT Oss 120b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "cortecs/devstral-small-2512": {
      "id": "devstral-small-2512",
      "provider": "cortecs",
      "name": "Devstral Small 2 2512",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-09",
      "open_weights": true
    },
    "cortecs/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen3-coder-480b-a35b-instruct",
      "provider": "cortecs",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.000441,
      "output_cost_per_1k": 0.001984,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "cortecs/claude-sonnet-4": {
      "id": "claude-sonnet-4",
      "provider": "cortecs",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003307,
      "output_cost_per_1k": 0.016536,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-05-22"
    },
    "cortecs/llama-3.1-405b-instruct": {
      "id": "llama-3.1-405b-instruct",
      "provider": "cortecs",
      "name": "Llama 3.1 405B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "cortecs/qwen3-next-80b-a3b-thinking": {
      "id": "qwen3-next-80b-a3b-thinking",
      "provider": "cortecs",
      "name": "Qwen3 Next 80B A3B Thinking",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.000164,
      "output_cost_per_1k": 0.001311,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-11",
      "open_weights": true
    },
    "cortecs/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "cortecs",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 9.9e-05,
      "output_cost_per_1k": 0.00033,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "github_models/core42/jais-30b-chat": {
      "id": "core42/jais-30b-chat",
      "provider": "github_models",
      "name": "JAIS 30b Chat",
      "family": "jais",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-03",
      "release_date": "2023-08-30",
      "open_weights": true
    },
    "github_models/xai/grok-3": {
      "id": "xai/grok-3",
      "provider": "github_models",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-09"
    },
    "github_models/xai/grok-3-mini": {
      "id": "xai/grok-3-mini",
      "provider": "github_models",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-09"
    },
    "github_models/cohere/cohere-command-r-08-2024": {
      "id": "cohere/cohere-command-r-08-2024",
      "provider": "github_models",
      "name": "Cohere Command R 08-2024",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-08-01"
    },
    "github_models/cohere/cohere-command-a": {
      "id": "cohere/cohere-command-a",
      "provider": "github_models",
      "name": "Cohere Command A",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-11-01"
    },
    "github_models/cohere/cohere-command-r-plus-08-2024": {
      "id": "cohere/cohere-command-r-plus-08-2024",
      "provider": "github_models",
      "name": "Cohere Command R+ 08-2024",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-08-01"
    },
    "github_models/cohere/cohere-command-r": {
      "id": "cohere/cohere-command-r",
      "provider": "github_models",
      "name": "Cohere Command R",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-03-11"
    },
    "github_models/cohere/cohere-command-r-plus": {
      "id": "cohere/cohere-command-r-plus",
      "provider": "github_models",
      "name": "Cohere Command R+",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-04-04"
    },
    "github_models/deepseek/deepseek-r1-0528": {
      "id": "deepseek/deepseek-r1-0528",
      "provider": "github_models",
      "name": "DeepSeek-R1-0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "github_models/deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "provider": "github_models",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "github_models/deepseek/deepseek-v3-0324": {
      "id": "deepseek/deepseek-v3-0324",
      "provider": "github_models",
      "name": "DeepSeek-V3-0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "github_models/mistral-ai/mistral-medium-2505": {
      "id": "mistral-ai/mistral-medium-2505",
      "provider": "github_models",
      "name": "Mistral Medium 3 (25.05)",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-05-01"
    },
    "github_models/mistral-ai/ministral-3b": {
      "id": "mistral-ai/ministral-3b",
      "provider": "github_models",
      "name": "Ministral 3B",
      "family": "ministral-3b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-10-22",
      "open_weights": true
    },
    "github_models/mistral-ai/mistral-nemo": {
      "id": "mistral-ai/mistral-nemo",
      "provider": "github_models",
      "name": "Mistral Nemo",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "github_models/mistral-ai/mistral-large-2411": {
      "id": "mistral-ai/mistral-large-2411",
      "provider": "github_models",
      "name": "Mistral Large 24.11",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-11-01"
    },
    "github_models/mistral-ai/codestral-2501": {
      "id": "mistral-ai/codestral-2501",
      "provider": "github_models",
      "name": "Codestral 25.01",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2025-01-01"
    },
    "github_models/mistral-ai/mistral-small-2503": {
      "id": "mistral-ai/mistral-small-2503",
      "provider": "github_models",
      "name": "Mistral Small 3.1",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-03-01"
    },
    "github_models/microsoft/phi-3-medium-128k-instruct": {
      "id": "microsoft/phi-3-medium-128k-instruct",
      "provider": "github_models",
      "name": "Phi-3-medium instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-3-mini-4k-instruct": {
      "id": "microsoft/phi-3-mini-4k-instruct",
      "provider": "github_models",
      "name": "Phi-3-mini instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-3-small-128k-instruct": {
      "id": "microsoft/phi-3-small-128k-instruct",
      "provider": "github_models",
      "name": "Phi-3-small instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-3.5-vision-instruct": {
      "id": "microsoft/phi-3.5-vision-instruct",
      "provider": "github_models",
      "name": "Phi-3.5-vision instruct (128k)",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "github_models/microsoft/phi-4": {
      "id": "microsoft/phi-4",
      "provider": "github_models",
      "name": "Phi-4",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "github_models/microsoft/phi-4-mini-reasoning": {
      "id": "microsoft/phi-4-mini-reasoning",
      "provider": "github_models",
      "name": "Phi-4-mini-reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "github_models/microsoft/phi-3-small-8k-instruct": {
      "id": "microsoft/phi-3-small-8k-instruct",
      "provider": "github_models",
      "name": "Phi-3-small instruct (8k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-3.5-mini-instruct": {
      "id": "microsoft/phi-3.5-mini-instruct",
      "provider": "github_models",
      "name": "Phi-3.5-mini instruct (128k)",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "github_models/microsoft/phi-4-multimodal-instruct": {
      "id": "microsoft/phi-4-multimodal-instruct",
      "provider": "github_models",
      "name": "Phi-4-multimodal-instruct",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "github_models/microsoft/phi-3-mini-128k-instruct": {
      "id": "microsoft/phi-3-mini-128k-instruct",
      "provider": "github_models",
      "name": "Phi-3-mini instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-3.5-moe-instruct": {
      "id": "microsoft/phi-3.5-moe-instruct",
      "provider": "github_models",
      "name": "Phi-3.5-MoE instruct (128k)",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "github_models/microsoft/phi-4-mini-instruct": {
      "id": "microsoft/phi-4-mini-instruct",
      "provider": "github_models",
      "name": "Phi-4-mini-instruct",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "github_models/microsoft/phi-3-medium-4k-instruct": {
      "id": "microsoft/phi-3-medium-4k-instruct",
      "provider": "github_models",
      "name": "Phi-3-medium instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "github_models/microsoft/phi-4-reasoning": {
      "id": "microsoft/phi-4-reasoning",
      "provider": "github_models",
      "name": "Phi-4-Reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "github_models/microsoft/mai-ds-r1": {
      "id": "microsoft/mai-ds-r1",
      "provider": "github_models",
      "name": "MAI-DS-R1",
      "family": "mai-ds-r1",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-01-20"
    },
    "github_models/openai/gpt-4.1-nano": {
      "id": "openai/gpt-4.1-nano",
      "provider": "github_models",
      "name": "GPT-4.1-nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "github_models/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "provider": "github_models",
      "name": "GPT-4.1-mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "github_models/openai/o1-preview": {
      "id": "openai/o1-preview",
      "provider": "github_models",
      "name": "OpenAI o1-preview",
      "family": "o1-preview",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o3-mini": {
      "id": "openai/o3-mini",
      "provider": "github_models",
      "name": "OpenAI o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-31"
    },
    "github_models/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "provider": "github_models",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-05-13"
    },
    "github_models/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "github_models",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "github_models/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "github_models",
      "name": "OpenAI o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-31"
    },
    "github_models/openai/o1": {
      "id": "openai/o1",
      "provider": "github_models",
      "name": "OpenAI o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o1-mini": {
      "id": "openai/o1-mini",
      "provider": "github_models",
      "name": "OpenAI o1-mini",
      "family": "o1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-09-12"
    },
    "github_models/openai/o3": {
      "id": "openai/o3",
      "provider": "github_models",
      "name": "OpenAI o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-01-31"
    },
    "github_models/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "github_models",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-07-18"
    },
    "github_models/meta/llama-3.2-11b-vision-instruct": {
      "id": "meta/llama-3.2-11b-vision-instruct",
      "provider": "github_models",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "github_models/meta/meta-llama-3.1-405b-instruct": {
      "id": "meta/meta-llama-3.1-405b-instruct",
      "provider": "github_models",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "github_models/meta/llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "meta/llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "github_models",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-31",
      "open_weights": true
    },
    "github_models/meta/meta-llama-3-70b-instruct": {
      "id": "meta/meta-llama-3-70b-instruct",
      "provider": "github_models",
      "name": "Meta-Llama-3-70B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "github_models/meta/meta-llama-3.1-70b-instruct": {
      "id": "meta/meta-llama-3.1-70b-instruct",
      "provider": "github_models",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "github_models/meta/llama-3.3-70b-instruct": {
      "id": "meta/llama-3.3-70b-instruct",
      "provider": "github_models",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "github_models/meta/llama-3.2-90b-vision-instruct": {
      "id": "meta/llama-3.2-90b-vision-instruct",
      "provider": "github_models",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "github_models/meta/meta-llama-3-8b-instruct": {
      "id": "meta/meta-llama-3-8b-instruct",
      "provider": "github_models",
      "name": "Meta-Llama-3-8B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "github_models/meta/llama-4-scout-17b-16e-instruct": {
      "id": "meta/llama-4-scout-17b-16e-instruct",
      "provider": "github_models",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-31",
      "open_weights": true
    },
    "github_models/meta/meta-llama-3.1-8b-instruct": {
      "id": "meta/meta-llama-3.1-8b-instruct",
      "provider": "github_models",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "github_models/ai21-labs/ai21-jamba-1.5-large": {
      "id": "ai21-labs/ai21-jamba-1.5-large",
      "provider": "github_models",
      "name": "AI21 Jamba 1.5 Large",
      "family": "jamba-1.5-large",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-08-29"
    },
    "github_models/ai21-labs/ai21-jamba-1.5-mini": {
      "id": "ai21-labs/ai21-jamba-1.5-mini",
      "provider": "github_models",
      "name": "AI21 Jamba 1.5 Mini",
      "family": "jamba-1.5-mini",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-08-29"
    },
    "togetherai/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "togetherai",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true
    },
    "togetherai/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "togetherai",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "togetherai/essentialai/Rnj-1-Instruct": {
      "id": "essentialai/Rnj-1-Instruct",
      "provider": "togetherai",
      "name": "Rnj-1 Instruct",
      "family": "rnj",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-12-05",
      "open_weights": true
    },
    "togetherai/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "togetherai",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "togetherai/meta-llama/Llama-3.3-70B-Instruct-Turbo": {
      "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
      "provider": "togetherai",
      "name": "Llama 3.3 70B",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.00088,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "provider": "togetherai",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "togetherai/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "togetherai",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "togetherai/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "provider": "togetherai",
      "name": "DeepSeek R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163839,
      "max_output_tokens": 12288,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.007,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-12-26",
      "open_weights": true
    },
    "togetherai/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "provider": "togetherai",
      "name": "DeepSeek V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 12288,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "togetherai/deepseek-ai/DeepSeek-V3-1": {
      "id": "deepseek-ai/DeepSeek-V3-1",
      "provider": "togetherai",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 12288,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0017,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "azure_openai/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "azure_openai",
      "name": "GPT-4.1 nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "azure_openai/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "provider": "azure_openai",
      "name": "text-embedding-3-small",
      "family": "text-embedding-3-small",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0,
      "release_date": "2024-01-25"
    },
    "azure_openai/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "provider": "azure_openai",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "azure_openai/deepseek-r1-0528": {
      "id": "deepseek-r1-0528",
      "provider": "azure_openai",
      "name": "DeepSeek-R1-0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "azure_openai/grok-4-fast-reasoning": {
      "id": "grok-4-fast-reasoning",
      "provider": "azure_openai",
      "name": "Grok 4 Fast (Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "azure_openai/phi-3-medium-128k-instruct": {
      "id": "phi-3-medium-128k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-medium-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/gpt-4": {
      "id": "gpt-4",
      "provider": "azure_openai",
      "name": "GPT-4",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-03-14"
    },
    "azure_openai/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "azure_openai",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-18"
    },
    "azure_openai/gpt-5.2-chat": {
      "id": "gpt-5.2-chat",
      "provider": "azure_openai",
      "name": "GPT-5.2 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "azure_openai/llama-3.2-11b-vision-instruct": {
      "id": "llama-3.2-11b-vision-instruct",
      "provider": "azure_openai",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00037,
      "output_cost_per_1k": 0.00037,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "azure_openai/cohere-embed-v-4-0": {
      "id": "cohere-embed-v-4-0",
      "provider": "azure_openai",
      "name": "Embed v4",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "vision"
      ],
      "release_date": "2025-04-15",
      "open_weights": true
    },
    "azure_openai/cohere-command-r-08-2024": {
      "id": "cohere-command-r-08-2024",
      "provider": "azure_openai",
      "name": "Command R",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "azure_openai/grok-4": {
      "id": "grok-4",
      "provider": "azure_openai",
      "name": "Grok 4",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "reasoning_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "azure_openai/cohere-embed-v3-multilingual": {
      "id": "cohere-embed-v3-multilingual",
      "provider": "azure_openai",
      "name": "Embed v3 Multilingual",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2023-11-07",
      "open_weights": true
    },
    "azure_openai/phi-4-mini": {
      "id": "phi-4-mini",
      "provider": "azure_openai",
      "name": "Phi-4-mini",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/gpt-4-32k": {
      "id": "gpt-4-32k",
      "provider": "azure_openai",
      "name": "GPT-4 32K",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-03-14"
    },
    "azure_openai/meta-llama-3.1-405b-instruct": {
      "id": "meta-llama-3.1-405b-instruct",
      "provider": "azure_openai",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00533,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_openai/deepseek-r1": {
      "id": "deepseek-r1",
      "provider": "azure_openai",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "azure_openai/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "azure_openai",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-08-28"
    },
    "azure_openai/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "azure_openai",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_openai/phi-3-mini-4k-instruct": {
      "id": "phi-3-mini-4k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-mini-instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "provider": "azure_openai",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-31",
      "release_date": "2025-11-18"
    },
    "azure_openai/deepseek-v3.2-speciale": {
      "id": "deepseek-v3.2-speciale",
      "provider": "azure_openai",
      "name": "DeepSeek-V3.2-Speciale",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "azure_openai/mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "provider": "azure_openai",
      "name": "Mistral Medium 3",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07"
    },
    "azure_openai/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "provider": "azure_openai",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "azure_openai/phi-3-small-128k-instruct": {
      "id": "phi-3-small-128k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-small-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/cohere-command-a": {
      "id": "cohere-command-a",
      "provider": "azure_openai",
      "name": "Command A",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-03-13",
      "open_weights": true
    },
    "azure_openai/cohere-command-r-plus-08-2024": {
      "id": "cohere-command-r-plus-08-2024",
      "provider": "azure_openai",
      "name": "Command R+",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "azure_openai/llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "azure_openai",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "azure_openai/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "azure_openai",
      "name": "GPT-4.1 mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "azure_openai/gpt-5-chat": {
      "id": "gpt-5-chat",
      "provider": "azure_openai",
      "name": "GPT-5 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-24",
      "release_date": "2025-08-07"
    },
    "azure_openai/deepseek-v3.1": {
      "id": "deepseek-v3.1",
      "provider": "azure_openai",
      "name": "DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "azure_openai/phi-4": {
      "id": "phi-4",
      "provider": "azure_openai",
      "name": "Phi-4",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/phi-4-mini-reasoning": {
      "id": "phi-4-mini-reasoning",
      "provider": "azure_openai",
      "name": "Phi-4-mini-reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "provider": "azure_openai",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-11-18"
    },
    "azure_openai/gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "provider": "azure_openai",
      "name": "GPT-3.5 Turbo 0125",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2024-01-25"
    },
    "azure_openai/grok-3": {
      "id": "grok-3",
      "provider": "azure_openai",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "azure_openai/text-embedding-3-large": {
      "id": "text-embedding-3-large",
      "provider": "azure_openai",
      "name": "text-embedding-3-large",
      "family": "text-embedding-3-large",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0,
      "release_date": "2024-01-25"
    },
    "azure_openai/meta-llama-3-70b-instruct": {
      "id": "meta-llama-3-70b-instruct",
      "provider": "azure_openai",
      "name": "Meta-Llama-3-70B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00268,
      "output_cost_per_1k": 0.00354,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "azure_openai/deepseek-v3-0324": {
      "id": "deepseek-v3-0324",
      "provider": "azure_openai",
      "name": "DeepSeek-V3-0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00114,
      "output_cost_per_1k": 0.00456,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "azure_openai/phi-3-small-8k-instruct": {
      "id": "phi-3-small-8k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-small-instruct (8k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/meta-llama-3.1-70b-instruct": {
      "id": "meta-llama-3.1-70b-instruct",
      "provider": "azure_openai",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00268,
      "output_cost_per_1k": 0.00354,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_openai/gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "provider": "azure_openai",
      "name": "GPT-4 Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "azure_openai/gpt-3.5-turbo-0613": {
      "id": "gpt-3.5-turbo-0613",
      "provider": "azure_openai",
      "name": "GPT-3.5 Turbo 0613",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-06-13"
    },
    "azure_openai/phi-3.5-mini-instruct": {
      "id": "phi-3.5-mini-instruct",
      "provider": "azure_openai",
      "name": "Phi-3.5-mini-instruct",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "azure_openai/o1-preview": {
      "id": "o1-preview",
      "provider": "azure_openai",
      "name": "o1-preview",
      "family": "o1-preview",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "cache_read_cost_per_1k": 0.00825,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "azure_openai/llama-3.3-70b-instruct": {
      "id": "llama-3.3-70b-instruct",
      "provider": "azure_openai",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00071,
      "output_cost_per_1k": 0.00071,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "azure_openai/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "azure_openai",
      "name": "GPT-5.1 Codex Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_openai/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "azure_openai",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "azure_openai/model-router": {
      "id": "model-router",
      "provider": "azure_openai",
      "name": "Model Router",
      "family": "model-router",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-05-19"
    },
    "azure_openai/o3-mini": {
      "id": "o3-mini",
      "provider": "azure_openai",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "azure_openai/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "azure_openai",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "image",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_openai/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "azure_openai",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "azure_openai/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "azure_openai",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "azure_openai/llama-3.2-90b-vision-instruct": {
      "id": "llama-3.2-90b-vision-instruct",
      "provider": "azure_openai",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00204,
      "output_cost_per_1k": 0.00204,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "azure_openai/phi-3-mini-128k-instruct": {
      "id": "phi-3-mini-128k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-mini-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/gpt-4o": {
      "id": "gpt-4o",
      "provider": "azure_openai",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "azure_openai/gpt-3.5-turbo-0301": {
      "id": "gpt-3.5-turbo-0301",
      "provider": "azure_openai",
      "name": "GPT-3.5 Turbo 0301",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-03-01"
    },
    "azure_openai/ministral-3b": {
      "id": "ministral-3b",
      "provider": "azure_openai",
      "name": "Ministral 3B",
      "family": "ministral-3b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-10-22",
      "open_weights": true
    },
    "azure_openai/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "azure_openai",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "azure_openai/o4-mini": {
      "id": "o4-mini",
      "provider": "azure_openai",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "azure_openai/phi-4-multimodal": {
      "id": "phi-4-multimodal",
      "provider": "azure_openai",
      "name": "Phi-4-multimodal",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00032,
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/meta-llama-3-8b-instruct": {
      "id": "meta-llama-3-8b-instruct",
      "provider": "azure_openai",
      "name": "Meta-Llama-3-8B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00061,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "azure_openai/o1": {
      "id": "o1",
      "provider": "azure_openai",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-12-05"
    },
    "azure_openai/grok-3-mini": {
      "id": "grok-3-mini",
      "provider": "azure_openai",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "azure_openai/gpt-5.1-chat": {
      "id": "gpt-5.1-chat",
      "provider": "azure_openai",
      "name": "GPT-5.1 Chat",
      "family": "gpt-5-chat",
      "mode": "image",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_openai/phi-3.5-moe-instruct": {
      "id": "phi-3.5-moe-instruct",
      "provider": "azure_openai",
      "name": "Phi-3.5-MoE-instruct",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00064,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "azure_openai/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "azure_openai",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "azure_openai/o1-mini": {
      "id": "o1-mini",
      "provider": "azure_openai",
      "name": "o1-mini",
      "family": "o1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "azure_openai/llama-4-scout-17b-16e-instruct": {
      "id": "llama-4-scout-17b-16e-instruct",
      "provider": "azure_openai",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.00078,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "azure_openai/cohere-embed-v3-english": {
      "id": "cohere-embed-v3-english",
      "provider": "azure_openai",
      "name": "Embed v3 English",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2023-11-07",
      "open_weights": true
    },
    "azure_openai/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "provider": "azure_openai",
      "name": "text-embedding-ada-002",
      "family": "text-embedding-ada",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2022-12-15"
    },
    "azure_openai/meta-llama-3.1-8b-instruct": {
      "id": "meta-llama-3.1-8b-instruct",
      "provider": "azure_openai",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00061,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_openai/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "provider": "azure_openai",
      "name": "GPT-5.1 Codex Max",
      "family": "gpt-5-codex-max",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "azure_openai/gpt-3.5-turbo-instruct": {
      "id": "gpt-3.5-turbo-instruct",
      "provider": "azure_openai",
      "name": "GPT-3.5 Turbo Instruct",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-09-21"
    },
    "azure_openai/mistral-nemo": {
      "id": "mistral-nemo",
      "provider": "azure_openai",
      "name": "Mistral Nemo",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "azure_openai/o3": {
      "id": "o3",
      "provider": "azure_openai",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "azure_openai/codex-mini": {
      "id": "codex-mini",
      "provider": "azure_openai",
      "name": "Codex Mini",
      "family": "codex",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-16"
    },
    "azure_openai/phi-3-medium-4k-instruct": {
      "id": "phi-3-medium-4k-instruct",
      "provider": "azure_openai",
      "name": "Phi-3-medium-instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_openai/phi-4-reasoning": {
      "id": "phi-4-reasoning",
      "provider": "azure_openai",
      "name": "Phi-4-reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/gpt-4-turbo-vision": {
      "id": "gpt-4-turbo-vision",
      "provider": "azure_openai",
      "name": "GPT-4 Turbo Vision",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "azure_openai/phi-4-reasoning-plus": {
      "id": "phi-4-reasoning-plus",
      "provider": "azure_openai",
      "name": "Phi-4-reasoning-plus",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_openai/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "provider": "azure_openai",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-07-18"
    },
    "azure_openai/gpt-5": {
      "id": "gpt-5",
      "provider": "azure_openai",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "azure_openai/mai-ds-r1": {
      "id": "mai-ds-r1",
      "provider": "azure_openai",
      "name": "MAI-DS-R1",
      "family": "mai-ds-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-01-20"
    },
    "azure_openai/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "azure_openai",
      "name": "DeepSeek-V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "azure_openai/gpt-5-pro": {
      "id": "gpt-5-pro",
      "provider": "azure_openai",
      "name": "GPT-5 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-10-06"
    },
    "azure_openai/mistral-large-2411": {
      "id": "mistral-large-2411",
      "provider": "azure_openai",
      "name": "Mistral Large 24.11",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-11-01"
    },
    "azure_openai/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "azure_openai",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "azure_openai/codestral-2501": {
      "id": "codestral-2501",
      "provider": "azure_openai",
      "name": "Codestral 25.01",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2025-01-01"
    },
    "azure_openai/mistral-small-2503": {
      "id": "mistral-small-2503",
      "provider": "azure_openai",
      "name": "Mistral Small 3.1",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-03-01"
    },
    "azure_openai/gpt-3.5-turbo-1106": {
      "id": "gpt-3.5-turbo-1106",
      "provider": "azure_openai",
      "name": "GPT-3.5 Turbo 1106",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-11-06"
    },
    "baseten/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "baseten",
      "name": "Kimi K2 Instruct 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "baseten/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "baseten",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "baseten/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "baseten",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00153,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "baseten/zai-org/GLM-4.7": {
      "id": "zai-org/GLM-4.7",
      "provider": "baseten",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "baseten/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "baseten",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-09-16",
      "open_weights": true
    },
    "baseten/deepseek-ai/DeepSeek-V3.2": {
      "id": "deepseek-ai/DeepSeek-V3.2",
      "provider": "baseten",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163800,
      "max_output_tokens": 131100,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-10",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "siliconflow/inclusionAI/Ling-mini-2.0": {
      "id": "inclusionAI/Ling-mini-2.0",
      "provider": "siliconflow",
      "name": "inclusionAI/Ling-mini-2.0",
      "family": "inclusionai-ling-mini",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-10"
    },
    "siliconflow/inclusionAI/Ling-flash-2.0": {
      "id": "inclusionAI/Ling-flash-2.0",
      "provider": "siliconflow",
      "name": "inclusionAI/Ling-flash-2.0",
      "family": "inclusionai-ling-flash",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow/inclusionAI/Ring-flash-2.0": {
      "id": "inclusionAI/Ring-flash-2.0",
      "provider": "siliconflow",
      "name": "inclusionAI/Ring-flash-2.0",
      "family": "inclusionai-ring-flash",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-29"
    },
    "siliconflow/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "siliconflow",
      "name": "moonshotai/Kimi-K2-Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00229,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-13"
    },
    "siliconflow/moonshotai/Kimi-Dev-72B": {
      "id": "moonshotai/Kimi-Dev-72B",
      "provider": "siliconflow",
      "name": "moonshotai/Kimi-Dev-72B",
      "family": "kimi",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-06-19"
    },
    "siliconflow/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "siliconflow",
      "name": "moonshotai/Kimi-K2-Instruct-0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-08"
    },
    "siliconflow/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "siliconflow",
      "name": "moonshotai/Kimi-K2-Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-11-07"
    },
    "siliconflow/tencent/Hunyuan-MT-7B": {
      "id": "tencent/Hunyuan-MT-7B",
      "provider": "siliconflow",
      "name": "tencent/Hunyuan-MT-7B",
      "family": "hunyuan",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow/tencent/Hunyuan-A13B-Instruct": {
      "id": "tencent/Hunyuan-A13B-Instruct",
      "provider": "siliconflow",
      "name": "tencent/Hunyuan-A13B-Instruct",
      "family": "hunyuan",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-06-30"
    },
    "siliconflow/MiniMaxAI/MiniMax-M2": {
      "id": "MiniMaxAI/MiniMax-M2",
      "provider": "siliconflow",
      "name": "MiniMaxAI/MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 197000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-28"
    },
    "siliconflow/MiniMaxAI/MiniMax-M1-80k": {
      "id": "MiniMaxAI/MiniMax-M1-80k",
      "provider": "siliconflow",
      "name": "MiniMaxAI/MiniMax-M1-80k",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-17"
    },
    "siliconflow/THUDM/GLM-4-32B-0414": {
      "id": "THUDM/GLM-4-32B-0414",
      "provider": "siliconflow",
      "name": "THUDM/GLM-4-32B-0414",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow/THUDM/GLM-4.1V-9B-Thinking": {
      "id": "THUDM/GLM-4.1V-9B-Thinking",
      "provider": "siliconflow",
      "name": "THUDM/GLM-4.1V-9B-Thinking",
      "family": "glm-4v",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-04"
    },
    "siliconflow/THUDM/GLM-Z1-9B-0414": {
      "id": "THUDM/GLM-Z1-9B-0414",
      "provider": "siliconflow",
      "name": "THUDM/GLM-Z1-9B-0414",
      "family": "glm-z1",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 8.6e-05,
      "output_cost_per_1k": 8.6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow/THUDM/GLM-4-9B-0414": {
      "id": "THUDM/GLM-4-9B-0414",
      "provider": "siliconflow",
      "name": "THUDM/GLM-4-9B-0414",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 33000,
      "input_cost_per_1k": 8.6e-05,
      "output_cost_per_1k": 8.6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow/THUDM/GLM-Z1-32B-0414": {
      "id": "THUDM/GLM-Z1-32B-0414",
      "provider": "siliconflow",
      "name": "THUDM/GLM-Z1-32B-0414",
      "family": "glm-z1",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-18"
    },
    "siliconflow/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "siliconflow",
      "name": "openai/gpt-oss-20b",
      "family": "openai-gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "siliconflow",
      "name": "openai/gpt-oss-120b",
      "family": "openai-gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow/stepfun-ai/step3": {
      "id": "stepfun-ai/step3",
      "provider": "siliconflow",
      "name": "stepfun-ai/step3",
      "family": "stepfun-ai-step3",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.00057,
      "output_cost_per_1k": 0.00142,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-06"
    },
    "siliconflow/nex-agi/DeepSeek-V3.1-Nex-N1": {
      "id": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "provider": "siliconflow",
      "name": "nex-agi/DeepSeek-V3.1-Nex-N1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-01"
    },
    "siliconflow/baidu/ERNIE-4.5-300B-A47B": {
      "id": "baidu/ERNIE-4.5-300B-A47B",
      "provider": "siliconflow",
      "name": "baidu/ERNIE-4.5-300B-A47B",
      "family": "ernie-4",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-02"
    },
    "siliconflow/z-ai/GLM-4.5": {
      "id": "z-ai/GLM-4.5",
      "provider": "siliconflow",
      "name": "z-ai/GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow/z-ai/GLM-4.5-Air": {
      "id": "z-ai/GLM-4.5-Air",
      "provider": "siliconflow",
      "name": "z-ai/GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow/ByteDance-Seed/Seed-OSS-36B-Instruct": {
      "id": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "provider": "siliconflow",
      "name": "ByteDance-Seed/Seed-OSS-36B-Instruct",
      "family": "bytedance-seed-seed-oss",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-04"
    },
    "siliconflow/meta-llama/Meta-Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "provider": "siliconflow",
      "name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-23"
    },
    "siliconflow/Qwen/Qwen3-30B-A3B": {
      "id": "Qwen/Qwen3-30B-A3B",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-30B-A3B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow/Qwen/Qwen3-30B-A3B-Thinking-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-31"
    },
    "siliconflow/Qwen/Qwen3-VL-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-30B-A3B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-05"
    },
    "siliconflow/Qwen/Qwen3-14B": {
      "id": "Qwen/Qwen3-14B",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-14B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow/Qwen/Qwen2.5-VL-32B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-VL-32B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-03-24"
    },
    "siliconflow/Qwen/Qwen3-Omni-30B-A3B-Captioner": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Captioner",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/Qwen/Qwen3-8B": {
      "id": "Qwen/Qwen3-8B",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-8B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow/Qwen/Qwen3-Omni-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Instruct",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/Qwen/Qwen3-VL-8B-Thinking": {
      "id": "Qwen/Qwen3-VL-8B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-8B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "siliconflow/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-23"
    },
    "siliconflow/Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-Coder-32B-Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-11-11"
    },
    "siliconflow/Qwen/Qwen2.5-32B-Instruct": {
      "id": "Qwen/Qwen2.5-32B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-32B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-19"
    },
    "siliconflow/Qwen/Qwen2.5-72B-Instruct-128K": {
      "id": "Qwen/Qwen2.5-72B-Instruct-128K",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-72B-Instruct-128K",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow/Qwen/Qwen2.5-72B-Instruct": {
      "id": "Qwen/Qwen2.5-72B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-72B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow/Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-08-01"
    },
    "siliconflow/Qwen/Qwen2.5-7B-Instruct": {
      "id": "Qwen/Qwen2.5-7B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-7B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow/Qwen/Qwen3-235B-A22B": {
      "id": "Qwen/Qwen3-235B-A22B",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00142,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow/Qwen/Qwen2.5-VL-72B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-72B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-VL-72B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-28"
    },
    "siliconflow/Qwen/QwQ-32B": {
      "id": "Qwen/QwQ-32B",
      "provider": "siliconflow",
      "name": "Qwen/QwQ-32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00058,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-03-06"
    },
    "siliconflow/Qwen/Qwen2.5-VL-7B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-7B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-VL-7B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-28"
    },
    "siliconflow/Qwen/Qwen3-32B": {
      "id": "Qwen/Qwen3-32B",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-30"
    },
    "siliconflow/Qwen/Qwen3-VL-8B-Instruct": {
      "id": "Qwen/Qwen3-VL-8B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-8B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "siliconflow/Qwen/Qwen3-VL-235B-A22B-Instruct": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-31"
    },
    "siliconflow/Qwen/Qwen3-VL-235B-A22B-Thinking": {
      "id": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-235B-A22B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-30"
    },
    "siliconflow/Qwen/Qwen3-VL-30B-A3B-Thinking": {
      "id": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-30B-A3B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-11"
    },
    "siliconflow/Qwen/Qwen3-VL-32B-Thinking": {
      "id": "Qwen/Qwen3-VL-32B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-32B-Thinking",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-21"
    },
    "siliconflow/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow/Qwen/Qwen3-Omni-30B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Omni-30B-A3B-Thinking",
      "family": "qwen3-omni",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/Qwen/Qwen3-VL-32B-Instruct": {
      "id": "Qwen/Qwen3-VL-32B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-VL-32B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-21"
    },
    "siliconflow/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "siliconflow/Qwen/Qwen2.5-14B-Instruct": {
      "id": "Qwen/Qwen2.5-14B-Instruct",
      "provider": "siliconflow",
      "name": "Qwen/Qwen2.5-14B-Instruct",
      "family": "qwen2.5",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-09-18"
    },
    "siliconflow/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "provider": "siliconflow",
      "name": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-25"
    },
    "siliconflow/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "provider": "siliconflow",
      "name": "zai-org/GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "siliconflow",
      "name": "zai-org/GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 205000,
      "max_output_tokens": 205000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0019,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-04"
    },
    "siliconflow/zai-org/GLM-4.5V": {
      "id": "zai-org/GLM-4.5V",
      "provider": "siliconflow",
      "name": "zai-org/GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 66000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-13"
    },
    "siliconflow/zai-org/GLM-4.5-Air": {
      "id": "zai-org/GLM-4.5-Air",
      "provider": "siliconflow",
      "name": "zai-org/GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00086,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-28"
    },
    "siliconflow/deepseek-ai/DeepSeek-R1": {
      "id": "deepseek-ai/DeepSeek-R1",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00218,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-05-28"
    },
    "siliconflow/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00018,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai/deepseek-vl2": {
      "id": "deepseek-ai/deepseek-vl2",
      "provider": "siliconflow",
      "name": "deepseek-ai/deepseek-vl2",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 4000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2024-12-13"
    },
    "siliconflow/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai/DeepSeek-V3.2-Exp": {
      "id": "deepseek-ai/DeepSeek-V3.2-Exp",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-V3.2-Exp",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-10"
    },
    "siliconflow/deepseek-ai/DeepSeek-V3.1-Terminus": {
      "id": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-V3.1-Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-29"
    },
    "siliconflow/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
      "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 33000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20"
    },
    "siliconflow/deepseek-ai/DeepSeek-V3": {
      "id": "deepseek-ai/DeepSeek-V3",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-12-26"
    },
    "siliconflow/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "provider": "siliconflow",
      "name": "deepseek-ai/DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 164000,
      "max_output_tokens": 164000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-25"
    },
    "helicone/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "helicone",
      "name": "OpenAI GPT-4.1 Nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-14"
    },
    "helicone/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "provider": "helicone",
      "name": "xAI Grok 4 Fast Non-Reasoning",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-19"
    },
    "helicone/qwen3-coder": {
      "id": "qwen3-coder",
      "provider": "helicone",
      "name": "Qwen3 Coder 480B A35B Instruct Turbo",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00095,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-23"
    },
    "helicone/deepseek-v3": {
      "id": "deepseek-v3",
      "provider": "helicone",
      "name": "DeepSeek V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-26"
    },
    "helicone/claude-opus-4": {
      "id": "claude-opus-4",
      "provider": "helicone",
      "name": "Anthropic: Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-14"
    },
    "helicone/grok-4-fast-reasoning": {
      "id": "grok-4-fast-reasoning",
      "provider": "helicone",
      "name": "xAI: Grok 4 Fast Reasoning",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-01"
    },
    "helicone/llama-3.1-8b-instant": {
      "id": "llama-3.1-8b-instant",
      "provider": "helicone",
      "name": "Meta Llama 3.1 8B Instant",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32678,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-01"
    },
    "helicone/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "helicone",
      "name": "Anthropic: Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-05"
    },
    "helicone/grok-4": {
      "id": "grok-4",
      "provider": "helicone",
      "name": "xAI Grok 4",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-09"
    },
    "helicone/qwen3-next-80b-a3b-instruct": {
      "id": "qwen3-next-80b-a3b-instruct",
      "provider": "helicone",
      "name": "Qwen3 Next 80B A3B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/llama-4-maverick": {
      "id": "llama-4-maverick",
      "provider": "helicone",
      "name": "Meta Llama 4 Maverick 17B 128E",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/llama-prompt-guard-2-86m": {
      "id": "llama-prompt-guard-2-86m",
      "provider": "helicone",
      "name": "Meta Llama Prompt Guard 2 86M",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 512,
      "max_output_tokens": 2,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 1e-05,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01"
    },
    "helicone/grok-4-1-fast-reasoning": {
      "id": "grok-4-1-fast-reasoning",
      "provider": "helicone",
      "name": "xAI Grok 4.1 Fast Reasoning",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 2000000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-17"
    },
    "helicone/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "helicone",
      "name": "xAI Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-25"
    },
    "helicone/claude-4.5-haiku": {
      "id": "claude-4.5-haiku",
      "provider": "helicone",
      "name": "Anthropic: Claude 4.5 Haiku",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-10",
      "release_date": "2025-10-01"
    },
    "helicone/llama-3.1-8b-instruct-turbo": {
      "id": "llama-3.1-8b-instruct-turbo",
      "provider": "helicone",
      "name": "Meta Llama 3.1 8B Instruct Turbo",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-23"
    },
    "helicone/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "helicone",
      "name": "OpenAI: GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-4.1-mini-2025-04-14": {
      "id": "gpt-4.1-mini-2025-04-14",
      "provider": "helicone",
      "name": "OpenAI GPT-4.1 Mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-14"
    },
    "helicone/llama-guard-4": {
      "id": "llama-guard-4",
      "provider": "helicone",
      "name": "Meta Llama Guard 4 12B",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00021,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "provider": "helicone",
      "name": "Meta Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-23"
    },
    "helicone/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "helicone",
      "name": "Google Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-18"
    },
    "helicone/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "helicone",
      "name": "Google Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-06-17"
    },
    "helicone/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "helicone",
      "name": "OpenAI GPT-4.1 Mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-14"
    },
    "helicone/deepseek-v3.1-terminus": {
      "id": "deepseek-v3.1-terminus",
      "provider": "helicone",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "cache_read_cost_per_1k": 0.000216,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-22"
    },
    "helicone/llama-prompt-guard-2-22m": {
      "id": "llama-prompt-guard-2-22m",
      "provider": "helicone",
      "name": "Meta Llama Prompt Guard 2 22M",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 512,
      "max_output_tokens": 2,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 1e-05,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-01"
    },
    "helicone/claude-3.5-sonnet-v2": {
      "id": "claude-3.5-sonnet-v2",
      "provider": "helicone",
      "name": "Anthropic: Claude 3.5 Sonnet v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-22"
    },
    "helicone/sonar-deep-research": {
      "id": "sonar-deep-research",
      "provider": "helicone",
      "name": "Perplexity Sonar Deep Research",
      "family": "sonar-deep-research",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-27"
    },
    "helicone/gemini-2.5-flash-lite": {
      "id": "gemini-2.5-flash-lite",
      "provider": "helicone",
      "name": "Google Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-22"
    },
    "helicone/claude-sonnet-4-5-20250929": {
      "id": "claude-sonnet-4-5-20250929",
      "provider": "helicone",
      "name": "Anthropic: Claude Sonnet 4.5 (20250929)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-29"
    },
    "helicone/grok-3": {
      "id": "grok-3",
      "provider": "helicone",
      "name": "xAI Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/mistral-small": {
      "id": "mistral-small",
      "provider": "helicone",
      "name": "Mistral Small",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.075,
      "output_cost_per_1k": 0.2,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-02",
      "release_date": "2024-02-26"
    },
    "helicone/kimi-k2-0711": {
      "id": "kimi-k2-0711",
      "provider": "helicone",
      "name": "Kimi K2 (07/11)",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00057,
      "output_cost_per_1k": 0.0023,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/chatgpt-4o-latest": {
      "id": "chatgpt-4o-latest",
      "provider": "helicone",
      "name": "OpenAI ChatGPT-4o",
      "family": "chatgpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-14"
    },
    "helicone/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen3-coder-30b-a3b-instruct",
      "provider": "helicone",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-31"
    },
    "helicone/kimi-k2-0905": {
      "id": "kimi-k2-0905",
      "provider": "helicone",
      "name": "Kimi K2 (09/05)",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-05"
    },
    "helicone/sonar-reasoning": {
      "id": "sonar-reasoning",
      "provider": "helicone",
      "name": "Perplexity Sonar Reasoning",
      "family": "sonar-reasoning",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-27"
    },
    "helicone/llama-3.3-70b-instruct": {
      "id": "llama-3.3-70b-instruct",
      "provider": "helicone",
      "name": "Meta Llama 3.3 70B Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16400,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00039,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-06"
    },
    "helicone/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "helicone",
      "name": "OpenAI: GPT-5.1 Codex Mini",
      "family": "gpt-5-codex-mini",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "helicone",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00048,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-06"
    },
    "helicone/o3-mini": {
      "id": "o3-mini",
      "provider": "helicone",
      "name": "OpenAI o3 Mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2023-10-01"
    },
    "helicone/claude-4.5-sonnet": {
      "id": "claude-4.5-sonnet",
      "provider": "helicone",
      "name": "Anthropic: Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-29"
    },
    "helicone/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "helicone",
      "name": "OpenAI GPT-5.1",
      "family": "gpt-5",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/codex-mini-latest": {
      "id": "codex-mini-latest",
      "provider": "helicone",
      "name": "OpenAI Codex Mini Latest",
      "family": "codex",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "helicone",
      "name": "OpenAI GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 5e-06,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "helicone",
      "name": "OpenAI: GPT-5 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/gpt-4o": {
      "id": "gpt-4o",
      "provider": "helicone",
      "name": "OpenAI GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-05-13"
    },
    "helicone/deepseek-tng-r1t2-chimera": {
      "id": "deepseek-tng-r1t2-chimera",
      "provider": "helicone",
      "name": "DeepSeek TNG R1T2 Chimera",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 130000,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-02"
    },
    "helicone/claude-4.5-opus": {
      "id": "claude-4.5-opus",
      "provider": "helicone",
      "name": "Anthropic: Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-24"
    },
    "helicone/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "helicone",
      "name": "OpenAI GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-14"
    },
    "helicone/sonar": {
      "id": "sonar",
      "provider": "helicone",
      "name": "Perplexity Sonar",
      "family": "sonar",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-27"
    },
    "helicone/glm-4.6": {
      "id": "glm-4.6",
      "provider": "helicone",
      "name": "Zai GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-18"
    },
    "helicone/o4-mini": {
      "id": "o4-mini",
      "provider": "helicone",
      "name": "OpenAI o4 Mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.000275,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/qwen3-235b-a22b-thinking": {
      "id": "qwen3-235b-a22b-thinking",
      "provider": "helicone",
      "name": "Qwen3 235B A22B Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 81920,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0029,
      "capabilities": [
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-25"
    },
    "helicone/hermes-2-pro-llama-3-8b": {
      "id": "hermes-2-pro-llama-3-8b",
      "provider": "helicone",
      "name": "Hermes 2 Pro Llama 3 8B",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-05-27"
    },
    "helicone/o1": {
      "id": "o1",
      "provider": "helicone",
      "name": "OpenAI: o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/grok-3-mini": {
      "id": "grok-3-mini",
      "provider": "helicone",
      "name": "xAI Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/sonar-pro": {
      "id": "sonar-pro",
      "provider": "helicone",
      "name": "Perplexity Sonar Pro",
      "family": "sonar-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-27"
    },
    "helicone/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "helicone",
      "name": "OpenAI GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "helicone",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-20"
    },
    "helicone/o1-mini": {
      "id": "o1-mini",
      "provider": "helicone",
      "name": "OpenAI: o1-mini",
      "family": "o1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/claude-3.7-sonnet": {
      "id": "claude-3.7-sonnet",
      "provider": "helicone",
      "name": "Anthropic: Claude 3.7 Sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02",
      "release_date": "2025-02-19"
    },
    "helicone/claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "provider": "helicone",
      "name": "Anthropic: Claude 3 Haiku",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-03-07"
    },
    "helicone/o3-pro": {
      "id": "o3-pro",
      "provider": "helicone",
      "name": "OpenAI o3 Pro",
      "family": "o3-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/qwen2.5-coder-7b-fast": {
      "id": "qwen2.5-coder-7b-fast",
      "provider": "helicone",
      "name": "Qwen2.5 Coder 7B fast",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 9e-05,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-09-15"
    },
    "helicone/deepseek-reasoner": {
      "id": "deepseek-reasoner",
      "provider": "helicone",
      "name": "DeepSeek Reasoner",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-20"
    },
    "helicone/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "helicone",
      "name": "Google Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.0003125,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-06-17"
    },
    "helicone/gemma-3-12b-it": {
      "id": "gemma-3-12b-it",
      "provider": "helicone",
      "name": "Google Gemma 3 12B",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "helicone/mistral-nemo": {
      "id": "mistral-nemo",
      "provider": "helicone",
      "name": "Mistral Nemo",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16400,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.04,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-18"
    },
    "helicone/o3": {
      "id": "o3",
      "provider": "helicone",
      "name": "OpenAI o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/gpt-oss-20b": {
      "id": "gpt-oss-20b",
      "provider": "helicone",
      "name": "OpenAI GPT-OSS 20b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "helicone",
      "name": "OpenAI GPT-OSS 120b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-01"
    },
    "helicone/claude-3.5-haiku": {
      "id": "claude-3.5-haiku",
      "provider": "helicone",
      "name": "Anthropic: Claude 3.5 Haiku",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-10-22"
    },
    "helicone/gpt-5-chat-latest": {
      "id": "gpt-5-chat-latest",
      "provider": "helicone",
      "name": "OpenAI GPT-5 Chat Latest",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-09-30"
    },
    "helicone/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "provider": "helicone",
      "name": "OpenAI GPT-4o-mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-18"
    },
    "helicone/gemma2-9b-it": {
      "id": "gemma2-9b-it",
      "provider": "helicone",
      "name": "Google Gemma 2",
      "family": "gemma-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 3e-05,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-25"
    },
    "helicone/claude-sonnet-4": {
      "id": "claude-sonnet-4",
      "provider": "helicone",
      "name": "Anthropic: Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-14"
    },
    "helicone/sonar-reasoning-pro": {
      "id": "sonar-reasoning-pro",
      "provider": "helicone",
      "name": "Perplexity Sonar Reasoning Pro",
      "family": "sonar-reasoning",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-27"
    },
    "helicone/gpt-5": {
      "id": "gpt-5",
      "provider": "helicone",
      "name": "OpenAI GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/qwen3-vl-235b-a22b-instruct": {
      "id": "qwen3-vl-235b-a22b-instruct",
      "provider": "helicone",
      "name": "Qwen3 VL 235B A22B Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-23"
    },
    "helicone/qwen3-30b-a3b": {
      "id": "qwen3-30b-a3b",
      "provider": "helicone",
      "name": "Qwen3 30B A3B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 41000,
      "max_output_tokens": 41000,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-06-01"
    },
    "helicone/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "helicone",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-22"
    },
    "helicone/grok-4-1-fast-non-reasoning": {
      "id": "grok-4-1-fast-non-reasoning",
      "provider": "helicone",
      "name": "xAI Grok 4.1 Fast Non-Reasoning",
      "family": "grok",
      "mode": "image",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-17"
    },
    "helicone/gpt-5-pro": {
      "id": "gpt-5-pro",
      "provider": "helicone",
      "name": "OpenAI: GPT-5 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/llama-3.3-70b-versatile": {
      "id": "llama-3.3-70b-versatile",
      "provider": "helicone",
      "name": "Meta Llama 3.3 70B Versatile",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32678,
      "input_cost_per_1k": 0.00059,
      "output_cost_per_1k": 0.00079,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-06"
    },
    "helicone/mistral-large-2411": {
      "id": "mistral-large-2411",
      "provider": "helicone",
      "name": "Mistral-Large",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-24"
    },
    "helicone/claude-opus-4-1-20250805": {
      "id": "claude-opus-4-1-20250805",
      "provider": "helicone",
      "name": "Anthropic: Claude Opus 4.1 (20250805)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-05"
    },
    "helicone/ernie-4.5-21b-a3b-thinking": {
      "id": "ernie-4.5-21b-a3b-thinking",
      "provider": "helicone",
      "name": "Baidu Ernie 4.5 21B A3B Thinking",
      "family": "ernie-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-03-16"
    },
    "helicone/gpt-5.1-chat-latest": {
      "id": "gpt-5.1-chat-latest",
      "provider": "helicone",
      "name": "OpenAI GPT-5.1 Chat",
      "family": "gpt-5-chat",
      "mode": "image",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "helicone/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "helicone",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00059,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28"
    },
    "helicone/claude-haiku-4-5-20251001": {
      "id": "claude-haiku-4-5-20251001",
      "provider": "helicone",
      "name": "Anthropic: Claude 4.5 Haiku (20251001)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-10",
      "release_date": "2025-10-01"
    },
    "helicone/llama-4-scout": {
      "id": "llama-4-scout",
      "provider": "helicone",
      "name": "Meta Llama 4 Scout 17B 16E",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01"
    },
    "huggingface/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "huggingface",
      "name": "Kimi-K2-Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true
    },
    "huggingface/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "huggingface",
      "name": "Kimi-K2-Instruct-0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-04",
      "open_weights": true
    },
    "huggingface/MiniMaxAI/MiniMax-M2": {
      "id": "MiniMaxAI/MiniMax-M2",
      "provider": "huggingface",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 204800,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-10",
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-Embedding-8B": {
      "id": "Qwen/Qwen3-Embedding-8B",
      "provider": "huggingface",
      "name": "Qwen 3 Embedding 8B",
      "family": "qwen3",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-Embedding-4B": {
      "id": "Qwen/Qwen3-Embedding-4B",
      "provider": "huggingface",
      "name": "Qwen 3 Embedding 4B",
      "family": "qwen3",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "huggingface",
      "name": "Qwen3-Coder-480B-A35B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "huggingface",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "huggingface",
      "name": "Qwen3-Next-80B-A3B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-11",
      "open_weights": true
    },
    "huggingface/Qwen/Qwen3-Next-80B-A3B-Thinking": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Thinking",
      "provider": "huggingface",
      "name": "Qwen3-Next-80B-A3B-Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-11",
      "open_weights": true
    },
    "huggingface/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "provider": "huggingface",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "huggingface/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "huggingface",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "huggingface/zai-org/GLM-4.5-Air": {
      "id": "zai-org/GLM-4.5-Air",
      "provider": "huggingface",
      "name": "GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "huggingface/deepseek-ai/Deepseek-V3-0324": {
      "id": "deepseek-ai/Deepseek-V3-0324",
      "provider": "huggingface",
      "name": "DeepSeek-V3-0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "huggingface/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "provider": "huggingface",
      "name": "DeepSeek-R1-0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "opencode/qwen3-coder": {
      "id": "qwen3-coder",
      "provider": "opencode",
      "name": "Qwen3 Coder",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "opencode/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "opencode",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "opencode/kimi-k2": {
      "id": "kimi-k2",
      "provider": "opencode",
      "name": "Kimi K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "opencode/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "opencode",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00107,
      "output_cost_per_1k": 0.0085,
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "opencode/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "provider": "opencode",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "opencode/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "provider": "opencode",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "opencode/gemini-3-pro": {
      "id": "gemini-3-pro",
      "provider": "opencode",
      "name": "Gemini 3 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "opencode/alpha-glm-4.7": {
      "id": "alpha-glm-4.7",
      "provider": "opencode",
      "name": "Alpha GLM-4.7",
      "family": "alpha-glm",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "opencode/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "provider": "opencode",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "opencode/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "opencode",
      "name": "GPT-5.1 Codex Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "opencode/alpha-gd4": {
      "id": "alpha-gd4",
      "provider": "opencode",
      "name": "Alpha GD4",
      "family": "alpha-gd4",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "opencode/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "opencode",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "opencode/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "opencode",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00107,
      "output_cost_per_1k": 0.0085,
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "opencode/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "opencode",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "opencode/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "opencode",
      "name": "GPT-5 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00107,
      "output_cost_per_1k": 0.0085,
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "opencode/big-pickle": {
      "id": "big-pickle",
      "provider": "opencode",
      "name": "Big Pickle",
      "family": "big-pickle",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-10-17"
    },
    "opencode/claude-3-5-haiku": {
      "id": "claude-3-5-haiku",
      "provider": "opencode",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "opencode/glm-4.6": {
      "id": "glm-4.6",
      "provider": "opencode",
      "name": "GLM-4.6",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "opencode/glm-4.7-free": {
      "id": "glm-4.7-free",
      "provider": "opencode",
      "name": "GLM-4.7",
      "family": "glm-free",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "opencode/grok-code": {
      "id": "grok-code",
      "provider": "opencode",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-08-20"
    },
    "opencode/gemini-3-flash": {
      "id": "gemini-3-flash",
      "provider": "opencode",
      "name": "Gemini 3 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "opencode/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "provider": "opencode",
      "name": "GPT-5.1 Codex Max",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "opencode/minimax-m2.1-free": {
      "id": "minimax-m2.1-free",
      "provider": "opencode",
      "name": "MiniMax M2.1",
      "family": "minimax-free",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "opencode/claude-sonnet-4": {
      "id": "claude-sonnet-4",
      "provider": "opencode",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "opencode/gpt-5": {
      "id": "gpt-5",
      "provider": "opencode",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00107,
      "output_cost_per_1k": 0.0085,
      "cache_read_cost_per_1k": 0.000107,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "opencode/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "opencode",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "fastrouter/moonshotai/kimi-k2": {
      "id": "moonshotai/kimi-k2",
      "provider": "fastrouter",
      "name": "Kimi K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "fastrouter/x-ai/grok-4": {
      "id": "x-ai/grok-4",
      "provider": "fastrouter",
      "name": "Grok 4",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "fastrouter/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "fastrouter",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "fastrouter/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "fastrouter",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "fastrouter/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "provider": "fastrouter",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 5e-06,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "fastrouter/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "fastrouter",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "fastrouter/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "provider": "fastrouter",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "fastrouter/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "fastrouter",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "fastrouter/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "fastrouter",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "fastrouter/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "fastrouter",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "fastrouter/qwen/qwen3-coder": {
      "id": "qwen/qwen3-coder",
      "provider": "fastrouter",
      "name": "Qwen3 Coder",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "fastrouter/anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "provider": "fastrouter",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "fastrouter/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "fastrouter",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "fastrouter/deepseek-ai/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-ai/deepseek-r1-distill-llama-70b",
      "provider": "fastrouter",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-23",
      "open_weights": true
    },
    "minimax/MiniMax-M2": {
      "id": "MiniMax-M2",
      "provider": "minimax",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "minimax/MiniMax-M2.1": {
      "id": "MiniMax-M2.1",
      "provider": "minimax",
      "name": "MiniMax-M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "google/gemini-embedding-001": {
      "id": "gemini-embedding-001",
      "provider": "google",
      "name": "Gemini Embedding 001",
      "family": "gemini",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-20"
    },
    "google/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "provider": "google",
      "name": "Gemini 3 Flash Preview",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "google/gemini-2.5-flash-image": {
      "id": "gemini-2.5-flash-image",
      "provider": "google",
      "name": "Gemini 2.5 Flash Image",
      "family": "gemini-flash-image",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.03,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "image_output",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-08-26"
    },
    "google/gemini-2.5-flash-preview-05-20": {
      "id": "gemini-2.5-flash-preview-05-20",
      "provider": "google",
      "name": "Gemini 2.5 Flash Preview 05-20",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-20"
    },
    "google/gemini-flash-lite-latest": {
      "id": "gemini-flash-lite-latest",
      "provider": "google",
      "name": "Gemini Flash-Lite Latest",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "google",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "google/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "google",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "google/gemini-flash-latest": {
      "id": "gemini-flash-latest",
      "provider": "google",
      "name": "Gemini Flash Latest",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google/gemini-2.5-pro-preview-05-06": {
      "id": "gemini-2.5-pro-preview-05-06",
      "provider": "google",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-06"
    },
    "google/gemini-2.5-flash-preview-tts": {
      "id": "gemini-2.5-flash-preview-tts",
      "provider": "google",
      "name": "Gemini 2.5 Flash Preview TTS",
      "family": "gemini-flash-tts",
      "mode": "audio_speech",
      "max_input_tokens": 8000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "audio_output"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-01"
    },
    "google/gemini-2.0-flash-lite": {
      "id": "gemini-2.0-flash-lite",
      "provider": "google",
      "name": "Gemini 2.0 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "google/gemini-live-2.5-flash-preview-native-audio": {
      "id": "gemini-live-2.5-flash-preview-native-audio",
      "provider": "google",
      "name": "Gemini Live 2.5 Flash Preview Native Audio",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "video_input"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google/gemini-2.0-flash": {
      "id": "gemini-2.0-flash",
      "provider": "google",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "google/gemini-2.5-flash-lite": {
      "id": "gemini-2.5-flash-lite",
      "provider": "google",
      "name": "Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google/gemini-2.5-pro-preview-06-05": {
      "id": "gemini-2.5-pro-preview-06-05",
      "provider": "google",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-05"
    },
    "google/gemini-live-2.5-flash": {
      "id": "gemini-live-2.5-flash",
      "provider": "google",
      "name": "Gemini Live 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-01"
    },
    "google/gemini-2.5-flash-lite-preview-06-17": {
      "id": "gemini-2.5-flash-lite-preview-06-17",
      "provider": "google",
      "name": "Gemini 2.5 Flash Lite Preview 06-17",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google/gemini-2.5-flash-image-preview": {
      "id": "gemini-2.5-flash-image-preview",
      "provider": "google",
      "name": "Gemini 2.5 Flash Image (Preview)",
      "family": "gemini-flash-image",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.03,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "image_output",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-08-26"
    },
    "google/gemini-2.5-flash-preview-09-2025": {
      "id": "gemini-2.5-flash-preview-09-2025",
      "provider": "google",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google/gemini-2.5-flash-preview-04-17": {
      "id": "gemini-2.5-flash-preview-04-17",
      "provider": "google",
      "name": "Gemini 2.5 Flash Preview 04-17",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-17"
    },
    "google/gemini-2.5-pro-preview-tts": {
      "id": "gemini-2.5-pro-preview-tts",
      "provider": "google",
      "name": "Gemini 2.5 Pro Preview TTS",
      "family": "gemini-flash-tts",
      "mode": "audio_speech",
      "max_input_tokens": 8000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.02,
      "capabilities": [
        "audio_output"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-01"
    },
    "google/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "google",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "google/gemini-1.5-flash": {
      "id": "gemini-1.5-flash",
      "provider": "google",
      "name": "Gemini 1.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "cache_read_cost_per_1k": 1.875e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-05-14"
    },
    "google/gemini-1.5-flash-8b": {
      "id": "gemini-1.5-flash-8b",
      "provider": "google",
      "name": "Gemini 1.5 Flash-8B",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3.75e-05,
      "output_cost_per_1k": 0.00015,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-10-03"
    },
    "google/gemini-2.5-flash-lite-preview-09-2025": {
      "id": "gemini-2.5-flash-lite-preview-09-2025",
      "provider": "google",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google/gemini-1.5-pro": {
      "id": "gemini-1.5-pro",
      "provider": "google",
      "name": "Gemini 1.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0003125,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-02-15"
    },
    "google_vertex/gemini-embedding-001": {
      "id": "gemini-embedding-001",
      "provider": "google_vertex",
      "name": "Gemini Embedding 001",
      "family": "gemini",
      "mode": "embedding",
      "max_input_tokens": 2048,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-20"
    },
    "google_vertex/gemini-3-flash-preview": {
      "id": "gemini-3-flash-preview",
      "provider": "google_vertex",
      "name": "Gemini 3 Flash Preview",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "google_vertex/gemini-2.5-flash-preview-05-20": {
      "id": "gemini-2.5-flash-preview-05-20",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Preview 05-20",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-20"
    },
    "google_vertex/gemini-flash-lite-latest": {
      "id": "gemini-flash-lite-latest",
      "provider": "google_vertex",
      "name": "Gemini Flash-Lite Latest",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "google_vertex",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "google_vertex/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-flash-latest": {
      "id": "gemini-flash-latest",
      "provider": "google_vertex",
      "name": "Gemini Flash Latest",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-2.5-pro-preview-05-06": {
      "id": "gemini-2.5-pro-preview-05-06",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-06"
    },
    "google_vertex/gemini-2.0-flash-lite": {
      "id": "gemini-2.0-flash-lite",
      "provider": "google_vertex",
      "name": "Gemini 2.0 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "google_vertex/gemini-2.0-flash": {
      "id": "gemini-2.0-flash",
      "provider": "google_vertex",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "google_vertex/gemini-2.5-flash-lite": {
      "id": "gemini-2.5-flash-lite",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.5-pro-preview-06-05": {
      "id": "gemini-2.5-pro-preview-06-05",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-05"
    },
    "google_vertex/gemini-2.5-flash-lite-preview-06-17": {
      "id": "gemini-2.5-flash-lite-preview-06-17",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Lite Preview 06-17",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "google_vertex/gemini-2.5-flash-preview-09-2025": {
      "id": "gemini-2.5-flash-preview-09-2025",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.000383,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google_vertex/gemini-2.5-flash-preview-04-17": {
      "id": "gemini-2.5-flash-preview-04-17",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Preview 04-17",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-17"
    },
    "google_vertex/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "google_vertex/gemini-2.5-flash-lite-preview-09-2025": {
      "id": "gemini-2.5-flash-lite-preview-09-2025",
      "provider": "google_vertex",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "google_vertex/openai/gpt-oss-120b-maas": {
      "id": "openai/gpt-oss-120b-maas",
      "provider": "google_vertex",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00036,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "google_vertex/openai/gpt-oss-20b-maas": {
      "id": "openai/gpt-oss-20b-maas",
      "provider": "google_vertex",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.1-awq": {
      "id": "mistral-7b-instruct-v0.1-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/mistral-7b-instruct-v0.1-awq",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-09-27",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/aura-1": {
      "id": "aura-1",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/deepgram/aura-1",
      "family": "aura",
      "mode": "audio_speech",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 1.5e-05,
      "output_cost_per_1k": 1.5e-05,
      "capabilities": [
        "audio_output"
      ],
      "release_date": "2025-08-27",
      "open_weights": true
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.2": {
      "id": "mistral-7b-instruct-v0.2",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/mistral/mistral-7b-instruct-v0.2",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 3072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-12-11",
      "open_weights": true
    },
    "cloudflare_workers_ai/tinyllama-1.1b-chat-v1.0": {
      "id": "tinyllama-1.1b-chat-v1.0",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-12-30",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/qwen1.5-0.5b-chat": {
      "id": "qwen1.5-0.5b-chat",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen1.5-0.5b-chat",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-01-31",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-3.2-11b-vision-instruct": {
      "id": "llama-3.2-11b-vision-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.2-11b-vision-instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4.9e-05,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-09-18",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-2-13b-chat-awq": {
      "id": "llama-2-13b-chat-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/llama-2-13b-chat-awq",
      "family": "llama-2",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-09-19",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-fp8": {
      "id": "llama-3.1-8b-instruct-fp8",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.1-8b-instruct-fp8",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-25",
      "open_weights": true
    },
    "cloudflare_workers_ai/whisper": {
      "id": "whisper",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openai/whisper",
      "family": "whisper",
      "mode": "audio_transcription",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 4.5e-07,
      "output_cost_per_1k": 4.5e-07,
      "capabilities": [
        "audio_input"
      ],
      "release_date": "2023-11-07",
      "open_weights": true
    },
    "cloudflare_workers_ai/stable-diffusion-xl-base-1.0": {
      "id": "stable-diffusion-xl-base-1.0",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/stabilityai/stable-diffusion-xl-base-1.0",
      "family": "stable-diffusion",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2023-07-25",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-2-7b-chat-fp16": {
      "id": "llama-2-7b-chat-fp16",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-2-7b-chat-fp16",
      "family": "llama-2",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00667,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-07-26",
      "open_weights": true
    },
    "cloudflare_workers_ai/resnet-50": {
      "id": "resnet-50",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/microsoft/resnet-50",
      "family": "resnet",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "vision"
      ],
      "release_date": "2022-03-16",
      "open_weights": true
    },
    "cloudflare_workers_ai/stable-diffusion-v1-5-inpainting": {
      "id": "stable-diffusion-v1-5-inpainting",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/runwayml/stable-diffusion-v1-5-inpainting",
      "family": "stable-diffusion",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2024-02-27",
      "open_weights": true
    },
    "cloudflare_workers_ai/sqlcoder-7b-2": {
      "id": "sqlcoder-7b-2",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/defog/sqlcoder-7b-2",
      "family": "sqlcoder",
      "mode": "chat",
      "max_input_tokens": 10000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-02-05",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3-8b-instruct": {
      "id": "llama-3-8b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3-8b-instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 7968,
      "max_output_tokens": 7968,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00083,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-04-17",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-2-7b-chat-hf-lora": {
      "id": "llama-2-7b-chat-hf-lora",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta-llama/llama-2-7b-chat-hf-lora",
      "family": "llama-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-07-13",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.1-8b-instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 7968,
      "max_output_tokens": 7968,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00083,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "cloudflare_workers_ai/openchat-3.5-0106": {
      "id": "openchat-3.5-0106",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openchat/openchat-3.5-0106",
      "family": "openchat",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-01-07",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/openhermes-2.5-mistral-7b-awq": {
      "id": "openhermes-2.5-mistral-7b-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/openhermes-2.5-mistral-7b-awq",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-11-02",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/lucid-origin": {
      "id": "lucid-origin",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/leonardo/lucid-origin",
      "family": "lucid-origin",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 7e-06,
      "output_cost_per_1k": 7e-06,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2025-08-25"
    },
    "cloudflare_workers_ai/bart-large-cnn": {
      "id": "bart-large-cnn",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/facebook/bart-large-cnn",
      "family": "bart-large-cnn",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "release_date": "2022-03-02",
      "open_weights": true
    },
    "cloudflare_workers_ai/flux-1-schnell": {
      "id": "flux-1-schnell",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/black-forest-labs/flux-1-schnell",
      "family": "flux-1",
      "mode": "image",
      "max_input_tokens": 2048,
      "max_output_tokens": 0,
      "input_cost_per_1k": 5e-08,
      "output_cost_per_1k": 1.1e-07,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2024-07-31",
      "open_weights": true
    },
    "cloudflare_workers_ai/deepseek-r1-distill-qwen-32b": {
      "id": "deepseek-r1-distill-qwen-32b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 80000,
      "max_output_tokens": 80000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00488,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "cloudflare_workers_ai/gemma-2b-it-lora": {
      "id": "gemma-2b-it-lora",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/google/gemma-2b-it-lora",
      "family": "gemma-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-04-02",
      "open_weights": true
    },
    "cloudflare_workers_ai/una-cybertron-7b-v2-bf16": {
      "id": "una-cybertron-7b-v2-bf16",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/fblgit/una-cybertron-7b-v2-bf16",
      "family": "una-cybertron",
      "mode": "chat",
      "max_input_tokens": 15000,
      "max_output_tokens": 15000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-12-02",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/gemma-sea-lion-v4-27b-it": {
      "id": "gemma-sea-lion-v4-27b-it",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/aisingapore/gemma-sea-lion-v4-27b-it",
      "family": "gemma",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-09-23"
    },
    "cloudflare_workers_ai/m2m100-1.2b": {
      "id": "m2m100-1.2b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/m2m100-1.2b",
      "family": "m2m100-1.2b",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00034,
      "output_cost_per_1k": 0.00034,
      "release_date": "2022-03-02",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3.2-3b-instruct": {
      "id": "llama-3.2-3b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.2-3b-instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5.1e-05,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-09-18",
      "open_weights": true
    },
    "cloudflare_workers_ai/qwen2.5-coder-32b-instruct": {
      "id": "qwen2.5-coder-32b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen2.5-coder-32b-instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-11-06",
      "open_weights": true
    },
    "cloudflare_workers_ai/stable-diffusion-v1-5-img2img": {
      "id": "stable-diffusion-v1-5-img2img",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/runwayml/stable-diffusion-v1-5-img2img",
      "family": "stable-diffusion",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2024-02-27",
      "open_weights": true
    },
    "cloudflare_workers_ai/gemma-7b-it-lora": {
      "id": "gemma-7b-it-lora",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/google/gemma-7b-it-lora",
      "family": "gemma",
      "mode": "chat",
      "max_input_tokens": 3500,
      "max_output_tokens": 3500,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-04-02",
      "open_weights": true
    },
    "cloudflare_workers_ai/qwen1.5-14b-chat-awq": {
      "id": "qwen1.5-14b-chat-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen1.5-14b-chat-awq",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 7500,
      "max_output_tokens": 7500,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-02-03",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/qwen1.5-1.8b-chat": {
      "id": "qwen1.5-1.8b-chat",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen1.5-1.8b-chat",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-01-30",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/mistral-small-3.1-24b-instruct": {
      "id": "mistral-small-3.1-24b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/mistralai/mistral-small-3.1-24b-instruct",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-03-11",
      "open_weights": true
    },
    "cloudflare_workers_ai/gemma-7b-it": {
      "id": "gemma-7b-it",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/google/gemma-7b-it",
      "family": "gemma",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-02-13",
      "open_weights": true
    },
    "cloudflare_workers_ai/qwen3-30b-a3b-fp8": {
      "id": "qwen3-30b-a3b-fp8",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen3-30b-a3b-fp8",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "input_cost_per_1k": 5.1e-05,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-30",
      "open_weights": true
    },
    "cloudflare_workers_ai/llamaguard-7b-awq": {
      "id": "llamaguard-7b-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/llamaguard-7b-awq",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-12-11",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/hermes-2-pro-mistral-7b": {
      "id": "hermes-2-pro-mistral-7b",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/nousresearch/hermes-2-pro-mistral-7b",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-03-11",
      "open_weights": true
    },
    "cloudflare_workers_ai/granite-4.0-h-micro": {
      "id": "granite-4.0-h-micro",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/ibm-granite/granite-4.0-h-micro",
      "family": "granite",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 0,
      "input_cost_per_1k": 1.7e-05,
      "output_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-10-07"
    },
    "cloudflare_workers_ai/falcon-7b-instruct": {
      "id": "falcon-7b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/tiiuae/falcon-7b-instruct",
      "family": "falcon-7b",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-04-25",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-3.3-70b-instruct-fp8-fast": {
      "id": "llama-3.3-70b-instruct-fp8-fast",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.3-70b-instruct-fp8-fast",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00225,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3-8b-instruct-awq": {
      "id": "llama-3-8b-instruct-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3-8b-instruct-awq",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-05-09",
      "open_weights": true
    },
    "cloudflare_workers_ai/phoenix-1.0": {
      "id": "phoenix-1.0",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/leonardo/phoenix-1.0",
      "family": "phoenix",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 5.8e-06,
      "output_cost_per_1k": 5.8e-06,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2025-08-25"
    },
    "cloudflare_workers_ai/phi-2": {
      "id": "phi-2",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/microsoft/phi-2",
      "family": "phi",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-12-13",
      "open_weights": true
    },
    "cloudflare_workers_ai/dreamshaper-8-lcm": {
      "id": "dreamshaper-8-lcm",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/lykon/dreamshaper-8-lcm",
      "family": "dreamshaper-8-lcm",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output",
        "vision"
      ],
      "release_date": "2023-12-06",
      "open_weights": true
    },
    "cloudflare_workers_ai/discolm-german-7b-v1-awq": {
      "id": "discolm-german-7b-v1-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/thebloke/discolm-german-7b-v1-awq",
      "family": "discolm-german",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-01-18",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-2-7b-chat-int8": {
      "id": "llama-2-7b-chat-int8",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-2-7b-chat-int8",
      "family": "llama-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.000556,
      "output_cost_per_1k": 0.006667,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-09-25",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3.2-1b-instruct": {
      "id": "llama-3.2-1b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.2-1b-instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 60000,
      "max_output_tokens": 60000,
      "input_cost_per_1k": 2.7e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-09-18",
      "open_weights": true
    },
    "cloudflare_workers_ai/whisper-large-v3-turbo": {
      "id": "whisper-large-v3-turbo",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openai/whisper-large-v3-turbo",
      "family": "whisper-large",
      "mode": "audio_transcription",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 5.1e-07,
      "output_cost_per_1k": 5.1e-07,
      "capabilities": [
        "audio_input"
      ],
      "release_date": "2024-10-01",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-4-scout-17b-16e-instruct": {
      "id": "llama-4-scout-17b-16e-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-4-scout-17b-16e-instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-04-02",
      "open_weights": true
    },
    "cloudflare_workers_ai/starling-lm-7b-beta": {
      "id": "starling-lm-7b-beta",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/nexusflow/starling-lm-7b-beta",
      "family": "starling-lm",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-03-19",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/deepseek-coder-6.7b-base-awq": {
      "id": "deepseek-coder-6.7b-base-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/deepseek-coder-6.7b-base-awq",
      "family": "deepseek-coder",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-11-05",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/gemma-3-12b-it": {
      "id": "gemma-3-12b-it",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/google/gemma-3-12b-it",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 80000,
      "max_output_tokens": 80000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-03-01",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-guard-3-8b": {
      "id": "llama-guard-3-8b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-guard-3-8b",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00048,
      "output_cost_per_1k": 3e-05,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2024-07-22",
      "open_weights": true
    },
    "cloudflare_workers_ai/neural-chat-7b-v3-1-awq": {
      "id": "neural-chat-7b-v3-1-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/neural-chat-7b-v3-1-awq",
      "family": "neural-chat-7b-v3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-11-15",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/whisper-tiny-en": {
      "id": "whisper-tiny-en",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openai/whisper-tiny-en",
      "family": "whisper",
      "mode": "audio_transcription",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input"
      ],
      "release_date": "2022-09-26",
      "open_weights": true
    },
    "cloudflare_workers_ai/stable-diffusion-xl-lightning": {
      "id": "stable-diffusion-xl-lightning",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/bytedance/stable-diffusion-xl-lightning",
      "family": "stable-diffusion",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "image_output"
      ],
      "release_date": "2024-02-20",
      "open_weights": true
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.1": {
      "id": "mistral-7b-instruct-v0.1",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/mistral/mistral-7b-instruct-v0.1",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 2824,
      "max_output_tokens": 2824,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00019,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-09-27",
      "open_weights": true
    },
    "cloudflare_workers_ai/llava-1.5-7b-hf": {
      "id": "llava-1.5-7b-hf",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/llava-hf/llava-1.5-7b-hf",
      "family": "llava-1.5-7b-hf",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "release_date": "2023-12-05",
      "open_weights": true
    },
    "cloudflare_workers_ai/gpt-oss-20b": {
      "id": "gpt-oss-20b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openai/gpt-oss-20b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "reasoning"
      ],
      "release_date": "2025-08-04",
      "open_weights": true
    },
    "cloudflare_workers_ai/deepseek-math-7b-instruct": {
      "id": "deepseek-math-7b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/deepseek-ai/deepseek-math-7b-instruct",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-02-05",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/openai/gpt-oss-120b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00075,
      "capabilities": [
        "reasoning"
      ],
      "release_date": "2025-08-04",
      "open_weights": true
    },
    "cloudflare_workers_ai/melotts": {
      "id": "melotts",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/myshell-ai/melotts",
      "family": "melotts",
      "mode": "audio_speech",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 2e-07,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_output",
        "vision"
      ],
      "release_date": "2024-07-19",
      "open_weights": true
    },
    "cloudflare_workers_ai/qwen1.5-7b-chat-awq": {
      "id": "qwen1.5-7b-chat-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwen1.5-7b-chat-awq",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 20000,
      "max_output_tokens": 20000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-02-03",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-fast": {
      "id": "llama-3.1-8b-instruct-fast",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.1-8b-instruct-fast",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4.5e-05,
      "output_cost_per_1k": 0.000384,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "cloudflare_workers_ai/nova-3": {
      "id": "nova-3",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/deepgram/nova-3",
      "family": "nova",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 5.2e-06,
      "output_cost_per_1k": 5.2e-06,
      "capabilities": [
        "audio_input"
      ],
      "release_date": "2025-06-05",
      "open_weights": true
    },
    "cloudflare_workers_ai/llama-3.1-70b-instruct": {
      "id": "llama-3.1-70b-instruct",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.1-70b-instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "input_cost_per_1k": 0.000293,
      "output_cost_per_1k": 0.002253,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-16",
      "open_weights": true
    },
    "cloudflare_workers_ai/qwq-32b": {
      "id": "qwq-32b",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/qwen/qwq-32b",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 24000,
      "max_output_tokens": 24000,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-03-05",
      "open_weights": true
    },
    "cloudflare_workers_ai/zephyr-7b-beta-awq": {
      "id": "zephyr-7b-beta-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/zephyr-7b-beta-awq",
      "family": "zephyr",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-10-27",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/deepseek-coder-6.7b-instruct-awq": {
      "id": "deepseek-coder-6.7b-instruct-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@hf/thebloke/deepseek-coder-6.7b-instruct-awq",
      "family": "deepseek-coder",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2023-11-05",
      "open_weights": true,
      "deprecated": true
    },
    "cloudflare_workers_ai/llama-3.1-8b-instruct-awq": {
      "id": "llama-3.1-8b-instruct-awq",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/meta/llama-3.1-8b-instruct-awq",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-07-25",
      "open_weights": true
    },
    "cloudflare_workers_ai/mistral-7b-instruct-v0.2-lora": {
      "id": "mistral-7b-instruct-v0.2-lora",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/mistral/mistral-7b-instruct-v0.2-lora",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 15000,
      "max_output_tokens": 15000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-04-01",
      "open_weights": true
    },
    "cloudflare_workers_ai/uform-gen2-qwen-500m": {
      "id": "uform-gen2-qwen-500m",
      "provider": "cloudflare_workers_ai",
      "name": "@cf/unum/uform-gen2-qwen-500m",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "vision"
      ],
      "release_date": "2024-02-15",
      "open_weights": true
    },
    "inception/mercury-coder": {
      "id": "mercury-coder",
      "provider": "inception",
      "name": "Mercury Coder",
      "family": "mercury-coder",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-02-26"
    },
    "inception/mercury": {
      "id": "mercury",
      "provider": "inception",
      "name": "Mercury",
      "family": "mercury",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-06-26"
    },
    "wandb/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "wandb",
      "name": "Kimi-K2-Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-14",
      "open_weights": true
    },
    "wandb/microsoft/Phi-4-mini-instruct": {
      "id": "microsoft/Phi-4-mini-instruct",
      "provider": "wandb",
      "name": "Phi-4-mini-instruct",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "wandb/meta-llama/Llama-3.1-8B-Instruct": {
      "id": "meta-llama/Llama-3.1-8B-Instruct",
      "provider": "wandb",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "wandb/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "provider": "wandb",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00071,
      "output_cost_per_1k": 0.00071,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "wandb/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "wandb",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-31",
      "open_weights": true
    },
    "wandb/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "wandb",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "wandb/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "wandb",
      "name": "Qwen3-Coder-480B-A35B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "wandb/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "wandb",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "wandb/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "provider": "wandb",
      "name": "DeepSeek-R1-0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 161000,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "wandb/deepseek-ai/DeepSeek-V3-0324": {
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "provider": "wandb",
      "name": "DeepSeek-V3-0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 161000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00114,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "cloudflare_ai_gateway/workers-ai/@cf/ibm-granite/granite-4.0-h-micro": {
      "id": "workers-ai/@cf/ibm-granite/granite-4.0-h-micro",
      "provider": "cloudflare_ai_gateway",
      "name": "IBM Granite 4.0 H Micro",
      "family": "granite-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 1.7e-05,
      "output_cost_per_1k": 0.00011,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-10-15"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/facebook/bart-large-cnn": {
      "id": "workers-ai/@cf/facebook/bart-large-cnn",
      "provider": "cloudflare_ai_gateway",
      "name": "BART Large CNN",
      "family": "bart",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-09"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/mistral/mistral-7b-instruct-v0.1": {
      "id": "workers-ai/@cf/mistral/mistral-7b-instruct-v0.1",
      "provider": "cloudflare_ai_gateway",
      "name": "Mistral 7B Instruct v0.1",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00019,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/huggingface/distilbert-sst-2-int8": {
      "id": "workers-ai/@cf/huggingface/distilbert-sst-2-int8",
      "provider": "cloudflare_ai_gateway",
      "name": "DistilBERT SST-2 INT8",
      "family": "distilbert",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 2.6e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/myshell-ai/melotts": {
      "id": "workers-ai/@cf/myshell-ai/melotts",
      "provider": "cloudflare_ai_gateway",
      "name": "MyShell MeloTTS",
      "family": "melotts",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/google/gemma-3-12b-it": {
      "id": "workers-ai/@cf/google/gemma-3-12b-it",
      "provider": "cloudflare_ai_gateway",
      "name": "Gemma 3 12B IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/pfnet/plamo-embedding-1b": {
      "id": "workers-ai/@cf/pfnet/plamo-embedding-1b",
      "provider": "cloudflare_ai_gateway",
      "name": "PLaMo Embedding 1B",
      "family": "plamo-embedding",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 1.9e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/openai/gpt-oss-20b": {
      "id": "workers-ai/@cf/openai/gpt-oss-20b",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT OSS 20B",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/openai/gpt-oss-120b": {
      "id": "workers-ai/@cf/openai/gpt-oss-120b",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT OSS 120B",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00075,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B": {
      "id": "workers-ai/@cf/ai4bharat/indictrans2-en-indic-1B",
      "provider": "cloudflare_ai_gateway",
      "name": "IndicTrans2 EN-Indic 1B",
      "family": "indictrans2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00034,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/pipecat-ai/smart-turn-v2": {
      "id": "workers-ai/@cf/pipecat-ai/smart-turn-v2",
      "provider": "cloudflare_ai_gateway",
      "name": "Pipecat Smart Turn v2",
      "family": "smart-turn",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct": {
      "id": "workers-ai/@cf/qwen/qwen2.5-coder-32b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Qwen 2.5 Coder 32B Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen3-30b-a3b-fp8": {
      "id": "workers-ai/@cf/qwen/qwen3-30b-a3b-fp8",
      "provider": "cloudflare_ai_gateway",
      "name": "Qwen3 30B A3B FP8",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5.1e-05,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwen3-embedding-0.6b": {
      "id": "workers-ai/@cf/qwen/qwen3-embedding-0.6b",
      "provider": "cloudflare_ai_gateway",
      "name": "Qwen3 Embedding 0.6B",
      "family": "qwen3-embedding",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 1.2e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/qwen/qwq-32b": {
      "id": "workers-ai/@cf/qwen/qwq-32b",
      "provider": "cloudflare_ai_gateway",
      "name": "QwQ 32B",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00066,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct": {
      "id": "workers-ai/@cf/mistralai/mistral-small-3.1-24b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Mistral Small 3.1 24B Instruct",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-11"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/aura-2-es": {
      "id": "workers-ai/@cf/deepgram/aura-2-es",
      "provider": "cloudflare_ai_gateway",
      "name": "Deepgram Aura 2 (ES)",
      "family": "aura-2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/aura-2-en": {
      "id": "workers-ai/@cf/deepgram/aura-2-en",
      "provider": "cloudflare_ai_gateway",
      "name": "Deepgram Aura 2 (EN)",
      "family": "aura-2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepgram/nova-3": {
      "id": "workers-ai/@cf/deepgram/nova-3",
      "provider": "cloudflare_ai_gateway",
      "name": "Deepgram Nova 3",
      "family": "nova",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-11-14"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it": {
      "id": "workers-ai/@cf/aisingapore/gemma-sea-lion-v4-27b-it",
      "provider": "cloudflare_ai_gateway",
      "name": "Gemma SEA-LION v4 27B IT",
      "family": "gemma-sea-lion",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00056,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-09-25"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-11b-vision-instruct": {
      "id": "workers-ai/@cf/meta/llama-3.2-11b-vision-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.2 11B Vision Instruct",
      "family": "llama-3.2-vision",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 4.9e-05,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8": {
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct-fp8",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.1 8B Instruct FP8",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00029,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-2-7b-chat-fp16": {
      "id": "workers-ai/@cf/meta/llama-2-7b-chat-fp16",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 2 7B Chat FP16",
      "family": "llama-2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00667,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3-8b-instruct": {
      "id": "workers-ai/@cf/meta/llama-3-8b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3 8B Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00083,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct": {
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00083,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/m2m100-1.2b": {
      "id": "workers-ai/@cf/meta/m2m100-1.2b",
      "provider": "cloudflare_ai_gateway",
      "name": "M2M100 1.2B",
      "family": "m2m100",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00034,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-3b-instruct": {
      "id": "workers-ai/@cf/meta/llama-3.2-3b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.2 3B Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5.1e-05,
      "output_cost_per_1k": 0.00034,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast": {
      "id": "workers-ai/@cf/meta/llama-3.3-70b-instruct-fp8-fast",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.3 70B Instruct FP8 Fast",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00225,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3-8b-instruct-awq": {
      "id": "workers-ai/@cf/meta/llama-3-8b-instruct-awq",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3 8B Instruct AWQ",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.2-1b-instruct": {
      "id": "workers-ai/@cf/meta/llama-3.2-1b-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.2 1B Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 2.7e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct": {
      "id": "workers-ai/@cf/meta/llama-4-scout-17b-16e-instruct",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00085,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-guard-3-8b": {
      "id": "workers-ai/@cf/meta/llama-guard-3-8b",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama Guard 3 8B",
      "family": "llama-guard",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00048,
      "output_cost_per_1k": 3e-05,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/meta/llama-3.1-8b-instruct-awq": {
      "id": "workers-ai/@cf/meta/llama-3.1-8b-instruct-awq",
      "provider": "cloudflare_ai_gateway",
      "name": "Llama 3.1 8B Instruct AWQ",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.00027,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-m3": {
      "id": "workers-ai/@cf/baai/bge-m3",
      "provider": "cloudflare_ai_gateway",
      "name": "BGE M3",
      "family": "bge-m3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 1.2e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-base-en-v1.5": {
      "id": "workers-ai/@cf/baai/bge-base-en-v1.5",
      "provider": "cloudflare_ai_gateway",
      "name": "BGE Base EN v1.5",
      "family": "bge-base",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 6.7e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-large-en-v1.5": {
      "id": "workers-ai/@cf/baai/bge-large-en-v1.5",
      "provider": "cloudflare_ai_gateway",
      "name": "BGE Large EN v1.5",
      "family": "bge-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-reranker-base": {
      "id": "workers-ai/@cf/baai/bge-reranker-base",
      "provider": "cloudflare_ai_gateway",
      "name": "BGE Reranker Base",
      "family": "bge-reranker",
      "mode": "rerank",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 3.1e-06,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-09"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/baai/bge-small-en-v1.5": {
      "id": "workers-ai/@cf/baai/bge-small-en-v1.5",
      "provider": "cloudflare_ai_gateway",
      "name": "BGE Small EN v1.5",
      "family": "bge-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b": {
      "id": "workers-ai/@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
      "provider": "cloudflare_ai_gateway",
      "name": "DeepSeek R1 Distill Qwen 32B",
      "family": "deepseek-r1-distill-qwen",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00488,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-03"
    },
    "cloudflare_ai_gateway/openai/gpt-4": {
      "id": "openai/gpt-4",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-4",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "cloudflare_ai_gateway/openai/gpt-5.1-codex": {
      "id": "openai/gpt-5.1-codex",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "cloudflare_ai_gateway/openai/gpt-3.5-turbo": {
      "id": "openai/gpt-3.5-turbo",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-3.5-turbo",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-09-01",
      "release_date": "2023-03-01"
    },
    "cloudflare_ai_gateway/openai/gpt-4-turbo": {
      "id": "openai/gpt-4-turbo",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-4 Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2023-11-06"
    },
    "cloudflare_ai_gateway/openai/o3-mini": {
      "id": "openai/o3-mini",
      "provider": "cloudflare_ai_gateway",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "cloudflare_ai_gateway/openai/gpt-5.1": {
      "id": "openai/gpt-5.1",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "cloudflare_ai_gateway/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "cloudflare_ai_gateway/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "cloudflare_ai_gateway",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/openai/o1": {
      "id": "openai/o1",
      "provider": "cloudflare_ai_gateway",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-12-05"
    },
    "cloudflare_ai_gateway/openai/o3-pro": {
      "id": "openai/o3-pro",
      "provider": "cloudflare_ai_gateway",
      "name": "o3-pro",
      "family": "o3-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-06-10"
    },
    "cloudflare_ai_gateway/openai/o3": {
      "id": "openai/o3",
      "provider": "cloudflare_ai_gateway",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "cloudflare_ai_gateway/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-07-18"
    },
    "cloudflare_ai_gateway/openai/gpt-5.2": {
      "id": "openai/gpt-5.2",
      "provider": "cloudflare_ai_gateway",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Opus 4 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4-1": {
      "id": "anthropic/claude-opus-4-1",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Opus 4.1 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "cloudflare_ai_gateway/anthropic/claude-haiku-4-5": {
      "id": "anthropic/claude-haiku-4-5",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Haiku 4.5 (latest)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-haiku": {
      "id": "anthropic/claude-3-haiku",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Haiku 3",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-13"
    },
    "cloudflare_ai_gateway/anthropic/claude-opus-4-5": {
      "id": "anthropic/claude-opus-4-5",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Opus 4.5 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-opus": {
      "id": "anthropic/claude-3-opus",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Opus 3",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-02-29"
    },
    "cloudflare_ai_gateway/anthropic/claude-sonnet-4-5": {
      "id": "anthropic/claude-sonnet-4-5",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Sonnet 4.5 (latest)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "cloudflare_ai_gateway/anthropic/claude-3.5-sonnet": {
      "id": "anthropic/claude-3.5-sonnet",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Sonnet 3.5 v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-sonnet": {
      "id": "anthropic/claude-3-sonnet",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Sonnet 3",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-04"
    },
    "cloudflare_ai_gateway/anthropic/claude-3-5-haiku": {
      "id": "anthropic/claude-3-5-haiku",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Haiku 3.5 (latest)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-3.5-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Haiku 3.5 (latest)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "cloudflare_ai_gateway/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "cloudflare_ai_gateway",
      "name": "Claude Sonnet 4 (latest)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "openai/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "openai",
      "name": "GPT-4.1 nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "openai/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "provider": "openai",
      "name": "text-embedding-3-small",
      "family": "text-embedding-3-small",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-25"
    },
    "openai/gpt-4": {
      "id": "gpt-4",
      "provider": "openai",
      "name": "GPT-4",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.03,
      "output_cost_per_1k": 0.06,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "openai/o1-pro": {
      "id": "o1-pro",
      "provider": "openai",
      "name": "o1-pro",
      "family": "o1-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.15,
      "output_cost_per_1k": 0.6,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2025-03-19"
    },
    "openai/gpt-4o-2024-05-13": {
      "id": "gpt-4o-2024-05-13",
      "provider": "openai",
      "name": "GPT-4o (2024-05-13)",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "openai/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "openai",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openai/gpt-4o-2024-08-06": {
      "id": "gpt-4o-2024-08-06",
      "provider": "openai",
      "name": "GPT-4o (2024-08-06)",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-08-06"
    },
    "openai/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "openai",
      "name": "GPT-4.1 mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "openai/o3-deep-research": {
      "id": "o3-deep-research",
      "provider": "openai",
      "name": "o3-deep-research",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.04,
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-06-26"
    },
    "openai/gpt-3.5-turbo": {
      "id": "gpt-3.5-turbo",
      "provider": "openai",
      "name": "GPT-3.5-turbo",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16385,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-09-01",
      "release_date": "2023-03-01"
    },
    "openai/gpt-5.2-pro": {
      "id": "gpt-5.2-pro",
      "provider": "openai",
      "name": "GPT-5.2 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openai/text-embedding-3-large": {
      "id": "text-embedding-3-large",
      "provider": "openai",
      "name": "text-embedding-3-large",
      "family": "text-embedding-3-large",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-25"
    },
    "openai/gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "provider": "openai",
      "name": "GPT-4 Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2023-11-06"
    },
    "openai/o1-preview": {
      "id": "o1-preview",
      "provider": "openai",
      "name": "o1-preview",
      "family": "o1-preview",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "openai/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "openai",
      "name": "GPT-5.1 Codex mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openai/o3-mini": {
      "id": "o3-mini",
      "provider": "openai",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "openai/gpt-5.2-chat-latest": {
      "id": "gpt-5.2-chat-latest",
      "provider": "openai",
      "name": "GPT-5.2 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openai/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "openai",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openai/codex-mini-latest": {
      "id": "codex-mini-latest",
      "provider": "openai",
      "name": "Codex Mini",
      "family": "codex",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-16"
    },
    "openai/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "openai",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "openai",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "openai/gpt-4o": {
      "id": "gpt-4o",
      "provider": "openai",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "openai/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "openai",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "openai/o4-mini": {
      "id": "o4-mini",
      "provider": "openai",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "openai/o1": {
      "id": "o1",
      "provider": "openai",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-12-05"
    },
    "openai/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "openai",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "openai/o1-mini": {
      "id": "o1-mini",
      "provider": "openai",
      "name": "o1-mini",
      "family": "o1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "json_mode",
        "reasoning"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "openai/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "provider": "openai",
      "name": "text-embedding-ada-002",
      "family": "text-embedding-ada",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2022-12",
      "release_date": "2022-12-15"
    },
    "openai/o3-pro": {
      "id": "o3-pro",
      "provider": "openai",
      "name": "o3-pro",
      "family": "o3-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.02,
      "output_cost_per_1k": 0.08,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-06-10"
    },
    "openai/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "provider": "openai",
      "name": "GPT-4o (2024-11-20)",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-11-20"
    },
    "openai/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "provider": "openai",
      "name": "GPT-5.1 Codex Max",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openai/o3": {
      "id": "o3",
      "provider": "openai",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "openai/o4-mini-deep-research": {
      "id": "o4-mini-deep-research",
      "provider": "openai",
      "name": "o4-mini-deep-research",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-06-26"
    },
    "openai/gpt-5-chat-latest": {
      "id": "gpt-5-chat-latest",
      "provider": "openai",
      "name": "GPT-5 Chat (latest)",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "openai/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "provider": "openai",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-07-18"
    },
    "openai/gpt-5": {
      "id": "gpt-5",
      "provider": "openai",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "openai/gpt-5-pro": {
      "id": "gpt-5-pro",
      "provider": "openai",
      "name": "GPT-5 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-10-06"
    },
    "openai/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "openai",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openai/gpt-5.1-chat-latest": {
      "id": "gpt-5.1-chat-latest",
      "provider": "openai",
      "name": "GPT-5.1 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "zhipuai_coding_plan/glm-4.6v-flash": {
      "id": "glm-4.6v-flash",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.6V-Flash",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.6v": {
      "id": "glm-4.6v",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.6V",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.6": {
      "id": "glm-4.6",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.5v": {
      "id": "glm-4.5v",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.5-air": {
      "id": "glm-4.5-air",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.5": {
      "id": "glm-4.5",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.5-flash": {
      "id": "glm-4.5-flash",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.5-Flash",
      "family": "glm-4.5-flash",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai_coding_plan/glm-4.7": {
      "id": "glm-4.7",
      "provider": "zhipuai_coding_plan",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "minimax_cn/MiniMax-M2.1": {
      "id": "MiniMax-M2.1",
      "provider": "minimax_cn",
      "name": "MiniMax-M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "minimax_cn/MiniMax-M2": {
      "id": "MiniMax-M2",
      "provider": "minimax_cn",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "perplexity/sonar": {
      "id": "sonar",
      "provider": "perplexity",
      "name": "Sonar",
      "family": "sonar",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2025-09-01",
      "release_date": "2024-01-01"
    },
    "perplexity/sonar-pro": {
      "id": "sonar-pro",
      "provider": "perplexity",
      "name": "Sonar Pro",
      "family": "sonar-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09-01",
      "release_date": "2024-01-01"
    },
    "perplexity/sonar-reasoning-pro": {
      "id": "sonar-reasoning-pro",
      "provider": "perplexity",
      "name": "Sonar Reasoning Pro",
      "family": "sonar-reasoning",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-09-01",
      "release_date": "2024-01-01"
    },
    "openrouter/moonshotai/kimi-k2": {
      "id": "moonshotai/kimi-k2",
      "provider": "openrouter",
      "name": "Kimi K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "openrouter/moonshotai/kimi-k2-0905": {
      "id": "moonshotai/kimi-k2-0905",
      "provider": "openrouter",
      "name": "Kimi K2 Instruct 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "openrouter/moonshotai/kimi-dev-72b:free": {
      "id": "moonshotai/kimi-dev-72b:free",
      "provider": "openrouter",
      "name": "Kimi Dev 72b (free)",
      "family": "kimi",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-06-16",
      "open_weights": true
    },
    "openrouter/moonshotai/kimi-k2-thinking": {
      "id": "moonshotai/kimi-k2-thinking",
      "provider": "openrouter",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "openrouter/moonshotai/kimi-k2-0905:exacto": {
      "id": "moonshotai/kimi-k2-0905:exacto",
      "provider": "openrouter",
      "name": "Kimi K2 Instruct 0905 (exacto)",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "openrouter/moonshotai/kimi-k2:free": {
      "id": "moonshotai/kimi-k2:free",
      "provider": "openrouter",
      "name": "Kimi K2 (free)",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 32800,
      "max_output_tokens": 32800,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "openrouter/thudm/glm-z1-32b:free": {
      "id": "thudm/glm-z1-32b:free",
      "provider": "openrouter",
      "name": "GLM Z1 32B (free)",
      "family": "glm-z1",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-17",
      "open_weights": true
    },
    "openrouter/nousresearch/hermes-4-70b": {
      "id": "nousresearch/hermes-4-70b",
      "provider": "openrouter",
      "name": "Hermes 4 70B",
      "family": "hermes",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-08-25",
      "open_weights": true
    },
    "openrouter/nousresearch/hermes-4-405b": {
      "id": "nousresearch/hermes-4-405b",
      "provider": "openrouter",
      "name": "Hermes 4 405B",
      "family": "hermes",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-08-25",
      "open_weights": true
    },
    "openrouter/nousresearch/deephermes-3-llama-3-8b-preview": {
      "id": "nousresearch/deephermes-3-llama-3-8b-preview",
      "provider": "openrouter",
      "name": "DeepHermes 3 Llama 3 8B Preview",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-02-28",
      "open_weights": true
    },
    "openrouter/nvidia/nemotron-nano-9b-v2": {
      "id": "nvidia/nemotron-nano-9b-v2",
      "provider": "openrouter",
      "name": "nvidia-nemotron-nano-9b-v2",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-08-18",
      "open_weights": true
    },
    "openrouter/x-ai/grok-4": {
      "id": "x-ai/grok-4",
      "provider": "openrouter",
      "name": "Grok 4",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "openrouter/x-ai/grok-code-fast-1": {
      "id": "x-ai/grok-code-fast-1",
      "provider": "openrouter",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-08",
      "release_date": "2025-08-26"
    },
    "openrouter/x-ai/grok-3": {
      "id": "x-ai/grok-3",
      "provider": "openrouter",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-4-fast": {
      "id": "x-ai/grok-4-fast",
      "provider": "openrouter",
      "name": "Grok 4 Fast",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-08-19"
    },
    "openrouter/x-ai/grok-3-beta": {
      "id": "x-ai/grok-3-beta",
      "provider": "openrouter",
      "name": "Grok 3 Beta",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-3-mini-beta": {
      "id": "x-ai/grok-3-mini-beta",
      "provider": "openrouter",
      "name": "Grok 3 Mini Beta",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-3-mini": {
      "id": "x-ai/grok-3-mini",
      "provider": "openrouter",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "openrouter/x-ai/grok-4.1-fast": {
      "id": "x-ai/grok-4.1-fast",
      "provider": "openrouter",
      "name": "Grok 4.1 Fast",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-11-19"
    },
    "openrouter/kwaipilot/kat-coder-pro:free": {
      "id": "kwaipilot/kat-coder-pro:free",
      "provider": "openrouter",
      "name": "Kat Coder Pro (free)",
      "family": "kat-coder-pro",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-10"
    },
    "openrouter/cognitivecomputations/dolphin3.0-mistral-24b": {
      "id": "cognitivecomputations/dolphin3.0-mistral-24b",
      "provider": "openrouter",
      "name": "Dolphin3.0 Mistral 24B",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-02-13",
      "open_weights": true
    },
    "openrouter/cognitivecomputations/dolphin3.0-r1-mistral-24b": {
      "id": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
      "provider": "openrouter",
      "name": "Dolphin3.0 R1 Mistral 24B",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-02-13",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-chat-v3.1": {
      "id": "deepseek/deepseek-chat-v3.1",
      "provider": "openrouter",
      "name": "DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-r1:free": {
      "id": "deepseek/deepseek-r1:free",
      "provider": "openrouter",
      "name": "R1 (free)",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-v3.2-speciale": {
      "id": "deepseek/deepseek-v3.2-speciale",
      "provider": "openrouter",
      "name": "DeepSeek V3.2 Speciale",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.00041,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-v3-base:free": {
      "id": "deepseek/deepseek-v3-base:free",
      "provider": "openrouter",
      "name": "DeepSeek V3 Base (free)",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-03-29",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-v3.1-terminus": {
      "id": "deepseek/deepseek-v3.1-terminus",
      "provider": "openrouter",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-22",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-r1-0528-qwen3-8b:free": {
      "id": "deepseek/deepseek-r1-0528-qwen3-8b:free",
      "provider": "openrouter",
      "name": "Deepseek R1 0528 Qwen3 8B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-29",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-chat-v3-0324": {
      "id": "deepseek/deepseek-chat-v3-0324",
      "provider": "openrouter",
      "name": "DeepSeek V3 0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-r1-0528:free": {
      "id": "deepseek/deepseek-r1-0528:free",
      "provider": "openrouter",
      "name": "R1 0528 (free)",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-r1-distill-llama-70b": {
      "id": "deepseek/deepseek-r1-distill-llama-70b",
      "provider": "openrouter",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-23",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-r1-distill-qwen-14b": {
      "id": "deepseek/deepseek-r1-distill-qwen-14b",
      "provider": "openrouter",
      "name": "DeepSeek R1 Distill Qwen 14B",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-29",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-v3.1-terminus:exacto": {
      "id": "deepseek/deepseek-v3.1-terminus:exacto",
      "provider": "openrouter",
      "name": "DeepSeek V3.1 Terminus (exacto)",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-22",
      "open_weights": true
    },
    "openrouter/deepseek/deepseek-v3.2": {
      "id": "deepseek/deepseek-v3.2",
      "provider": "openrouter",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "openrouter/featherless/qwerky-72b": {
      "id": "featherless/qwerky-72b",
      "provider": "openrouter",
      "name": "Qwerky 72B",
      "family": "qwerky",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-20",
      "open_weights": true
    },
    "openrouter/tngtech/deepseek-r1t2-chimera:free": {
      "id": "tngtech/deepseek-r1t2-chimera:free",
      "provider": "openrouter",
      "name": "DeepSeek R1T2 Chimera (free)",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-08",
      "open_weights": true
    },
    "openrouter/minimax/minimax-m1": {
      "id": "minimax/minimax-m1",
      "provider": "openrouter",
      "name": "MiniMax M1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 40000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-17",
      "open_weights": true
    },
    "openrouter/minimax/minimax-m2": {
      "id": "minimax/minimax-m2",
      "provider": "openrouter",
      "name": "MiniMax M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 196600,
      "max_output_tokens": 118000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00115,
      "cache_read_cost_per_1k": 0.00028,
      "cache_write_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-23",
      "open_weights": true
    },
    "openrouter/minimax/minimax-01": {
      "id": "minimax/minimax-01",
      "provider": "openrouter",
      "name": "MiniMax-01",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 1000000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-15",
      "open_weights": true
    },
    "openrouter/minimax/minimax-m2.1": {
      "id": "minimax/minimax-m2.1",
      "provider": "openrouter",
      "name": "MiniMax M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "openrouter/google/gemini-2.0-flash-001": {
      "id": "google/gemini-2.0-flash-001",
      "provider": "openrouter",
      "name": "Gemini 2.0 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-12-11"
    },
    "openrouter/google/gemma-2-9b-it:free": {
      "id": "google/gemma-2-9b-it:free",
      "provider": "openrouter",
      "name": "Gemma 2 9B (free)",
      "family": "gemma-2",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2024-06-28",
      "open_weights": true
    },
    "openrouter/google/gemini-3-flash-preview": {
      "id": "google/gemini-3-flash-preview",
      "provider": "openrouter",
      "name": "Gemini 3 Flash Preview",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "openrouter/google/gemini-3-pro-preview": {
      "id": "google/gemini-3-pro-preview",
      "provider": "openrouter",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1050000,
      "max_output_tokens": 66000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "openrouter/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "openrouter",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 3.75e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-07-17"
    },
    "openrouter/google/gemini-2.5-pro-preview-05-06": {
      "id": "google/gemini-2.5-pro-preview-05-06",
      "provider": "openrouter",
      "name": "Gemini 2.5 Pro Preview 05-06",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-05-06"
    },
    "openrouter/google/gemma-3n-e4b-it": {
      "id": "google/gemma-3n-e4b-it",
      "provider": "openrouter",
      "name": "Gemma 3n E4B IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-05-20",
      "open_weights": true
    },
    "openrouter/google/gemini-2.5-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "openrouter",
      "name": "Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "openrouter/google/gemini-2.5-pro-preview-06-05": {
      "id": "google/gemini-2.5-pro-preview-06-05",
      "provider": "openrouter",
      "name": "Gemini 2.5 Pro Preview 06-05",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-05"
    },
    "openrouter/google/gemini-2.5-flash-preview-09-2025": {
      "id": "google/gemini-2.5-flash-preview-09-2025",
      "provider": "openrouter",
      "name": "Gemini 2.5 Flash Preview 09-25",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 3.1e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "openrouter/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "openrouter",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "openrouter/google/gemma-3-12b-it": {
      "id": "google/gemma-3-12b-it",
      "provider": "openrouter",
      "name": "Gemma 3 12B IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-13",
      "open_weights": true
    },
    "openrouter/google/gemma-3n-e4b-it:free": {
      "id": "google/gemma-3n-e4b-it:free",
      "provider": "openrouter",
      "name": "Gemma 3n 4B (free)",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-20",
      "open_weights": true
    },
    "openrouter/google/gemini-2.5-flash-lite-preview-09-2025": {
      "id": "google/gemini-2.5-flash-lite-preview-09-2025",
      "provider": "openrouter",
      "name": "Gemini 2.5 Flash Lite Preview 09-25",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-25"
    },
    "openrouter/google/gemini-2.0-flash-exp:free": {
      "id": "google/gemini-2.0-flash-exp:free",
      "provider": "openrouter",
      "name": "Gemini 2.0 Flash Experimental (free)",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 1048576,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-11"
    },
    "openrouter/google/gemma-3-27b-it": {
      "id": "google/gemma-3-27b-it",
      "provider": "openrouter",
      "name": "Gemma 3 27B IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-12",
      "open_weights": true
    },
    "openrouter/microsoft/mai-ds-r1:free": {
      "id": "microsoft/mai-ds-r1:free",
      "provider": "openrouter",
      "name": "MAI DS R1 (free)",
      "family": "mai-ds-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-21",
      "open_weights": true
    },
    "openrouter/openai/gpt-oss-safeguard-20b": {
      "id": "openai/gpt-oss-safeguard-20b",
      "provider": "openrouter",
      "name": "GPT OSS Safeguard 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-29"
    },
    "openrouter/openai/gpt-5.1-codex": {
      "id": "openai/gpt-5.1-codex",
      "provider": "openrouter",
      "name": "GPT-5.1-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "provider": "openrouter",
      "name": "GPT-4.1 Mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "openrouter/openai/gpt-5-chat": {
      "id": "openai/gpt-5-chat",
      "provider": "openrouter",
      "name": "GPT-5 Chat (latest)",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5.2-pro": {
      "id": "openai/gpt-5.2-pro",
      "provider": "openrouter",
      "name": "GPT-5.2 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.021,
      "output_cost_per_1k": 0.168,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openrouter/openai/gpt-5.1-codex-mini": {
      "id": "openai/gpt-5.1-codex-mini",
      "provider": "openrouter",
      "name": "GPT-5.1-Codex-Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5.2-chat-latest": {
      "id": "openai/gpt-5.2-chat-latest",
      "provider": "openrouter",
      "name": "GPT-5.2 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openrouter/openai/gpt-5.1": {
      "id": "openai/gpt-5.1",
      "provider": "openrouter",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "provider": "openrouter",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-codex": {
      "id": "openai/gpt-5-codex",
      "provider": "openrouter",
      "name": "GPT-5 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-09-15"
    },
    "openrouter/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "openrouter",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "openrouter/openai/gpt-oss-120b:exacto": {
      "id": "openai/gpt-oss-120b:exacto",
      "provider": "openrouter",
      "name": "GPT OSS 120B (exacto)",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "openrouter/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "openrouter",
      "name": "o4 Mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-04-16"
    },
    "openrouter/openai/gpt-5.1-chat": {
      "id": "openai/gpt-5.1-chat",
      "provider": "openrouter",
      "name": "GPT-5.1 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "openrouter/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "provider": "openrouter",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-image": {
      "id": "openai/gpt-5-image",
      "provider": "openrouter",
      "name": "GPT-5 Image",
      "family": "gpt-5",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "image_output",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-10-14"
    },
    "openrouter/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "openrouter",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "openrouter/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "openrouter",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 7.2e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "openrouter/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "openrouter",
      "name": "GPT-4o-mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-07-18"
    },
    "openrouter/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "openrouter",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-01",
      "release_date": "2025-08-07"
    },
    "openrouter/openai/gpt-5-pro": {
      "id": "openai/gpt-5-pro",
      "provider": "openrouter",
      "name": "GPT-5 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-10-06"
    },
    "openrouter/openai/gpt-5.2": {
      "id": "openai/gpt-5.2",
      "provider": "openrouter",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "openrouter/openrouter/sherlock-think-alpha": {
      "id": "openrouter/sherlock-think-alpha",
      "provider": "openrouter",
      "name": "Sherlock Think Alpha",
      "family": "sherlock",
      "mode": "chat",
      "max_input_tokens": 1840000,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-15"
    },
    "openrouter/openrouter/sherlock-dash-alpha": {
      "id": "openrouter/sherlock-dash-alpha",
      "provider": "openrouter",
      "name": "Sherlock Dash Alpha",
      "family": "sherlock",
      "mode": "chat",
      "max_input_tokens": 1840000,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-15"
    },
    "openrouter/z-ai/glm-4.7": {
      "id": "z-ai/glm-4.7",
      "provider": "openrouter",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.5": {
      "id": "z-ai/glm-4.5",
      "provider": "openrouter",
      "name": "GLM 4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.5-air": {
      "id": "z-ai/glm-4.5-air",
      "provider": "openrouter",
      "name": "GLM 4.5 Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.5v": {
      "id": "z-ai/glm-4.5v",
      "provider": "openrouter",
      "name": "GLM 4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.6": {
      "id": "z-ai/glm-4.6",
      "provider": "openrouter",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.6:exacto": {
      "id": "z-ai/glm-4.6:exacto",
      "provider": "openrouter",
      "name": "GLM 4.6 (exacto)",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0019,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "openrouter/z-ai/glm-4.5-air:free": {
      "id": "z-ai/glm-4.5-air:free",
      "provider": "openrouter",
      "name": "GLM 4.5 Air (free)",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-coder": {
      "id": "qwen/qwen3-coder",
      "provider": "openrouter",
      "name": "Qwen3 Coder",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-32b:free": {
      "id": "qwen/qwen3-32b:free",
      "provider": "openrouter",
      "name": "Qwen3 32B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-next-80b-a3b-instruct": {
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "provider": "openrouter",
      "name": "Qwen3 Next 80B A3B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-11",
      "open_weights": true
    },
    "openrouter/qwen/qwen-2.5-coder-32b-instruct": {
      "id": "qwen/qwen-2.5-coder-32b-instruct",
      "provider": "openrouter",
      "name": "Qwen2.5 Coder 32B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-11",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-235b-a22b:free": {
      "id": "qwen/qwen3-235b-a22b:free",
      "provider": "openrouter",
      "name": "Qwen3 235B A22B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-coder-flash": {
      "id": "qwen/qwen3-coder-flash",
      "provider": "openrouter",
      "name": "Qwen3 Coder Flash",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23"
    },
    "openrouter/qwen/qwq-32b:free": {
      "id": "qwen/qwq-32b:free",
      "provider": "openrouter",
      "name": "QwQ 32B (free)",
      "family": "qwq",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-03-05",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-30b-a3b-thinking-2507": {
      "id": "qwen/qwen3-30b-a3b-thinking-2507",
      "provider": "openrouter",
      "name": "Qwen3 30B A3B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-29",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-30b-a3b:free": {
      "id": "qwen/qwen3-30b-a3b:free",
      "provider": "openrouter",
      "name": "Qwen3 30B A3B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen2.5-vl-72b-instruct": {
      "id": "qwen/qwen2.5-vl-72b-instruct",
      "provider": "openrouter",
      "name": "Qwen2.5 VL 72B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-02-01",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-14b:free": {
      "id": "qwen/qwen3-14b:free",
      "provider": "openrouter",
      "name": "Qwen3 14B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-30b-a3b-instruct-2507": {
      "id": "qwen/qwen3-30b-a3b-instruct-2507",
      "provider": "openrouter",
      "name": "Qwen3 30B A3B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-29",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "provider": "openrouter",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 81920,
      "input_cost_per_1k": 7.8e-05,
      "output_cost_per_1k": 0.000312,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "openrouter/qwen/qwen2.5-vl-32b-instruct:free": {
      "id": "qwen/qwen2.5-vl-32b-instruct:free",
      "provider": "openrouter",
      "name": "Qwen2.5 VL 32B Instruct (free)",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "openrouter/qwen/qwen2.5-vl-72b-instruct:free": {
      "id": "qwen/qwen2.5-vl-72b-instruct:free",
      "provider": "openrouter",
      "name": "Qwen2.5 VL 72B Instruct (free)",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02",
      "release_date": "2025-02-01",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-235b-a22b-07-25:free": {
      "id": "qwen/qwen3-235b-a22b-07-25:free",
      "provider": "openrouter",
      "name": "Qwen3 235B A22B Instruct 2507 (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-coder:free": {
      "id": "qwen/qwen3-coder:free",
      "provider": "openrouter",
      "name": "Qwen3 Coder 480B A35B Instruct (free)",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-235b-a22b-07-25": {
      "id": "qwen/qwen3-235b-a22b-07-25",
      "provider": "openrouter",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-8b:free": {
      "id": "qwen/qwen3-8b:free",
      "provider": "openrouter",
      "name": "Qwen3 8B (free)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 40960,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-max": {
      "id": "qwen/qwen3-max",
      "provider": "openrouter",
      "name": "Qwen3 Max",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-05"
    },
    "openrouter/qwen/qwen3-next-80b-a3b-thinking": {
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "provider": "openrouter",
      "name": "Qwen3 Next 80B A3B Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-11",
      "open_weights": true
    },
    "openrouter/qwen/qwen3-coder:exacto": {
      "id": "qwen/qwen3-coder:exacto",
      "provider": "openrouter",
      "name": "Qwen3 Coder (exacto)",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00038,
      "output_cost_per_1k": 0.00153,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-medium-2507": {
      "id": "mistralai/devstral-medium-2507",
      "provider": "openrouter",
      "name": "Devstral Medium",
      "family": "devstral-medium",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-07-10",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-2512:free": {
      "id": "mistralai/devstral-2512:free",
      "provider": "openrouter",
      "name": "Devstral 2 2512 (free)",
      "family": "devstral",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-09-12",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-2512": {
      "id": "mistralai/devstral-2512",
      "provider": "openrouter",
      "name": "Devstral 2 2512",
      "family": "devstral",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-09-12",
      "open_weights": true
    },
    "openrouter/mistralai/codestral-2508": {
      "id": "mistralai/codestral-2508",
      "provider": "openrouter",
      "name": "Codestral 2508",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-08-01",
      "open_weights": true
    },
    "openrouter/mistralai/mistral-7b-instruct:free": {
      "id": "mistralai/mistral-7b-instruct:free",
      "provider": "openrouter",
      "name": "Mistral 7B Instruct (free)",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-05-27",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-small-2505": {
      "id": "mistralai/devstral-small-2505",
      "provider": "openrouter",
      "name": "Devstral Small",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07",
      "open_weights": true
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct": {
      "id": "mistralai/mistral-small-3.2-24b-instruct",
      "provider": "openrouter",
      "name": "Mistral Small 3.2 24B Instruct",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-06-20",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-small-2505:free": {
      "id": "mistralai/devstral-small-2505:free",
      "provider": "openrouter",
      "name": "Devstral Small 2505 (free)",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-21",
      "open_weights": true
    },
    "openrouter/mistralai/mistral-small-3.2-24b-instruct:free": {
      "id": "mistralai/mistral-small-3.2-24b-instruct:free",
      "provider": "openrouter",
      "name": "Mistral Small 3.2 24B (free)",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 96000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-06",
      "release_date": "2025-06-20",
      "open_weights": true
    },
    "openrouter/mistralai/mistral-medium-3": {
      "id": "mistralai/mistral-medium-3",
      "provider": "openrouter",
      "name": "Mistral Medium 3",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07"
    },
    "openrouter/mistralai/mistral-small-3.1-24b-instruct": {
      "id": "mistralai/mistral-small-3.1-24b-instruct",
      "provider": "openrouter",
      "name": "Mistral Small 3.1 24B Instruct",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-17",
      "open_weights": true
    },
    "openrouter/mistralai/devstral-small-2507": {
      "id": "mistralai/devstral-small-2507",
      "provider": "openrouter",
      "name": "Devstral Small 1.1",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-07-10",
      "open_weights": true
    },
    "openrouter/mistralai/mistral-medium-3.1": {
      "id": "mistralai/mistral-medium-3.1",
      "provider": "openrouter",
      "name": "Mistral Medium 3.1",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-08-12"
    },
    "openrouter/mistralai/mistral-nemo:free": {
      "id": "mistralai/mistral-nemo:free",
      "provider": "openrouter",
      "name": "Mistral Nemo (free)",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-19",
      "open_weights": true
    },
    "openrouter/rekaai/reka-flash-3": {
      "id": "rekaai/reka-flash-3",
      "provider": "openrouter",
      "name": "Reka Flash 3",
      "family": "reka-flash",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-12",
      "open_weights": true
    },
    "openrouter/meta-llama/llama-3.2-11b-vision-instruct": {
      "id": "meta-llama/llama-3.2-11b-vision-instruct",
      "provider": "openrouter",
      "name": "Llama 3.2 11B Vision Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "openrouter/meta-llama/llama-3.3-70b-instruct:free": {
      "id": "meta-llama/llama-3.3-70b-instruct:free",
      "provider": "openrouter",
      "name": "Llama 3.3 70B Instruct (free)",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "openrouter/meta-llama/llama-4-scout:free": {
      "id": "meta-llama/llama-4-scout:free",
      "provider": "openrouter",
      "name": "Llama 4 Scout (free)",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "openrouter/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "provider": "openrouter",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "openrouter/anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "provider": "openrouter",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "openrouter/anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "provider": "openrouter",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "openrouter/anthropic/claude-3.7-sonnet": {
      "id": "anthropic/claude-3.7-sonnet",
      "provider": "openrouter",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2025-02-19"
    },
    "openrouter/anthropic/claude-3.5-haiku": {
      "id": "anthropic/claude-3.5-haiku",
      "provider": "openrouter",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "openrouter/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "openrouter",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "openrouter/anthropic/claude-opus-4.5": {
      "id": "anthropic/claude-opus-4.5",
      "provider": "openrouter",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05-30",
      "release_date": "2025-11-24"
    },
    "openrouter/anthropic/claude-sonnet-4.5": {
      "id": "anthropic/claude-sonnet-4.5",
      "provider": "openrouter",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "openrouter/sarvamai/sarvam-m:free": {
      "id": "sarvamai/sarvam-m:free",
      "provider": "openrouter",
      "name": "Sarvam-M (free)",
      "family": "sarvam-m",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-25",
      "open_weights": true
    },
    "zenmux/stepfun/step-3": {
      "id": "stepfun/step-3",
      "provider": "zenmux",
      "name": "Step-3",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 65536,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.00057,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-18"
    },
    "zenmux/moonshotai/kimi-k2-thinking-turbo": {
      "id": "moonshotai/kimi-k2-thinking-turbo",
      "provider": "zenmux",
      "name": "Kimi K2 Thinking Turbo",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00115,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-06"
    },
    "zenmux/moonshotai/kimi-k2-0905": {
      "id": "moonshotai/kimi-k2-0905",
      "provider": "zenmux",
      "name": "Kimi K2 0905",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262100,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-09"
    },
    "zenmux/moonshotai/kimi-k2-thinking": {
      "id": "moonshotai/kimi-k2-thinking",
      "provider": "zenmux",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-06"
    },
    "zenmux/xiaomi/mimo-v2-flash-free": {
      "id": "xiaomi/mimo-v2-flash-free",
      "provider": "zenmux",
      "name": "MiMo-V2-Flash Free",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-31"
    },
    "zenmux/xiaomi/mimo-v2-flash": {
      "id": "xiaomi/mimo-v2-flash",
      "provider": "zenmux",
      "name": "MiMo-V2-Flash",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-17"
    },
    "zenmux/x-ai/grok-4": {
      "id": "x-ai/grok-4",
      "provider": "zenmux",
      "name": "Grok 4",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-19"
    },
    "zenmux/x-ai/grok-code-fast-1": {
      "id": "x-ai/grok-code-fast-1",
      "provider": "zenmux",
      "name": "Grok Code Fast 1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-19"
    },
    "zenmux/x-ai/grok-4.1-fast-non-reasoning": {
      "id": "x-ai/grok-4.1-fast-non-reasoning",
      "provider": "zenmux",
      "name": "Grok 4.1 Fast Non Reasoning",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-20"
    },
    "zenmux/x-ai/grok-4-fast": {
      "id": "x-ai/grok-4-fast",
      "provider": "zenmux",
      "name": "Grok 4 Fast",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-22"
    },
    "zenmux/x-ai/grok-4.1-fast": {
      "id": "x-ai/grok-4.1-fast",
      "provider": "zenmux",
      "name": "Grok 4.1 Fast",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-20"
    },
    "zenmux/deepseek/deepseek-chat": {
      "id": "deepseek/deepseek-chat",
      "provider": "zenmux",
      "name": "DeepSeek-V3.2 (Non-thinking Mode)",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-10"
    },
    "zenmux/deepseek/deepseek-v3.2-exp": {
      "id": "deepseek/deepseek-v3.2-exp",
      "provider": "zenmux",
      "name": "DeepSeek-V3.2-Exp",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00033,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-26"
    },
    "zenmux/deepseek/deepseek-reasoner": {
      "id": "deepseek/deepseek-reasoner",
      "provider": "zenmux",
      "name": "DeepSeek-V3.2 (Thinking Mode)",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-23"
    },
    "zenmux/deepseek/deepseek-v3.2": {
      "id": "deepseek/deepseek-v3.2",
      "provider": "zenmux",
      "name": "DeepSeek V3.2",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00043,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-08"
    },
    "zenmux/minimax/minimax-m2": {
      "id": "minimax/minimax-m2",
      "provider": "zenmux",
      "name": "MiniMax M2",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-28"
    },
    "zenmux/minimax/minimax-m2.1": {
      "id": "minimax/minimax-m2.1",
      "provider": "zenmux",
      "name": "MiniMax M2.1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-23"
    },
    "zenmux/google/gemini-3-flash-preview": {
      "id": "google/gemini-3-flash-preview",
      "provider": "zenmux",
      "name": "Gemini 3 Flash Preview",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-17"
    },
    "zenmux/google/gemini-3-flash-preview-free": {
      "id": "google/gemini-3-flash-preview-free",
      "provider": "zenmux",
      "name": "Gemini 3 Flash Preview Free",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-17"
    },
    "zenmux/google/gemini-3-pro-preview": {
      "id": "google/gemini-3-pro-preview",
      "provider": "zenmux",
      "name": "Gemini 3 Pro Preview",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "cache_write_cost_per_1k": 0.0045,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-18"
    },
    "zenmux/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "zenmux",
      "name": "Gemini 2.5 Flash",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-18"
    },
    "zenmux/google/gemini-2.5-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "zenmux",
      "name": "Gemini 2.5 Flash Lite",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-14"
    },
    "zenmux/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "zenmux",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "cache_write_cost_per_1k": 0.0045,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-20"
    },
    "zenmux/volcengine/doubao-seed-code": {
      "id": "volcengine/doubao-seed-code",
      "provider": "zenmux",
      "name": "Doubao-Seed-Code",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00112,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-11"
    },
    "zenmux/volcengine/doubao-seed-1.8": {
      "id": "volcengine/doubao-seed-1.8",
      "provider": "zenmux",
      "name": "Doubao-Seed-1.8",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00028,
      "cache_read_cost_per_1k": 2e-05,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-18"
    },
    "zenmux/openai/gpt-5.1-codex": {
      "id": "openai/gpt-5.1-codex",
      "provider": "zenmux",
      "name": "GPT-5.1-Codex",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-14"
    },
    "zenmux/openai/gpt-5.1-codex-mini": {
      "id": "openai/gpt-5.1-codex-mini",
      "provider": "zenmux",
      "name": "GPT-5.1-Codex-Mini",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-14"
    },
    "zenmux/openai/gpt-5.1": {
      "id": "openai/gpt-5.1",
      "provider": "zenmux",
      "name": "GPT-5.1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-14"
    },
    "zenmux/openai/gpt-5-codex": {
      "id": "openai/gpt-5-codex",
      "provider": "zenmux",
      "name": "GPT-5 Codex",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-13"
    },
    "zenmux/openai/gpt-5.1-chat": {
      "id": "openai/gpt-5.1-chat",
      "provider": "zenmux",
      "name": "GPT-5.1 Chat",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-14"
    },
    "zenmux/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "zenmux",
      "name": "GPT-5",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-13"
    },
    "zenmux/openai/gpt-5.2": {
      "id": "openai/gpt-5.2",
      "provider": "zenmux",
      "name": "GPT-5.2",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.00017,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-11"
    },
    "zenmux/baidu/ernie-5.0-thinking-preview": {
      "id": "baidu/ernie-5.0-thinking-preview",
      "provider": "zenmux",
      "name": "ERNIE-5.0-Thinking-Preview",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00084,
      "output_cost_per_1k": 0.00337,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-13"
    },
    "zenmux/inclusionai/ring-1t": {
      "id": "inclusionai/ring-1t",
      "provider": "zenmux",
      "name": "Ring-1T",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00224,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-01"
    },
    "zenmux/inclusionai/ling-1t": {
      "id": "inclusionai/ling-1t",
      "provider": "zenmux",
      "name": "Ling-1T",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00224,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-01"
    },
    "zenmux/z-ai/glm-4.7": {
      "id": "z-ai/glm-4.7",
      "provider": "zenmux",
      "name": "GLM 4.7",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00114,
      "cache_read_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-23"
    },
    "zenmux/z-ai/glm-4.6v-flash-free": {
      "id": "z-ai/glm-4.6v-flash-free",
      "provider": "zenmux",
      "name": "GLM 4.6V Flash (Free)",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-30"
    },
    "zenmux/z-ai/glm-4.6v-flash": {
      "id": "z-ai/glm-4.6v-flash",
      "provider": "zenmux",
      "name": "GLM 4.6V FlashX",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-08"
    },
    "zenmux/z-ai/glm-4.5": {
      "id": "z-ai/glm-4.5",
      "provider": "zenmux",
      "name": "GLM 4.5",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00154,
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-09"
    },
    "zenmux/z-ai/glm-4.5-air": {
      "id": "z-ai/glm-4.5-air",
      "provider": "zenmux",
      "name": "GLM 4.5 Air",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00056,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-09"
    },
    "zenmux/z-ai/glm-4.6": {
      "id": "z-ai/glm-4.6",
      "provider": "zenmux",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.00154,
      "cache_read_cost_per_1k": 7e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "zenmux/z-ai/glm-4.6v": {
      "id": "z-ai/glm-4.6v",
      "provider": "zenmux",
      "name": "GLM 4.6V",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-08"
    },
    "zenmux/qwen/qwen3-coder-plus": {
      "id": "qwen/qwen3-coder-plus",
      "provider": "zenmux",
      "name": "Qwen3-Coder-Plus",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-09-10"
    },
    "zenmux/kuaishou/kat-coder-pro-v1-free": {
      "id": "kuaishou/kat-coder-pro-v1-free",
      "provider": "zenmux",
      "name": "KAT-Coder-Pro-V1 Free",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-12-31"
    },
    "zenmux/kuaishou/kat-coder-pro-v1": {
      "id": "kuaishou/kat-coder-pro-v1",
      "provider": "zenmux",
      "name": "KAT-Coder-Pro-V1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-10-24"
    },
    "zenmux/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "provider": "zenmux",
      "name": "Claude Opus 4",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-14"
    },
    "zenmux/anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "provider": "zenmux",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "zenmux/anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "provider": "zenmux",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "zenmux/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "zenmux",
      "name": "Claude Sonnet 4",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-08-13"
    },
    "zenmux/anthropic/claude-opus-4.5": {
      "id": "anthropic/claude-opus-4.5",
      "provider": "zenmux",
      "name": "Claude Opus 4.5",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-01",
      "release_date": "2025-11-25"
    },
    "zenmux/anthropic/claude-sonnet-4.5": {
      "id": "anthropic/claude-sonnet-4.5",
      "provider": "zenmux",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "ovhcloud/mixtral-8x7b-instruct-v0.1": {
      "id": "mixtral-8x7b-instruct-v0.1",
      "provider": "ovhcloud",
      "name": "Mixtral-8x7B-Instruct-v0.1",
      "family": "mixtral-8x7b",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "ovhcloud/mistral-7b-instruct-v0.3": {
      "id": "mistral-7b-instruct-v0.3",
      "provider": "ovhcloud",
      "name": "Mistral-7B-Instruct-v0.3",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "ovhcloud/llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "provider": "ovhcloud",
      "name": "Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-06-11",
      "open_weights": true
    },
    "ovhcloud/qwen2.5-vl-72b-instruct": {
      "id": "qwen2.5-vl-72b-instruct",
      "provider": "ovhcloud",
      "name": "Qwen2.5-VL-72B-Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00101,
      "output_cost_per_1k": 0.00101,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-03-31",
      "open_weights": true
    },
    "ovhcloud/mistral-nemo-instruct-2407": {
      "id": "mistral-nemo-instruct-2407",
      "provider": "ovhcloud",
      "name": "Mistral-Nemo-Instruct-2407",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 118000,
      "max_output_tokens": 118000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-11-20",
      "open_weights": true
    },
    "ovhcloud/mistral-small-3.2-24b-instruct-2506": {
      "id": "mistral-small-3.2-24b-instruct-2506",
      "provider": "ovhcloud",
      "name": "Mistral-Small-3.2-24B-Instruct-2506",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00031,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-16",
      "open_weights": true
    },
    "ovhcloud/qwen2.5-coder-32b-instruct": {
      "id": "qwen2.5-coder-32b-instruct",
      "provider": "ovhcloud",
      "name": "Qwen2.5-Coder-32B-Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00096,
      "output_cost_per_1k": 0.00096,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "ovhcloud/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen3-coder-30b-a3b-instruct",
      "provider": "ovhcloud",
      "name": "Qwen3-Coder-30B-A3B-Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00026,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-10-28",
      "open_weights": true
    },
    "ovhcloud/llava-next-mistral-7b": {
      "id": "llava-next-mistral-7b",
      "provider": "ovhcloud",
      "name": "llava-next-mistral-7b",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00032,
      "output_cost_per_1k": 0.00032,
      "capabilities": [
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-01-08",
      "open_weights": true
    },
    "ovhcloud/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "ovhcloud",
      "name": "DeepSeek-R1-Distill-Llama-70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00074,
      "output_cost_per_1k": 0.00074,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-01-30",
      "open_weights": true
    },
    "ovhcloud/meta-llama-3_1-70b-instruct": {
      "id": "meta-llama-3_1-70b-instruct",
      "provider": "ovhcloud",
      "name": "Meta-Llama-3_1-70B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00074,
      "output_cost_per_1k": 0.00074,
      "capabilities": [
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "ovhcloud/gpt-oss-20b": {
      "id": "gpt-oss-20b",
      "provider": "ovhcloud",
      "name": "gpt-oss-20b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00018,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "release_date": "2025-08-28",
      "open_weights": true
    },
    "ovhcloud/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "ovhcloud",
      "name": "gpt-oss-120b",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00047,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning"
      ],
      "release_date": "2025-08-28",
      "open_weights": true
    },
    "ovhcloud/meta-llama-3_3-70b-instruct": {
      "id": "meta-llama-3_3-70b-instruct",
      "provider": "ovhcloud",
      "name": "Meta-Llama-3_3-70B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00074,
      "output_cost_per_1k": 0.00074,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "ovhcloud/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "ovhcloud",
      "name": "Qwen3-32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-16",
      "open_weights": true
    },
    "v0/v0-1.5-lg": {
      "id": "v0-1.5-lg",
      "provider": "v0",
      "name": "v0-1.5-lg",
      "family": "v0",
      "mode": "chat",
      "max_input_tokens": 512000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-06-09"
    },
    "v0/v0-1.5-md": {
      "id": "v0-1.5-md",
      "provider": "v0",
      "name": "v0-1.5-md",
      "family": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-06-09"
    },
    "v0/v0-1.0-md": {
      "id": "v0-1.0-md",
      "provider": "v0",
      "name": "v0-1.0-md",
      "family": "v0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-05-22"
    },
    "iflowcn/qwen3-coder": {
      "id": "qwen3-coder",
      "provider": "iflowcn",
      "name": "Qwen3-Coder-480B-A35B",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "iflowcn/deepseek-v3": {
      "id": "deepseek-v3",
      "provider": "iflowcn",
      "name": "DeepSeek-V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-26",
      "open_weights": true
    },
    "iflowcn/kimi-k2": {
      "id": "kimi-k2",
      "provider": "iflowcn",
      "name": "Kimi-K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01"
    },
    "iflowcn/deepseek-r1": {
      "id": "deepseek-r1",
      "provider": "iflowcn",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "iflowcn/deepseek-v3.1": {
      "id": "deepseek-v3.1",
      "provider": "iflowcn",
      "name": "DeepSeek-V3.1-Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "iflowcn/minimax-m2": {
      "id": "minimax-m2",
      "provider": "iflowcn",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131100,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-11-13",
      "open_weights": true
    },
    "iflowcn/qwen3-235b": {
      "id": "qwen3-235b",
      "provider": "iflowcn",
      "name": "Qwen3-235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01",
      "open_weights": true
    },
    "iflowcn/deepseek-v3.2-chat": {
      "id": "deepseek-v3.2-chat",
      "provider": "iflowcn",
      "name": "DeepSeek-V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "iflowcn/kimi-k2-0905": {
      "id": "kimi-k2-0905",
      "provider": "iflowcn",
      "name": "Kimi-K2-0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-09-05"
    },
    "iflowcn/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "iflowcn",
      "name": "Kimi-K2-Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "iflowcn/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen3-235b-a22b-thinking-2507",
      "provider": "iflowcn",
      "name": "Qwen3-235B-A22B-Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "iflowcn/qwen3-vl-plus": {
      "id": "qwen3-vl-plus",
      "provider": "iflowcn",
      "name": "Qwen3-VL-Plus",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01"
    },
    "iflowcn/glm-4.6": {
      "id": "glm-4.6",
      "provider": "iflowcn",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01"
    },
    "iflowcn/tstars2.0": {
      "id": "tstars2.0",
      "provider": "iflowcn",
      "name": "TStars-2.0",
      "family": "tstars2.0",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2024-01-01"
    },
    "iflowcn/qwen3-235b-a22b-instruct": {
      "id": "qwen3-235b-a22b-instruct",
      "provider": "iflowcn",
      "name": "Qwen3-235B-A22B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "iflowcn/qwen3-max": {
      "id": "qwen3-max",
      "provider": "iflowcn",
      "name": "Qwen3-Max",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01"
    },
    "iflowcn/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "iflowcn",
      "name": "DeepSeek-V3.2-Exp",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "iflowcn/qwen3-max-preview": {
      "id": "qwen3-max-preview",
      "provider": "iflowcn",
      "name": "Qwen3-Max-Preview",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01"
    },
    "iflowcn/qwen3-coder-plus": {
      "id": "qwen3-coder-plus",
      "provider": "iflowcn",
      "name": "Qwen3-Coder-Plus",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "iflowcn/qwen3-32b": {
      "id": "qwen3-32b",
      "provider": "iflowcn",
      "name": "Qwen3-32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01",
      "open_weights": true
    },
    "synthetic/hf:Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "hf:Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "synthetic",
      "name": "Qwen 3 235B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "synthetic/hf:Qwen/Qwen2.5-Coder-32B-Instruct": {
      "id": "hf:Qwen/Qwen2.5-Coder-32B-Instruct",
      "provider": "synthetic",
      "name": "Qwen2.5-Coder-32B-Instruct",
      "family": "qwen2.5-coder",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-11",
      "open_weights": true
    },
    "synthetic/hf:Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "hf:Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "synthetic",
      "name": "Qwen 3 Coder 480B",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "synthetic/hf:Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "hf:Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "synthetic",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00065,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "synthetic/hf:MiniMaxAI/MiniMax-M2": {
      "id": "hf:MiniMaxAI/MiniMax-M2",
      "provider": "synthetic",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "synthetic/hf:MiniMaxAI/MiniMax-M2.1": {
      "id": "hf:MiniMaxAI/MiniMax-M2.1",
      "provider": "synthetic",
      "name": "MiniMax-M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-3.1-70B-Instruct": {
      "id": "hf:meta-llama/Llama-3.1-70B-Instruct",
      "provider": "synthetic",
      "name": "Llama-3.1-70B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-3.1-8B-Instruct": {
      "id": "hf:meta-llama/Llama-3.1-8B-Instruct",
      "provider": "synthetic",
      "name": "Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-3.3-70B-Instruct": {
      "id": "hf:meta-llama/Llama-3.3-70B-Instruct",
      "provider": "synthetic",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "hf:meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "synthetic",
      "name": "Llama-4-Scout-17B-16E-Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 328000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "hf:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "synthetic",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 524000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "synthetic/hf:meta-llama/Llama-3.1-405B-Instruct": {
      "id": "hf:meta-llama/Llama-3.1-405B-Instruct",
      "provider": "synthetic",
      "name": "Llama-3.1-405B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "synthetic/hf:moonshotai/Kimi-K2-Instruct-0905": {
      "id": "hf:moonshotai/Kimi-K2-Instruct-0905",
      "provider": "synthetic",
      "name": "Kimi K2 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "synthetic/hf:moonshotai/Kimi-K2-Thinking": {
      "id": "hf:moonshotai/Kimi-K2-Thinking",
      "provider": "synthetic",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-07",
      "open_weights": true
    },
    "synthetic/hf:zai-org/GLM-4.5": {
      "id": "hf:zai-org/GLM-4.5",
      "provider": "synthetic",
      "name": "GLM 4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 96000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "synthetic/hf:zai-org/GLM-4.7": {
      "id": "hf:zai-org/GLM-4.7",
      "provider": "synthetic",
      "name": "GLM 4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "synthetic/hf:zai-org/GLM-4.6": {
      "id": "hf:zai-org/GLM-4.6",
      "provider": "synthetic",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "synthetic/hf:deepseek-ai/DeepSeek-R1": {
      "id": "hf:deepseek-ai/DeepSeek-R1",
      "provider": "synthetic",
      "name": "DeepSeek R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "synthetic/hf:deepseek-ai/DeepSeek-R1-0528": {
      "id": "hf:deepseek-ai/DeepSeek-R1-0528",
      "provider": "synthetic",
      "name": "DeepSeek R1 (0528)",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-01"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.1-Terminus": {
      "id": "hf:deepseek-ai/DeepSeek-V3.1-Terminus",
      "provider": "synthetic",
      "name": "DeepSeek V3.1 Terminus",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-09-22"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.2": {
      "id": "hf:deepseek-ai/DeepSeek-V3.2",
      "provider": "synthetic",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 162816,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 0.00027,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3": {
      "id": "hf:deepseek-ai/DeepSeek-V3",
      "provider": "synthetic",
      "name": "DeepSeek V3",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3.1": {
      "id": "hf:deepseek-ai/DeepSeek-V3.1",
      "provider": "synthetic",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-21"
    },
    "synthetic/hf:deepseek-ai/DeepSeek-V3-0324": {
      "id": "hf:deepseek-ai/DeepSeek-V3-0324",
      "provider": "synthetic",
      "name": "DeepSeek V3 (0324)",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0012,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-08-01"
    },
    "synthetic/hf:openai/gpt-oss-120b": {
      "id": "hf:openai/gpt-oss-120b",
      "provider": "synthetic",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "deepinfra/moonshotai/Kimi-K2-Instruct": {
      "id": "moonshotai/Kimi-K2-Instruct",
      "provider": "deepinfra",
      "name": "Kimi K2",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "deepinfra/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "deepinfra",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00047,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "deepinfra/MiniMaxAI/MiniMax-M2": {
      "id": "MiniMaxAI/MiniMax-M2",
      "provider": "deepinfra",
      "name": "MiniMax M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.000254,
      "output_cost_per_1k": 0.00102,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-11-13",
      "open_weights": true
    },
    "deepinfra/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "deepinfra",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00014,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "deepinfra/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "deepinfra",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00024,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
      "provider": "deepinfra",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
      "provider": "deepinfra",
      "name": "Qwen3 Coder 480B A35B Instruct Turbo",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 66536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "deepinfra/zai-org/GLM-4.5": {
      "id": "zai-org/GLM-4.5",
      "provider": "deepinfra",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true,
      "deprecated": true
    },
    "deepinfra/zai-org/GLM-4.7": {
      "id": "zai-org/GLM-4.7",
      "provider": "deepinfra",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00043,
      "output_cost_per_1k": 0.00175,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "zhipuai/glm-4.6v-flash": {
      "id": "glm-4.6v-flash",
      "provider": "zhipuai",
      "name": "GLM-4.6V-Flash",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "zhipuai/glm-4.6v": {
      "id": "glm-4.6v",
      "provider": "zhipuai",
      "name": "GLM-4.6V",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "zhipuai/glm-4.6": {
      "id": "glm-4.6",
      "provider": "zhipuai",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "zhipuai/glm-4.5v": {
      "id": "glm-4.5v",
      "provider": "zhipuai",
      "name": "GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "zhipuai/glm-4.5-air": {
      "id": "glm-4.5-air",
      "provider": "zhipuai",
      "name": "GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai/glm-4.5": {
      "id": "glm-4.5",
      "provider": "zhipuai",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai/glm-4.5-flash": {
      "id": "glm-4.5-flash",
      "provider": "zhipuai",
      "name": "GLM-4.5-Flash",
      "family": "glm-4.5-flash",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zhipuai/glm-4.7": {
      "id": "glm-4.7",
      "provider": "zhipuai",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "submodel/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "submodel",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-23",
      "open_weights": true
    },
    "submodel/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "submodel",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-08-23",
      "open_weights": true
    },
    "submodel/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8": {
      "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
      "provider": "submodel",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-08-23"
    },
    "submodel/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "submodel",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-23",
      "open_weights": true
    },
    "submodel/zai-org/GLM-4.5-FP8": {
      "id": "zai-org/GLM-4.5-FP8",
      "provider": "submodel",
      "name": "GLM 4.5 FP8",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "submodel/zai-org/GLM-4.5-Air": {
      "id": "zai-org/GLM-4.5-Air",
      "provider": "submodel",
      "name": "GLM 4.5 Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "submodel/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "provider": "submodel",
      "name": "DeepSeek R1 0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.00215,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-23"
    },
    "submodel/deepseek-ai/DeepSeek-V3.1": {
      "id": "deepseek-ai/DeepSeek-V3.1",
      "provider": "submodel",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-23"
    },
    "submodel/deepseek-ai/DeepSeek-V3-0324": {
      "id": "deepseek-ai/DeepSeek-V3-0324",
      "provider": "submodel",
      "name": "DeepSeek V3 0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 75000,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-08-23"
    },
    "nano_gpt/moonshotai/kimi-k2-thinking": {
      "id": "moonshotai/kimi-k2-thinking",
      "provider": "nano_gpt",
      "name": "Kimi K2 Thinking",
      "family": "kimi",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-11-01"
    },
    "nano_gpt/moonshotai/kimi-k2-instruct": {
      "id": "moonshotai/kimi-k2-instruct",
      "provider": "nano_gpt",
      "name": "Kimi K2 Instruct",
      "family": "kimi",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-07-18"
    },
    "nano_gpt/nousresearch/hermes-4-405b:thinking": {
      "id": "nousresearch/hermes-4-405b:thinking",
      "provider": "nano_gpt",
      "name": "Hermes 4 405b Thinking",
      "family": "hermes",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2024-08-13",
      "open_weights": true
    },
    "nano_gpt/nvidia/llama-3_3-nemotron-super-49b-v1_5": {
      "id": "nvidia/llama-3_3-nemotron-super-49b-v1_5",
      "provider": "nano_gpt",
      "name": "Llama 3 3 Nemotron Super 49B V1 5",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-08-08",
      "open_weights": true
    },
    "nano_gpt/deepseek/deepseek-v3.2:thinking": {
      "id": "deepseek/deepseek-v3.2:thinking",
      "provider": "nano_gpt",
      "name": "Deepseek V3.2 Thinking",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "nano_gpt/deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "provider": "nano_gpt",
      "name": "Deepseek R1",
      "family": "deepseek",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "nano_gpt/minimax/minimax-m2.1": {
      "id": "minimax/minimax-m2.1",
      "provider": "nano_gpt",
      "name": "Minimax M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-23"
    },
    "nano_gpt/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "nano_gpt",
      "name": "GPT Oss 120b",
      "family": "gpt",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-06-23"
    },
    "nano_gpt/z-ai/glm-4.6:thinking": {
      "id": "z-ai/glm-4.6:thinking",
      "provider": "nano_gpt",
      "name": "GLM 4.6 Thinking",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-07",
      "open_weights": true
    },
    "nano_gpt/z-ai/glm-4.6": {
      "id": "z-ai/glm-4.6",
      "provider": "nano_gpt",
      "name": "GLM 4.6",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-15",
      "open_weights": true
    },
    "nano_gpt/qwen/qwen3-coder": {
      "id": "qwen/qwen3-coder",
      "provider": "nano_gpt",
      "name": "Qwen3 Coder",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 106000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-15",
      "open_weights": true
    },
    "nano_gpt/qwen/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "provider": "nano_gpt",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "nano_gpt/mistralai/devstral-2-123b-instruct-2512": {
      "id": "mistralai/devstral-2-123b-instruct-2512",
      "provider": "nano_gpt",
      "name": "Devstral 2 123b Instruct 2512",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-12-11",
      "open_weights": true
    },
    "nano_gpt/mistralai/mistral-large-3-675b-instruct-2512": {
      "id": "mistralai/mistral-large-3-675b-instruct-2512",
      "provider": "nano_gpt",
      "name": "Mistral Large 3 675b Instruct 2512",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-02",
      "open_weights": true
    },
    "nano_gpt/mistralai/ministral-14b-instruct-2512": {
      "id": "mistralai/ministral-14b-instruct-2512",
      "provider": "nano_gpt",
      "name": "Ministral 14b Instruct 2512",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-12",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "nano_gpt/meta-llama/llama-4-maverick": {
      "id": "meta-llama/llama-4-maverick",
      "provider": "nano_gpt",
      "name": "Llama 4 Maverick",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "nano_gpt/meta-llama/llama-3.3-70b-instruct": {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "provider": "nano_gpt",
      "name": "Llama 3.3 70b Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "nano_gpt/zai-org/glm-4.7": {
      "id": "zai-org/glm-4.7",
      "provider": "nano_gpt",
      "name": "GLM 4.7",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "nano_gpt/zai-org/glm-4.5-air": {
      "id": "zai-org/glm-4.5-air",
      "provider": "nano_gpt",
      "name": "GLM 4.5 Air",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "nano_gpt/zai-org/glm-4.7:thinking": {
      "id": "zai-org/glm-4.7:thinking",
      "provider": "nano_gpt",
      "name": "GLM 4.7 Thinking",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-07",
      "open_weights": true
    },
    "nano_gpt/zai-org/glm-4.5-air:thinking": {
      "id": "zai-org/glm-4.5-air:thinking",
      "provider": "nano_gpt",
      "name": "GLM 4.5 Air Thinking",
      "family": "glm",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-04-07",
      "open_weights": true
    },
    "zai/glm-4.7": {
      "id": "glm-4.7",
      "provider": "zai",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "zai/glm-4.5-flash": {
      "id": "glm-4.5-flash",
      "provider": "zai",
      "name": "GLM-4.5-Flash",
      "family": "glm-4.5-flash",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai/glm-4.5": {
      "id": "glm-4.5",
      "provider": "zai",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai/glm-4.5-air": {
      "id": "glm-4.5-air",
      "provider": "zai",
      "name": "GLM-4.5-Air",
      "family": "glm-4.5-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0011,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "zai/glm-4.5v": {
      "id": "glm-4.5v",
      "provider": "zai",
      "name": "GLM-4.5V",
      "family": "glm-4.5v",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-11",
      "open_weights": true
    },
    "zai/glm-4.6": {
      "id": "glm-4.6",
      "provider": "zai",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "zai/glm-4.6v": {
      "id": "glm-4.6v",
      "provider": "zai",
      "name": "GLM-4.6V",
      "family": "glm-4.6v",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-08",
      "open_weights": true
    },
    "inference/mistral/mistral-nemo-12b-instruct": {
      "id": "mistral/mistral-nemo-12b-instruct",
      "provider": "inference",
      "name": "Mistral Nemo 12B Instruct",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3.8e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/google/gemma-3": {
      "id": "google/gemma-3",
      "provider": "inference",
      "name": "Google Gemma 3",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 125000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/osmosis/osmosis-structure-0.6b": {
      "id": "osmosis/osmosis-structure-0.6b",
      "provider": "inference",
      "name": "Osmosis Structure 0.6B",
      "family": "osmosis-structure-0.6b",
      "mode": "chat",
      "max_input_tokens": 4000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/qwen/qwen3-embedding-4b": {
      "id": "qwen/qwen3-embedding-4b",
      "provider": "inference",
      "name": "Qwen 3 Embedding 4B",
      "family": "qwen3",
      "mode": "embedding",
      "max_input_tokens": 32000,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 0.0,
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/qwen/qwen-2.5-7b-vision-instruct": {
      "id": "qwen/qwen-2.5-7b-vision-instruct",
      "provider": "inference",
      "name": "Qwen 2.5 7B Vision Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 125000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/meta/llama-3.2-11b-vision-instruct": {
      "id": "meta/llama-3.2-11b-vision-instruct",
      "provider": "inference",
      "name": "Llama 3.2 11B Vision Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5.5e-05,
      "output_cost_per_1k": 5.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/meta/llama-3.1-8b-instruct": {
      "id": "meta/llama-3.1-8b-instruct",
      "provider": "inference",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 2.5e-05,
      "output_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/meta/llama-3.2-3b-instruct": {
      "id": "meta/llama-3.2-3b-instruct",
      "provider": "inference",
      "name": "Llama 3.2 3B Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "inference/meta/llama-3.2-1b-instruct": {
      "id": "meta/llama-3.2-1b-instruct",
      "provider": "inference",
      "name": "Llama 3.2 1B Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 1e-05,
      "output_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "requesty/xai/grok-4": {
      "id": "xai/grok-4",
      "provider": "requesty",
      "name": "Grok 4",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "cache_write_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-09"
    },
    "requesty/xai/grok-4-fast": {
      "id": "xai/grok-4-fast",
      "provider": "requesty",
      "name": "Grok 4 Fast",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-09-19"
    },
    "requesty/google/gemini-3-flash-preview": {
      "id": "google/gemini-3-flash-preview",
      "provider": "requesty",
      "name": "Gemini 3 Flash",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.003,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-12-17"
    },
    "requesty/google/gemini-3-pro-preview": {
      "id": "google/gemini-3-pro-preview",
      "provider": "requesty",
      "name": "Gemini 3 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0002,
      "cache_write_cost_per_1k": 0.0045,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-11-18"
    },
    "requesty/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "requesty",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.00055,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "requesty/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "requesty",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "cache_write_cost_per_1k": 0.002375,
      "capabilities": [
        "audio_input",
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-17"
    },
    "requesty/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "provider": "requesty",
      "name": "GPT-4.1 Mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "requesty/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "provider": "requesty",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "requesty/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "requesty",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "requesty/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "requesty",
      "name": "o4 Mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-04-16"
    },
    "requesty/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "provider": "requesty",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "requesty/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "requesty",
      "name": "GPT-4o Mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-07-18"
    },
    "requesty/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "requesty",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "requesty/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "provider": "requesty",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "requesty/anthropic/claude-opus-4-1": {
      "id": "anthropic/claude-opus-4-1",
      "provider": "requesty",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "requesty/anthropic/claude-haiku-4-5": {
      "id": "anthropic/claude-haiku-4-5",
      "provider": "requesty",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 62000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-01",
      "release_date": "2025-10-15"
    },
    "requesty/anthropic/claude-opus-4-5": {
      "id": "anthropic/claude-opus-4-5",
      "provider": "requesty",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "requesty/anthropic/claude-sonnet-4-5": {
      "id": "anthropic/claude-sonnet-4-5",
      "provider": "requesty",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "requesty/anthropic/claude-3-7-sonnet": {
      "id": "anthropic/claude-3-7-sonnet",
      "provider": "requesty",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-01",
      "release_date": "2025-02-19"
    },
    "requesty/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "requesty",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "morph/morph-v3-large": {
      "id": "morph-v3-large",
      "provider": "morph",
      "name": "Morph v3 Large",
      "family": "morph-v3-large",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0019,
      "release_date": "2024-08-15"
    },
    "morph/auto": {
      "id": "auto",
      "provider": "morph",
      "name": "Auto",
      "family": "auto",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.00155,
      "release_date": "2024-06-01"
    },
    "morph/morph-v3-fast": {
      "id": "morph-v3-fast",
      "provider": "morph",
      "name": "Morph v3 Fast",
      "family": "morph-v3-fast",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 16000,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0012,
      "release_date": "2024-08-15"
    },
    "lmstudio/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "lmstudio",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "lmstudio/qwen/qwen3-30b-a3b-2507": {
      "id": "qwen/qwen3-30b-a3b-2507",
      "provider": "lmstudio",
      "name": "Qwen3 30B A3B 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-30",
      "open_weights": true
    },
    "lmstudio/qwen/qwen3-coder-30b": {
      "id": "qwen/qwen3-coder-30b",
      "provider": "lmstudio",
      "name": "Qwen3 Coder 30B",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-23",
      "open_weights": true
    },
    "friendli/meta-llama-3.3-70b-instruct": {
      "id": "meta-llama-3.3-70b-instruct",
      "provider": "friendli",
      "name": "Llama 3.3 70B Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-08-01",
      "open_weights": true
    },
    "friendli/meta-llama-3.1-8b-instruct": {
      "id": "meta-llama-3.1-8b-instruct",
      "provider": "friendli",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2024-08-01",
      "open_weights": true
    },
    "friendli/LGAI-EXAONE/EXAONE-4.0.1-32B": {
      "id": "LGAI-EXAONE/EXAONE-4.0.1-32B",
      "provider": "friendli",
      "name": "EXAONE 4.0.1 32B",
      "family": "exaone",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-31",
      "open_weights": true
    },
    "friendli/meta-llama/Llama-4-Maverick-17B-128E-Instruct": {
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct",
      "provider": "friendli",
      "name": "Llama 4 Maverick 17B 128E Instruct",
      "family": "llama-4",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-16",
      "open_weights": true
    },
    "friendli/meta-llama/Llama-4-Scout-17B-16E-Instruct": {
      "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "provider": "friendli",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-16",
      "open_weights": true
    },
    "friendli/Qwen/Qwen3-30B-A3B": {
      "id": "Qwen/Qwen3-30B-A3B",
      "provider": "friendli",
      "name": "Qwen3 30B A3B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-16",
      "open_weights": true
    },
    "friendli/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "friendli",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-07-29",
      "open_weights": true
    },
    "friendli/Qwen/Qwen3-32B": {
      "id": "Qwen/Qwen3-32B",
      "provider": "friendli",
      "name": "Qwen3 32B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8000,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-06-16",
      "open_weights": true
    },
    "friendli/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "friendli",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-29",
      "open_weights": true
    },
    "friendli/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "friendli",
      "name": "GLM 4.6",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-31",
      "open_weights": true
    },
    "friendli/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "provider": "friendli",
      "name": "DeepSeek R1 0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "capabilities": [
        "json_mode",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "sap_ai_core/anthropic--claude-3.5-sonnet": {
      "id": "anthropic--claude-3.5-sonnet",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-3.5-sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-10-22"
    },
    "sap_ai_core/anthropic--claude-4.5-haiku": {
      "id": "anthropic--claude-4.5-haiku",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-4.5-haiku",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-01"
    },
    "sap_ai_core/anthropic--claude-4-opus": {
      "id": "anthropic--claude-4-opus",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-4-opus",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-31",
      "release_date": "2025-05-22"
    },
    "sap_ai_core/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "sap_ai_core",
      "name": "gemini-2.5-flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-25"
    },
    "sap_ai_core/anthropic--claude-3-haiku": {
      "id": "anthropic--claude-3-haiku",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-3-haiku",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-13"
    },
    "sap_ai_core/anthropic--claude-3-sonnet": {
      "id": "anthropic--claude-3-sonnet",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-3-sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-04"
    },
    "sap_ai_core/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "sap_ai_core",
      "name": "gpt-5-nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "sap_ai_core/anthropic--claude-3.7-sonnet": {
      "id": "anthropic--claude-3.7-sonnet",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-3.7-sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-24"
    },
    "sap_ai_core/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "sap_ai_core",
      "name": "gpt-5-mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "sap_ai_core/anthropic--claude-4.5-sonnet": {
      "id": "anthropic--claude-4.5-sonnet",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-4.5-sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-31",
      "release_date": "2025-09-29"
    },
    "sap_ai_core/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "sap_ai_core",
      "name": "gemini-2.5-pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-03-25"
    },
    "sap_ai_core/anthropic--claude-3-opus": {
      "id": "anthropic--claude-3-opus",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-3-opus",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-02-29"
    },
    "sap_ai_core/anthropic--claude-4-sonnet": {
      "id": "anthropic--claude-4-sonnet",
      "provider": "sap_ai_core",
      "name": "anthropic--claude-4-sonnet",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01-31",
      "release_date": "2025-05-22"
    },
    "sap_ai_core/gpt-5": {
      "id": "gpt-5",
      "provider": "sap_ai_core",
      "name": "gpt-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "anthropic/claude-opus-4-0": {
      "id": "claude-opus-4-0",
      "provider": "anthropic",
      "name": "Claude Opus 4 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-3-5-sonnet-20241022": {
      "id": "claude-3-5-sonnet-20241022",
      "provider": "anthropic",
      "name": "Claude Sonnet 3.5 v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "anthropic",
      "name": "Claude Opus 4.1 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "anthropic/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "provider": "anthropic",
      "name": "Claude Haiku 4.5 (latest)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "anthropic/claude-3-5-sonnet-20240620": {
      "id": "claude-3-5-sonnet-20240620",
      "provider": "anthropic",
      "name": "Claude Sonnet 3.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04-30",
      "release_date": "2024-06-20"
    },
    "anthropic/claude-3-5-haiku-latest": {
      "id": "claude-3-5-haiku-latest",
      "provider": "anthropic",
      "name": "Claude Haiku 3.5 (latest)",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "provider": "anthropic",
      "name": "Claude Opus 4.5 (latest)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "anthropic/claude-3-opus-20240229": {
      "id": "claude-3-opus-20240229",
      "provider": "anthropic",
      "name": "Claude Opus 3",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-02-29"
    },
    "anthropic/claude-opus-4-5-20251101": {
      "id": "claude-opus-4-5-20251101",
      "provider": "anthropic",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-01"
    },
    "anthropic/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "provider": "anthropic",
      "name": "Claude Sonnet 4.5 (latest)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "anthropic/claude-sonnet-4-5-20250929": {
      "id": "claude-sonnet-4-5-20250929",
      "provider": "anthropic",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "anthropic/claude-sonnet-4-20250514": {
      "id": "claude-sonnet-4-20250514",
      "provider": "anthropic",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-opus-4-20250514": {
      "id": "claude-opus-4-20250514",
      "provider": "anthropic",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-3-5-haiku-20241022": {
      "id": "claude-3-5-haiku-20241022",
      "provider": "anthropic",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07-31",
      "release_date": "2024-10-22"
    },
    "anthropic/claude-3-haiku-20240307": {
      "id": "claude-3-haiku-20240307",
      "provider": "anthropic",
      "name": "Claude Haiku 3",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "cache_read_cost_per_1k": 3e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-13"
    },
    "anthropic/claude-3-7-sonnet-20250219": {
      "id": "claude-3-7-sonnet-20250219",
      "provider": "anthropic",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-19"
    },
    "anthropic/claude-3-7-sonnet-latest": {
      "id": "claude-3-7-sonnet-latest",
      "provider": "anthropic",
      "name": "Claude Sonnet 3.7 (latest)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-31",
      "release_date": "2025-02-19"
    },
    "anthropic/claude-sonnet-4-0": {
      "id": "claude-sonnet-4-0",
      "provider": "anthropic",
      "name": "Claude Sonnet 4 (latest)",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-05-22"
    },
    "anthropic/claude-opus-4-1-20250805": {
      "id": "claude-opus-4-1-20250805",
      "provider": "anthropic",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "anthropic/claude-3-sonnet-20240229": {
      "id": "claude-3-sonnet-20240229",
      "provider": "anthropic",
      "name": "Claude Sonnet 3",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08-31",
      "release_date": "2024-03-04"
    },
    "anthropic/claude-haiku-4-5-20251001": {
      "id": "claude-haiku-4-5-20251001",
      "provider": "anthropic",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "aihubmix/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "aihubmix",
      "name": "GPT-4.1 nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "aihubmix/glm-4.7": {
      "id": "glm-4.7",
      "provider": "aihubmix",
      "name": "GLM-4.7",
      "family": "glm-4.7",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00027,
      "output_cost_per_1k": 0.0011,
      "cache_read_cost_per_1k": 0.000548,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "aihubmix/qwen3-235b-a22b-instruct-2507": {
      "id": "qwen3-235b-a22b-instruct-2507",
      "provider": "aihubmix",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00112,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-30",
      "open_weights": true
    },
    "aihubmix/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "aihubmix",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.0825,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "aihubmix/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "aihubmix",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-15"
    },
    "aihubmix/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "provider": "aihubmix",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0055,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "aihubmix/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "provider": "aihubmix",
      "name": "Claude Opus 4.5",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0005,
      "cache_write_cost_per_1k": 0.00625,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03",
      "release_date": "2025-11-25"
    },
    "aihubmix/gemini-3-pro-preview": {
      "id": "gemini-3-pro-preview",
      "provider": "aihubmix",
      "name": "Gemini 3 Pro Preview",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.012,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-19"
    },
    "aihubmix/gemini-2.5-flash": {
      "id": "gemini-2.5-flash",
      "provider": "aihubmix",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 65000,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "aihubmix",
      "name": "GPT-4.1 mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "aihubmix/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "provider": "aihubmix",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0033,
      "output_cost_per_1k": 0.0165,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "aihubmix/coding-glm-4.7-free": {
      "id": "coding-glm-4.7-free",
      "provider": "aihubmix",
      "name": "Coding GLM-4.7 Free",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "aihubmix/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "aihubmix",
      "name": "GPT-5.1 Codex Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-15"
    },
    "aihubmix/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen3-235b-a22b-thinking-2507",
      "provider": "aihubmix",
      "name": "Qwen3 235B A22B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.0028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-30",
      "open_weights": true
    },
    "aihubmix/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "aihubmix",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-11",
      "release_date": "2025-11-15"
    },
    "aihubmix/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "aihubmix",
      "name": "GPT-5-Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "aihubmix",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-4o": {
      "id": "gpt-4o",
      "provider": "aihubmix",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "aihubmix/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "aihubmix",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-04-14"
    },
    "aihubmix/o4-mini": {
      "id": "o4-mini",
      "provider": "aihubmix",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "reasoning"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "aihubmix",
      "name": "GPT-5-Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "aihubmix/gemini-2.5-pro": {
      "id": "gemini-2.5-pro",
      "provider": "aihubmix",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 65000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.00031,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-4o-2024-11-20": {
      "id": "gpt-4o-2024-11-20",
      "provider": "aihubmix",
      "name": "GPT-4o (2024-11-20)",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-11-20"
    },
    "aihubmix/gpt-5.1-codex-max": {
      "id": "gpt-5.1-codex-max",
      "provider": "aihubmix",
      "name": "GPT-5.1-Codex-Max",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-13"
    },
    "aihubmix/minimax-m2.1-free": {
      "id": "minimax-m2.1-free",
      "provider": "aihubmix",
      "name": "MiniMax M2.1 Free",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "aihubmix/qwen3-coder-480b-a35b-instruct": {
      "id": "qwen3-coder-480b-a35b-instruct",
      "provider": "aihubmix",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131000,
      "input_cost_per_1k": 0.00082,
      "output_cost_per_1k": 0.00329,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-08-01"
    },
    "aihubmix/deepseek-v3.2-think": {
      "id": "deepseek-v3.2-think",
      "provider": "aihubmix",
      "name": "DeepSeek-V3.2-Think",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "aihubmix/gpt-5": {
      "id": "gpt-5",
      "provider": "aihubmix",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.02,
      "cache_read_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "aihubmix/minimax-m2.1": {
      "id": "minimax-m2.1",
      "provider": "aihubmix",
      "name": "MiniMax M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204800,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00029,
      "output_cost_per_1k": 0.00115,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "aihubmix/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "aihubmix",
      "name": "DeepSeek-V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "aihubmix/Kimi-K2-0905": {
      "id": "Kimi-K2-0905",
      "provider": "aihubmix",
      "name": "Kimi K2 0905",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-09-05",
      "open_weights": true
    },
    "aihubmix/gpt-5-pro": {
      "id": "gpt-5-pro",
      "provider": "aihubmix",
      "name": "GPT-5-Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.007,
      "output_cost_per_1k": 0.028,
      "cache_read_cost_per_1k": 0.0035,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "aihubmix/gpt-5.2": {
      "id": "gpt-5.2",
      "provider": "aihubmix",
      "name": "GPT-5.2",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "fireworks/accounts/fireworks/models/deepseek-r1-0528": {
      "id": "accounts/fireworks/models/deepseek-r1-0528",
      "provider": "fireworks",
      "name": "Deepseek R1 05/28",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p1": {
      "id": "accounts/fireworks/models/deepseek-v3p1",
      "provider": "fireworks",
      "name": "DeepSeek V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/deepseek-v3p2": {
      "id": "accounts/fireworks/models/deepseek-v3p2",
      "provider": "fireworks",
      "name": "DeepSeek V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 160000,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-09",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/minimax-m2": {
      "id": "accounts/fireworks/models/minimax-m2",
      "provider": "fireworks",
      "name": "MiniMax-M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 192000,
      "max_output_tokens": 192000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/minimax-m2p1": {
      "id": "accounts/fireworks/models/minimax-m2p1",
      "provider": "fireworks",
      "name": "MiniMax-M2.1",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 200000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-23",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/glm-4p7": {
      "id": "accounts/fireworks/models/glm-4p7",
      "provider": "fireworks",
      "name": "GLM 4.7",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 198000,
      "max_output_tokens": 198000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0022,
      "cache_read_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-12-22",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/deepseek-v3-0324": {
      "id": "accounts/fireworks/models/deepseek-v3-0324",
      "provider": "fireworks",
      "name": "Deepseek V3 03-24",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 160000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/glm-4p6": {
      "id": "accounts/fireworks/models/glm-4p6",
      "provider": "fireworks",
      "name": "GLM 4.6",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 198000,
      "max_output_tokens": 198000,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-10-01",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/kimi-k2-thinking": {
      "id": "accounts/fireworks/models/kimi-k2-thinking",
      "provider": "fireworks",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/kimi-k2-instruct": {
      "id": "accounts/fireworks/models/kimi-k2-instruct",
      "provider": "fireworks",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2025-07-11",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/qwen3-235b-a22b": {
      "id": "accounts/fireworks/models/qwen3-235b-a22b",
      "provider": "fireworks",
      "name": "Qwen3 235B-A22B",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-29",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/gpt-oss-20b": {
      "id": "accounts/fireworks/models/gpt-oss-20b",
      "provider": "fireworks",
      "name": "GPT OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/gpt-oss-120b": {
      "id": "accounts/fireworks/models/gpt-oss-120b",
      "provider": "fireworks",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/glm-4p5-air": {
      "id": "accounts/fireworks/models/glm-4p5-air",
      "provider": "fireworks",
      "name": "GLM 4.5 Air",
      "family": "glm-4-air",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-08-01",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/qwen3-coder-480b-a35b-instruct": {
      "id": "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
      "provider": "fireworks",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-07-22",
      "open_weights": true
    },
    "fireworks/accounts/fireworks/models/glm-4p5": {
      "id": "accounts/fireworks/models/glm-4p5",
      "provider": "fireworks",
      "name": "GLM 4.5",
      "family": "glm-4",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00219,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-29",
      "open_weights": true
    },
    "io_net/moonshotai/Kimi-K2-Instruct-0905": {
      "id": "moonshotai/Kimi-K2-Instruct-0905",
      "provider": "io_net",
      "name": "Kimi K2 Instruct",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00039,
      "output_cost_per_1k": 0.0019,
      "cache_read_cost_per_1k": 0.000195,
      "cache_write_cost_per_1k": 0.00078,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-09-05"
    },
    "io_net/moonshotai/Kimi-K2-Thinking": {
      "id": "moonshotai/Kimi-K2-Thinking",
      "provider": "io_net",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00055,
      "output_cost_per_1k": 0.00225,
      "cache_read_cost_per_1k": 0.000275,
      "cache_write_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-11-01"
    },
    "io_net/openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "provider": "io_net",
      "name": "GPT-OSS 20B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 64000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3e-05,
      "output_cost_per_1k": 0.00014,
      "cache_read_cost_per_1k": 1.5e-05,
      "cache_write_cost_per_1k": 6e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01",
      "open_weights": true
    },
    "io_net/openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "provider": "io_net",
      "name": "GPT-OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 2e-05,
      "cache_write_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-01",
      "open_weights": true
    },
    "io_net/mistralai/Devstral-Small-2505": {
      "id": "mistralai/Devstral-Small-2505",
      "provider": "io_net",
      "name": "Devstral Small 2505",
      "family": "devstral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-05-01"
    },
    "io_net/mistralai/Mistral-Nemo-Instruct-2407": {
      "id": "mistralai/Mistral-Nemo-Instruct-2407",
      "provider": "io_net",
      "name": "Mistral Nemo Instruct 2407",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 4e-05,
      "cache_read_cost_per_1k": 1e-05,
      "cache_write_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-07-01",
      "open_weights": true
    },
    "io_net/mistralai/Magistral-Small-2506": {
      "id": "mistralai/Magistral-Small-2506",
      "provider": "io_net",
      "name": "Magistral Small 2506",
      "family": "magistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 0.00025,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-06-01"
    },
    "io_net/mistralai/Mistral-Large-Instruct-2411": {
      "id": "mistralai/Mistral-Large-Instruct-2411",
      "provider": "io_net",
      "name": "Mistral Large Instruct 2411",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.001,
      "cache_write_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-01"
    },
    "io_net/meta-llama/Llama-3.3-70B-Instruct": {
      "id": "meta-llama/Llama-3.3-70B-Instruct",
      "provider": "io_net",
      "name": "Llama 3.3 70B Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00038,
      "cache_read_cost_per_1k": 6.5e-05,
      "cache_write_cost_per_1k": 0.00026,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "io_net/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8": {
      "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
      "provider": "io_net",
      "name": "Llama 4 Maverick 17B 128E Instruct",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 430000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 7.5e-05,
      "cache_write_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-15",
      "open_weights": true
    },
    "io_net/meta-llama/Llama-3.2-90B-Vision-Instruct": {
      "id": "meta-llama/Llama-3.2-90B-Vision-Instruct",
      "provider": "io_net",
      "name": "Llama 3.2 90B Vision Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 16000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00035,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 0.000175,
      "cache_write_cost_per_1k": 0.0007,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "io_net/Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar": {
      "id": "Intel/Qwen3-Coder-480B-A35B-Instruct-int4-mixed-ar",
      "provider": "io_net",
      "name": "Qwen 3 Coder 480B",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 106000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00095,
      "cache_read_cost_per_1k": 0.00011,
      "cache_write_cost_per_1k": 0.00044,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-15",
      "open_weights": true
    },
    "io_net/Qwen/Qwen2.5-VL-32B-Instruct": {
      "id": "Qwen/Qwen2.5-VL-32B-Instruct",
      "provider": "io_net",
      "name": "Qwen 2.5 VL 32B Instruct",
      "family": "qwen2.5-vl",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.00022,
      "cache_read_cost_per_1k": 2.5e-05,
      "cache_write_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-11-01",
      "open_weights": true
    },
    "io_net/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "io_net",
      "name": "Qwen 3 235B Thinking",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 5.5e-05,
      "cache_write_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "io_net/Qwen/Qwen3-Next-80B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "provider": "io_net",
      "name": "Qwen 3 Next 80B Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0008,
      "cache_read_cost_per_1k": 5e-05,
      "cache_write_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2025-01-10",
      "open_weights": true
    },
    "io_net/zai-org/GLM-4.6": {
      "id": "zai-org/GLM-4.6",
      "provider": "io_net",
      "name": "GLM 4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.00175,
      "cache_read_cost_per_1k": 0.0002,
      "cache_write_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-11-15"
    },
    "io_net/deepseek-ai/DeepSeek-R1-0528": {
      "id": "deepseek-ai/DeepSeek-R1-0528",
      "provider": "io_net",
      "name": "DeepSeek R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.00875,
      "cache_read_cost_per_1k": 0.001,
      "cache_write_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "modelscope/ZhipuAI/GLM-4.5": {
      "id": "ZhipuAI/GLM-4.5",
      "provider": "modelscope",
      "name": "GLM-4.5",
      "family": "glm-4.5",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-28",
      "open_weights": true
    },
    "modelscope/ZhipuAI/GLM-4.6": {
      "id": "ZhipuAI/GLM-4.6",
      "provider": "modelscope",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 98304,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-30",
      "open_weights": true
    },
    "modelscope/Qwen/Qwen3-30B-A3B-Thinking-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Thinking-2507",
      "provider": "modelscope",
      "name": "Qwen3 30B A3B Thinking 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-30",
      "open_weights": true
    },
    "modelscope/Qwen/Qwen3-235B-A22B-Instruct-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
      "provider": "modelscope",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04-28",
      "open_weights": true
    },
    "modelscope/Qwen/Qwen3-Coder-30B-A3B-Instruct": {
      "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
      "provider": "modelscope",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-31",
      "open_weights": true
    },
    "modelscope/Qwen/Qwen3-30B-A3B-Instruct-2507": {
      "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
      "provider": "modelscope",
      "name": "Qwen3 30B A3B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-30",
      "open_weights": true
    },
    "modelscope/Qwen/Qwen3-235B-A22B-Thinking-2507": {
      "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
      "provider": "modelscope",
      "name": "Qwen3-235B-A22B-Thinking-2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-25",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-3.5-turbo-1106": {
      "id": "gpt-3.5-turbo-1106",
      "provider": "azure_cognitive_services",
      "name": "GPT-3.5 Turbo 1106",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/mistral-small-2503": {
      "id": "mistral-small-2503",
      "provider": "azure_cognitive_services",
      "name": "Mistral Small 3.1",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2025-03-01"
    },
    "azure_cognitive_services/codestral-2501": {
      "id": "codestral-2501",
      "provider": "azure_cognitive_services",
      "name": "Codestral 25.01",
      "family": "codestral",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2025-01-01"
    },
    "azure_cognitive_services/mistral-large-2411": {
      "id": "mistral-large-2411",
      "provider": "azure_cognitive_services",
      "name": "Mistral Large 24.11",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-09",
      "release_date": "2024-11-01"
    },
    "azure_cognitive_services/gpt-5-pro": {
      "id": "gpt-5-pro",
      "provider": "azure_cognitive_services",
      "name": "GPT-5 Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 272000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-10-06"
    },
    "azure_cognitive_services/deepseek-v3.2": {
      "id": "deepseek-v3.2",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-V3.2",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "cache_read_cost_per_1k": 2.8e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "azure_cognitive_services/mai-ds-r1": {
      "id": "mai-ds-r1",
      "provider": "azure_cognitive_services",
      "name": "MAI-DS-R1",
      "family": "mai-ds-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06",
      "release_date": "2025-01-20"
    },
    "azure_cognitive_services/gpt-5": {
      "id": "gpt-5",
      "provider": "azure_cognitive_services",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-4o-mini": {
      "id": "gpt-4o-mini",
      "provider": "azure_cognitive_services",
      "name": "GPT-4o mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "cache_read_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-07-18"
    },
    "azure_cognitive_services/phi-4-reasoning-plus": {
      "id": "phi-4-reasoning-plus",
      "provider": "azure_cognitive_services",
      "name": "Phi-4-reasoning-plus",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-4-turbo-vision": {
      "id": "gpt-4-turbo-vision",
      "provider": "azure_cognitive_services",
      "name": "GPT-4 Turbo Vision",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/phi-4-reasoning": {
      "id": "phi-4-reasoning",
      "provider": "azure_cognitive_services",
      "name": "Phi-4-reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/phi-3-medium-4k-instruct": {
      "id": "phi-3-medium-4k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-medium-instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/codex-mini": {
      "id": "codex-mini",
      "provider": "azure_cognitive_services",
      "name": "Codex Mini",
      "family": "codex",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.006,
      "cache_read_cost_per_1k": 0.000375,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-16"
    },
    "azure_cognitive_services/o3": {
      "id": "o3",
      "provider": "azure_cognitive_services",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "azure_cognitive_services/mistral-nemo": {
      "id": "mistral-nemo",
      "provider": "azure_cognitive_services",
      "name": "Mistral Nemo",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-07-18",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-3.5-turbo-instruct": {
      "id": "gpt-3.5-turbo-instruct",
      "provider": "azure_cognitive_services",
      "name": "GPT-3.5 Turbo Instruct",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-09-21"
    },
    "azure_cognitive_services/meta-llama-3.1-8b-instruct": {
      "id": "meta-llama-3.1-8b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Meta-Llama-3.1-8B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00061,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_cognitive_services/text-embedding-ada-002": {
      "id": "text-embedding-ada-002",
      "provider": "azure_cognitive_services",
      "name": "text-embedding-ada-002",
      "family": "text-embedding-ada",
      "mode": "embedding",
      "max_input_tokens": 8192,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2022-12-15"
    },
    "azure_cognitive_services/cohere-embed-v3-english": {
      "id": "cohere-embed-v3-english",
      "provider": "azure_cognitive_services",
      "name": "Embed v3 English",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2023-11-07",
      "open_weights": true
    },
    "azure_cognitive_services/llama-4-scout-17b-16e-instruct": {
      "id": "llama-4-scout-17b-16e-instruct",
      "provider": "azure_cognitive_services",
      "name": "Llama 4 Scout 17B 16E Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.00078,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "azure_cognitive_services/o1-mini": {
      "id": "o1-mini",
      "provider": "azure_cognitive_services",
      "name": "o1-mini",
      "family": "o1-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "azure_cognitive_services/gpt-5-mini": {
      "id": "gpt-5-mini",
      "provider": "azure_cognitive_services",
      "name": "GPT-5 Mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/phi-3.5-moe-instruct": {
      "id": "phi-3.5-moe-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3.5-MoE-instruct",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00064,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5.1-chat": {
      "id": "gpt-5.1-chat",
      "provider": "azure_cognitive_services",
      "name": "GPT-5.1 Chat",
      "family": "gpt-5-chat",
      "mode": "image",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/grok-3-mini": {
      "id": "grok-3-mini",
      "provider": "azure_cognitive_services",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "reasoning_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "azure_cognitive_services/o1": {
      "id": "o1",
      "provider": "azure_cognitive_services",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.06,
      "cache_read_cost_per_1k": 0.0075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-12-05"
    },
    "azure_cognitive_services/meta-llama-3-8b-instruct": {
      "id": "meta-llama-3-8b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Meta-Llama-3-8B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.00061,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "azure_cognitive_services/phi-4-multimodal": {
      "id": "phi-4-multimodal",
      "provider": "azure_cognitive_services",
      "name": "Phi-4-multimodal",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 8e-05,
      "output_cost_per_1k": 0.00032,
      "capabilities": [
        "audio_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/o4-mini": {
      "id": "o4-mini",
      "provider": "azure_cognitive_services",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00028,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-16"
    },
    "azure_cognitive_services/gpt-4.1": {
      "id": "gpt-4.1",
      "provider": "azure_cognitive_services",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "cache_read_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "azure_cognitive_services/ministral-3b": {
      "id": "ministral-3b",
      "provider": "azure_cognitive_services",
      "name": "Ministral 3B",
      "family": "ministral-3b",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-03",
      "release_date": "2024-10-22",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-3.5-turbo-0301": {
      "id": "gpt-3.5-turbo-0301",
      "provider": "azure_cognitive_services",
      "name": "GPT-3.5 Turbo 0301",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-03-01"
    },
    "azure_cognitive_services/gpt-4o": {
      "id": "gpt-4o",
      "provider": "azure_cognitive_services",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-05-13"
    },
    "azure_cognitive_services/phi-3-mini-128k-instruct": {
      "id": "phi-3-mini-128k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-mini-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/llama-3.2-90b-vision-instruct": {
      "id": "llama-3.2-90b-vision-instruct",
      "provider": "azure_cognitive_services",
      "name": "Llama-3.2-90B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00204,
      "output_cost_per_1k": 0.00204,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5-codex": {
      "id": "gpt-5-codex",
      "provider": "azure_cognitive_services",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-09-15"
    },
    "azure_cognitive_services/gpt-5-nano": {
      "id": "gpt-5-nano",
      "provider": "azure_cognitive_services",
      "name": "GPT-5 Nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 1e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-05-30",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-5.1": {
      "id": "gpt-5.1",
      "provider": "azure_cognitive_services",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "image",
      "max_input_tokens": 272000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/o3-mini": {
      "id": "o3-mini",
      "provider": "azure_cognitive_services",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.0044,
      "cache_read_cost_per_1k": 0.00055,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2024-12-20"
    },
    "azure_cognitive_services/model-router": {
      "id": "model-router",
      "provider": "azure_cognitive_services",
      "name": "Model Router",
      "family": "model-router",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-05-19"
    },
    "azure_cognitive_services/kimi-k2-thinking": {
      "id": "kimi-k2-thinking",
      "provider": "azure_cognitive_services",
      "name": "Kimi K2 Thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 262144,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "cache_read_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-11-06",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5.1-codex-mini": {
      "id": "gpt-5.1-codex-mini",
      "provider": "azure_cognitive_services",
      "name": "GPT-5.1 Codex Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.002,
      "cache_read_cost_per_1k": 2.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/llama-3.3-70b-instruct": {
      "id": "llama-3.3-70b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00071,
      "output_cost_per_1k": 0.00071,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "azure_cognitive_services/o1-preview": {
      "id": "o1-preview",
      "provider": "azure_cognitive_services",
      "name": "o1-preview",
      "family": "o1-preview",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0165,
      "output_cost_per_1k": 0.066,
      "cache_read_cost_per_1k": 0.00825,
      "capabilities": [
        "function_calling",
        "reasoning"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2024-09-12"
    },
    "azure_cognitive_services/phi-3.5-mini-instruct": {
      "id": "phi-3.5-mini-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3.5-mini-instruct",
      "family": "phi-3.5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-08-20",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-3.5-turbo-0613": {
      "id": "gpt-3.5-turbo-0613",
      "provider": "azure_cognitive_services",
      "name": "GPT-3.5 Turbo 0613",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2023-06-13"
    },
    "azure_cognitive_services/gpt-4-turbo": {
      "id": "gpt-4-turbo",
      "provider": "azure_cognitive_services",
      "name": "GPT-4 Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.01,
      "output_cost_per_1k": 0.03,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-11-06"
    },
    "azure_cognitive_services/meta-llama-3.1-70b-instruct": {
      "id": "meta-llama-3.1-70b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Meta-Llama-3.1-70B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00268,
      "output_cost_per_1k": 0.00354,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_cognitive_services/phi-3-small-8k-instruct": {
      "id": "phi-3-small-8k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-small-instruct (8k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/deepseek-v3-0324": {
      "id": "deepseek-v3-0324",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-V3-0324",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00114,
      "output_cost_per_1k": 0.00456,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-03-24",
      "open_weights": true
    },
    "azure_cognitive_services/meta-llama-3-70b-instruct": {
      "id": "meta-llama-3-70b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Meta-Llama-3-70B-Instruct",
      "family": "llama-3",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00268,
      "output_cost_per_1k": 0.00354,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-04-18",
      "open_weights": true
    },
    "azure_cognitive_services/text-embedding-3-large": {
      "id": "text-embedding-3-large",
      "provider": "azure_cognitive_services",
      "name": "text-embedding-3-large",
      "family": "text-embedding-3-large",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0,
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/grok-3": {
      "id": "grok-3",
      "provider": "azure_cognitive_services",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-11",
      "release_date": "2025-02-17"
    },
    "azure_cognitive_services/gpt-3.5-turbo-0125": {
      "id": "gpt-3.5-turbo-0125",
      "provider": "azure_cognitive_services",
      "name": "GPT-3.5 Turbo 0125",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2021-08",
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/claude-sonnet-4-5": {
      "id": "claude-sonnet-4-5",
      "provider": "azure_cognitive_services",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/phi-4-mini-reasoning": {
      "id": "phi-4-mini-reasoning",
      "provider": "azure_cognitive_services",
      "name": "Phi-4-mini-reasoning",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/phi-4": {
      "id": "phi-4",
      "provider": "azure_cognitive_services",
      "name": "Phi-4",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.000125,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/deepseek-v3.1": {
      "id": "deepseek-v3.1",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00056,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-08-21",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5-chat": {
      "id": "gpt-5-chat",
      "provider": "azure_cognitive_services",
      "name": "GPT-5 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00013,
      "capabilities": [
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-10-24",
      "release_date": "2025-08-07"
    },
    "azure_cognitive_services/gpt-4.1-mini": {
      "id": "gpt-4.1-mini",
      "provider": "azure_cognitive_services",
      "name": "GPT-4.1 mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0016,
      "cache_read_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "azure_cognitive_services/llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "azure_cognitive_services",
      "name": "Llama 4 Maverick 17B 128E Instruct FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "azure_cognitive_services/cohere-command-r-plus-08-2024": {
      "id": "cohere-command-r-plus-08-2024",
      "provider": "azure_cognitive_services",
      "name": "Command R+",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "azure_cognitive_services/cohere-command-a": {
      "id": "cohere-command-a",
      "provider": "azure_cognitive_services",
      "name": "Command A",
      "family": "command-a",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 8000,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.01,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2025-03-13",
      "open_weights": true
    },
    "azure_cognitive_services/phi-3-small-128k-instruct": {
      "id": "phi-3-small-128k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-small-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/claude-opus-4-5": {
      "id": "claude-opus-4-5",
      "provider": "azure_cognitive_services",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "azure_cognitive_services/mistral-medium-2505": {
      "id": "mistral-medium-2505",
      "provider": "azure_cognitive_services",
      "name": "Mistral Medium 3",
      "family": "mistral-medium",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-05",
      "release_date": "2025-05-07"
    },
    "azure_cognitive_services/deepseek-v3.2-speciale": {
      "id": "deepseek-v3.2-speciale",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-V3.2-Speciale",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00028,
      "output_cost_per_1k": 0.00042,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-12-01",
      "open_weights": true
    },
    "azure_cognitive_services/claude-haiku-4-5": {
      "id": "claude-haiku-4-5",
      "provider": "azure_cognitive_services",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-31",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/phi-3-mini-4k-instruct": {
      "id": "phi-3-mini-4k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-mini-instruct (4k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.00052,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5.1-codex": {
      "id": "gpt-5.1-codex",
      "provider": "azure_cognitive_services",
      "name": "GPT-5.1 Codex",
      "family": "gpt-5-codex",
      "mode": "image",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00125,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.000125,
      "capabilities": [
        "audio_input",
        "audio_output",
        "function_calling",
        "image_output",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2024-09-30",
      "release_date": "2025-11-14"
    },
    "azure_cognitive_services/grok-code-fast-1": {
      "id": "grok-code-fast-1",
      "provider": "azure_cognitive_services",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 10000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2025-08-28"
    },
    "azure_cognitive_services/deepseek-r1": {
      "id": "deepseek-r1",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "azure_cognitive_services/meta-llama-3.1-405b-instruct": {
      "id": "meta-llama-3.1-405b-instruct",
      "provider": "azure_cognitive_services",
      "name": "Meta-Llama-3.1-405B-Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00533,
      "output_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-4-32k": {
      "id": "gpt-4-32k",
      "provider": "azure_cognitive_services",
      "name": "GPT-4 32K",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 32768,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-03-14"
    },
    "azure_cognitive_services/phi-4-mini": {
      "id": "phi-4-mini",
      "provider": "azure_cognitive_services",
      "name": "Phi-4-mini",
      "family": "phi-4",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7.5e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-12-11",
      "open_weights": true
    },
    "azure_cognitive_services/cohere-embed-v3-multilingual": {
      "id": "cohere-embed-v3-multilingual",
      "provider": "azure_cognitive_services",
      "name": "Embed v3 Multilingual",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 512,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0,
      "release_date": "2023-11-07",
      "open_weights": true
    },
    "azure_cognitive_services/grok-4": {
      "id": "grok-4",
      "provider": "azure_cognitive_services",
      "name": "Grok 4",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "reasoning_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-09"
    },
    "azure_cognitive_services/cohere-command-r-08-2024": {
      "id": "cohere-command-r-08-2024",
      "provider": "azure_cognitive_services",
      "name": "Command R",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4000,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-06-01",
      "release_date": "2024-08-30",
      "open_weights": true
    },
    "azure_cognitive_services/cohere-embed-v-4-0": {
      "id": "cohere-embed-v-4-0",
      "provider": "azure_cognitive_services",
      "name": "Embed v4",
      "family": "cohere-embed",
      "mode": "embedding",
      "max_input_tokens": 128000,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "vision"
      ],
      "release_date": "2025-04-15",
      "open_weights": true
    },
    "azure_cognitive_services/llama-3.2-11b-vision-instruct": {
      "id": "llama-3.2-11b-vision-instruct",
      "provider": "azure_cognitive_services",
      "name": "Llama-3.2-11B-Vision-Instruct",
      "family": "llama-3.2",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00037,
      "output_cost_per_1k": 0.00037,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "azure_cognitive_services/gpt-5.2-chat": {
      "id": "gpt-5.2-chat",
      "provider": "azure_cognitive_services",
      "name": "GPT-5.2 Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00175,
      "output_cost_per_1k": 0.014,
      "cache_read_cost_per_1k": 0.000175,
      "capabilities": [
        "function_calling",
        "json_mode",
        "reasoning",
        "vision"
      ],
      "knowledge_cutoff": "2025-08-31",
      "release_date": "2025-12-11"
    },
    "azure_cognitive_services/claude-opus-4-1": {
      "id": "claude-opus-4-1",
      "provider": "azure_cognitive_services",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "json_mode",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-18"
    },
    "azure_cognitive_services/gpt-4": {
      "id": "gpt-4",
      "provider": "azure_cognitive_services",
      "name": "GPT-4",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.06,
      "output_cost_per_1k": 0.12,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-11",
      "release_date": "2023-03-14"
    },
    "azure_cognitive_services/phi-3-medium-128k-instruct": {
      "id": "phi-3-medium-128k-instruct",
      "provider": "azure_cognitive_services",
      "name": "Phi-3-medium-instruct (128k)",
      "family": "phi-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00068,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-10",
      "release_date": "2024-04-23",
      "open_weights": true
    },
    "azure_cognitive_services/grok-4-fast-reasoning": {
      "id": "grok-4-fast-reasoning",
      "provider": "azure_cognitive_services",
      "name": "Grok 4 Fast (Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "azure_cognitive_services/deepseek-r1-0528": {
      "id": "deepseek-r1-0528",
      "provider": "azure_cognitive_services",
      "name": "DeepSeek-R1-0528",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 163840,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-05-28",
      "open_weights": true
    },
    "azure_cognitive_services/grok-4-fast-non-reasoning": {
      "id": "grok-4-fast-non-reasoning",
      "provider": "azure_cognitive_services",
      "name": "Grok 4 Fast (Non-Reasoning)",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-09-19"
    },
    "azure_cognitive_services/text-embedding-3-small": {
      "id": "text-embedding-3-small",
      "provider": "azure_cognitive_services",
      "name": "text-embedding-3-small",
      "family": "text-embedding-3-small",
      "mode": "embedding",
      "max_input_tokens": 8191,
      "max_output_tokens": 1536,
      "input_cost_per_1k": 2e-05,
      "output_cost_per_1k": 0.0,
      "release_date": "2024-01-25"
    },
    "azure_cognitive_services/gpt-4.1-nano": {
      "id": "gpt-4.1-nano",
      "provider": "azure_cognitive_services",
      "name": "GPT-4.1 nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0004,
      "cache_read_cost_per_1k": 3e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-05",
      "release_date": "2025-04-14"
    },
    "llama/llama-3.3-8b-instruct": {
      "id": "llama-3.3-8b-instruct",
      "provider": "llama",
      "name": "Llama-3.3-8B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "llama/llama-4-maverick-17b-128e-instruct-fp8": {
      "id": "llama-4-maverick-17b-128e-instruct-fp8",
      "provider": "llama",
      "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "llama/llama-3.3-70b-instruct": {
      "id": "llama-3.3-70b-instruct",
      "provider": "llama",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "llama/llama-4-scout-17b-16e-instruct-fp8": {
      "id": "llama-4-scout-17b-16e-instruct-fp8",
      "provider": "llama",
      "name": "Llama-4-Scout-17B-16E-Instruct-FP8",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "llama/groq-llama-4-maverick-17b-128e-instruct": {
      "id": "groq-llama-4-maverick-17b-128e-instruct",
      "provider": "llama",
      "name": "Groq-Llama-4-Maverick-17B-128E-Instruct",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "llama/cerebras-llama-4-scout-17b-16e-instruct": {
      "id": "cerebras-llama-4-scout-17b-16e-instruct",
      "provider": "llama",
      "name": "Cerebras-Llama-4-Scout-17B-16E-Instruct",
      "family": "llama-4-scout",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "llama/cerebras-llama-4-maverick-17b-128e-instruct": {
      "id": "cerebras-llama-4-maverick-17b-128e-instruct",
      "provider": "llama",
      "name": "Cerebras-Llama-4-Maverick-17B-128E-Instruct",
      "family": "llama-4-maverick",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-01",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "scaleway/qwen3-235b-a22b-instruct-2507": {
      "id": "qwen3-235b-a22b-instruct-2507",
      "provider": "scaleway",
      "name": "Qwen3 235B A22B Instruct 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 260000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00075,
      "output_cost_per_1k": 0.00225,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "scaleway/pixtral-12b-2409": {
      "id": "pixtral-12b-2409",
      "provider": "scaleway",
      "name": "Pixtral 12B 2409",
      "family": "pixtral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "scaleway/llama-3.1-8b-instruct": {
      "id": "llama-3.1-8b-instruct",
      "provider": "scaleway",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama-3.1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2025-01-01",
      "open_weights": true
    },
    "scaleway/mistral-nemo-instruct-2407": {
      "id": "mistral-nemo-instruct-2407",
      "provider": "scaleway",
      "name": "Mistral Nemo Instruct 2407",
      "family": "mistral-nemo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2024-07-25",
      "open_weights": true
    },
    "scaleway/mistral-small-3.2-24b-instruct-2506": {
      "id": "mistral-small-3.2-24b-instruct-2506",
      "provider": "scaleway",
      "name": "Mistral Small 3.2 24B Instruct (2506)",
      "family": "mistral-small",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-06-20",
      "open_weights": true
    },
    "scaleway/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen3-coder-30b-a3b-instruct",
      "provider": "scaleway",
      "name": "Qwen3-Coder 30B-A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-04",
      "open_weights": true
    },
    "scaleway/llama-3.3-70b-instruct": {
      "id": "llama-3.3-70b-instruct",
      "provider": "scaleway",
      "name": "Llama-3.3-70B-Instruct",
      "family": "llama-3.3",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "scaleway/whisper-large-v3": {
      "id": "whisper-large-v3",
      "provider": "scaleway",
      "name": "Whisper Large v3",
      "family": "whisper-large",
      "mode": "audio_transcription",
      "max_input_tokens": 0,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 3e-06,
      "output_cost_per_1k": 0.0,
      "capabilities": [
        "audio_input"
      ],
      "knowledge_cutoff": "2023-09",
      "release_date": "2023-09-01",
      "open_weights": true
    },
    "scaleway/deepseek-r1-distill-llama-70b": {
      "id": "deepseek-r1-distill-llama-70b",
      "provider": "scaleway",
      "name": "DeepSeek R1 Distill Llama 70B",
      "family": "deepseek-r1-distill-llama",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0009,
      "output_cost_per_1k": 0.0009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20",
      "open_weights": true
    },
    "scaleway/voxtral-small-24b-2507": {
      "id": "voxtral-small-24b-2507",
      "provider": "scaleway",
      "name": "Voxtral Small 24B 2507",
      "family": "voxtral-small",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "scaleway/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "scaleway",
      "name": "GPT-OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2024-01-01",
      "open_weights": true
    },
    "scaleway/bge-multilingual-gemma2": {
      "id": "bge-multilingual-gemma2",
      "provider": "scaleway",
      "name": "BGE Multilingual Gemma2",
      "family": "gemma-2",
      "mode": "chat",
      "max_input_tokens": 8191,
      "max_output_tokens": 3072,
      "input_cost_per_1k": 0.00013,
      "output_cost_per_1k": 0.0,
      "release_date": "2024-07-26"
    },
    "scaleway/gemma-3-27b-it": {
      "id": "gemma-3-27b-it",
      "provider": "scaleway",
      "name": "Gemma-3-27B-IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 40000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.0005,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/cohere.command-r-plus-v1:0": {
      "id": "cohere.command-r-plus-v1:0",
      "provider": "aws_bedrock",
      "name": "Command R+",
      "family": "command-r-plus",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-04-04",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-v2": {
      "id": "anthropic.claude-v2",
      "provider": "aws_bedrock",
      "name": "Claude 2",
      "family": "claude",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2023-07-11"
    },
    "aws_bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0": {
      "id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-02-19"
    },
    "aws_bedrock/anthropic.claude-sonnet-4-20250514-v1:0": {
      "id": "anthropic.claude-sonnet-4-20250514-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-22"
    },
    "aws_bedrock/qwen.qwen3-coder-30b-a3b-v1:0": {
      "id": "qwen.qwen3-coder-30b-a3b-v1:0",
      "provider": "aws_bedrock",
      "name": "Qwen3 Coder 30B A3B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-18"
    },
    "aws_bedrock/google.gemma-3-4b-it": {
      "id": "google.gemma-3-4b-it",
      "provider": "aws_bedrock",
      "name": "Gemma 3 4B IT",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 8e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/minimax.minimax-m2": {
      "id": "minimax.minimax-m2",
      "provider": "aws_bedrock",
      "name": "MiniMax M2",
      "family": "minimax",
      "mode": "chat",
      "max_input_tokens": 204608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-10-27",
      "open_weights": true
    },
    "aws_bedrock/meta.llama3-2-11b-instruct-v1:0": {
      "id": "meta.llama3-2-11b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.2 11B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00016,
      "output_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "aws_bedrock/qwen.qwen3-next-80b-a3b": {
      "id": "qwen.qwen3-next-80b-a3b",
      "provider": "aws_bedrock",
      "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-09-18"
    },
    "aws_bedrock/anthropic.claude-3-haiku-20240307-v1:0": {
      "id": "anthropic.claude-3-haiku-20240307-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Haiku 3",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-02",
      "release_date": "2024-03-13"
    },
    "aws_bedrock/meta.llama3-2-90b-instruct-v1:0": {
      "id": "meta.llama3-2-90b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.2 90B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "aws_bedrock/qwen.qwen3-vl-235b-a22b": {
      "id": "qwen.qwen3-vl-235b-a22b",
      "provider": "aws_bedrock",
      "name": "Qwen/Qwen3-VL-235B-A22B-Instruct",
      "family": "qwen3-vl",
      "mode": "chat",
      "max_input_tokens": 262000,
      "max_output_tokens": 262000,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature",
        "vision"
      ],
      "release_date": "2025-10-04"
    },
    "aws_bedrock/meta.llama3-2-1b-instruct-v1:0": {
      "id": "meta.llama3-2-1b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.2 1B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-v2:1": {
      "id": "anthropic.claude-v2:1",
      "provider": "aws_bedrock",
      "name": "Claude 2.1",
      "family": "claude",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.008,
      "output_cost_per_1k": 0.024,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2023-11-21"
    },
    "aws_bedrock/deepseek.v3-v1:0": {
      "id": "deepseek.v3-v1:0",
      "provider": "aws_bedrock",
      "name": "DeepSeek-V3.1",
      "family": "deepseek-v3",
      "mode": "chat",
      "max_input_tokens": 163840,
      "max_output_tokens": 81920,
      "input_cost_per_1k": 0.00058,
      "output_cost_per_1k": 0.00168,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-09-18",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Opus 4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "aws_bedrock/cohere.command-light-text-v14": {
      "id": "cohere.command-light-text-v14",
      "provider": "aws_bedrock",
      "name": "Command Light",
      "family": "command-light",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2023-11-01",
      "open_weights": true
    },
    "aws_bedrock/mistral.mistral-large-2402-v1:0": {
      "id": "mistral.mistral-large-2402-v1:0",
      "provider": "aws_bedrock",
      "name": "Mistral Large (24.02)",
      "family": "mistral-large",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/google.gemma-3-27b-it": {
      "id": "google.gemma-3-27b-it",
      "provider": "aws_bedrock",
      "name": "Google Gemma 3 27B Instruct",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 202752,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00012,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07",
      "release_date": "2025-07-27",
      "open_weights": true
    },
    "aws_bedrock/nvidia.nemotron-nano-12b-v2": {
      "id": "nvidia.nemotron-nano-12b-v2",
      "provider": "aws_bedrock",
      "name": "NVIDIA Nemotron Nano 12B v2 VL BF16",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/google.gemma-3-12b-it": {
      "id": "google.gemma-3-12b-it",
      "provider": "aws_bedrock",
      "name": "Google Gemma 3 12B",
      "family": "gemma-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5e-05,
      "output_cost_per_1k": 0.0001,
      "capabilities": [
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-12",
      "release_date": "2024-12-01"
    },
    "aws_bedrock/ai21.jamba-1-5-large-v1:0": {
      "id": "ai21.jamba-1-5-large-v1:0",
      "provider": "aws_bedrock",
      "name": "Jamba 1.5 Large",
      "family": "jamba-1.5-large",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.002,
      "output_cost_per_1k": 0.008,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-15",
      "open_weights": true
    },
    "aws_bedrock/meta.llama3-3-70b-instruct-v1:0": {
      "id": "meta.llama3-3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.3 70B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-12-06",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-3-opus-20240229-v1:0": {
      "id": "anthropic.claude-3-opus-20240229-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Opus 3",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2024-02-29"
    },
    "aws_bedrock/amazon.nova-pro-v1:0": {
      "id": "amazon.nova-pro-v1:0",
      "provider": "aws_bedrock",
      "name": "Nova Pro",
      "family": "nova-pro",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0032,
      "cache_read_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/meta.llama3-1-8b-instruct-v1:0": {
      "id": "meta.llama3-1-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.1 8B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00022,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "aws_bedrock/openai.gpt-oss-120b-1:0": {
      "id": "openai.gpt-oss-120b-1:0",
      "provider": "aws_bedrock",
      "name": "gpt-oss-120b",
      "family": "openai.gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/qwen.qwen3-32b-v1:0": {
      "id": "qwen.qwen3-32b-v1:0",
      "provider": "aws_bedrock",
      "name": "Qwen3 32B (dense)",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-18",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20240620-v1:0": {
      "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 3.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-06-20"
    },
    "aws_bedrock/anthropic.claude-haiku-4-5-20251001-v1:0": {
      "id": "anthropic.claude-haiku-4-5-20251001-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.001,
      "output_cost_per_1k": 0.005,
      "cache_read_cost_per_1k": 0.0001,
      "cache_write_cost_per_1k": 0.00125,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-02-28",
      "release_date": "2025-10-15"
    },
    "aws_bedrock/cohere.command-r-v1:0": {
      "id": "cohere.command-r-v1:0",
      "provider": "aws_bedrock",
      "name": "Command R",
      "family": "command-r",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0005,
      "output_cost_per_1k": 0.0015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-03-11",
      "open_weights": true
    },
    "aws_bedrock/mistral.voxtral-small-24b-2507": {
      "id": "mistral.voxtral-small-24b-2507",
      "provider": "aws_bedrock",
      "name": "Voxtral Small 24B 2507",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00035,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature",
        "vision"
      ],
      "release_date": "2025-07-01",
      "open_weights": true
    },
    "aws_bedrock/amazon.nova-micro-v1:0": {
      "id": "amazon.nova-micro-v1:0",
      "provider": "aws_bedrock",
      "name": "Nova Micro",
      "family": "nova-micro",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 3.5e-05,
      "output_cost_per_1k": 0.00014,
      "cache_read_cost_per_1k": 8.75e-06,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/meta.llama3-1-70b-instruct-v1:0": {
      "id": "meta.llama3-1-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.1 70B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00072,
      "output_cost_per_1k": 0.00072,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "aws_bedrock/meta.llama3-70b-instruct-v1:0": {
      "id": "meta.llama3-70b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3 70B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00265,
      "output_cost_per_1k": 0.0035,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "aws_bedrock/deepseek.r1-v1:0": {
      "id": "deepseek.r1-v1:0",
      "provider": "aws_bedrock",
      "name": "DeepSeek-R1",
      "family": "deepseek-r1",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00135,
      "output_cost_per_1k": 0.0054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2025-01-20"
    },
    "aws_bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0": {
      "id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 3.5 v2",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2024-10-22"
    },
    "aws_bedrock/mistral.ministral-3-8b-instruct": {
      "id": "mistral.ministral-3-8b-instruct",
      "provider": "aws_bedrock",
      "name": "Ministral 3 8B",
      "family": "ministral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/cohere.command-text-v14": {
      "id": "cohere.command-text-v14",
      "provider": "aws_bedrock",
      "name": "Command",
      "family": "command",
      "mode": "chat",
      "max_input_tokens": 4096,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0015,
      "output_cost_per_1k": 0.002,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2023-11-01",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-opus-4-20250514-v1:0": {
      "id": "anthropic.claude-opus-4-20250514-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-05-22"
    },
    "aws_bedrock/mistral.voxtral-mini-3b-2507": {
      "id": "mistral.voxtral-mini-3b-2507",
      "provider": "aws_bedrock",
      "name": "Voxtral Mini 3B 2507",
      "family": "mistral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 4e-05,
      "output_cost_per_1k": 4e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/global.anthropic.claude-opus-4-5-20251101-v1:0": {
      "id": "global.anthropic.claude-opus-4-5-20251101-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Opus 4.5 (Global)",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.005,
      "output_cost_per_1k": 0.025,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-11-24"
    },
    "aws_bedrock/amazon.nova-2-lite-v1:0": {
      "id": "amazon.nova-2-lite-v1:0",
      "provider": "aws_bedrock",
      "name": "Nova 2 Lite",
      "family": "nova",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00033,
      "output_cost_per_1k": 0.00275,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/qwen.qwen3-coder-480b-a35b-v1:0": {
      "id": "qwen.qwen3-coder-480b-a35b-v1:0",
      "provider": "aws_bedrock",
      "name": "Qwen3 Coder 480B A35B Instruct",
      "family": "qwen3-coder",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-18",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-sonnet-4-5-20250929-v1:0": {
      "id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.0003,
      "cache_write_cost_per_1k": 0.00375,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-07-31",
      "release_date": "2025-09-29"
    },
    "aws_bedrock/openai.gpt-oss-safeguard-20b": {
      "id": "openai.gpt-oss-safeguard-20b",
      "provider": "aws_bedrock",
      "name": "GPT OSS Safeguard 20B",
      "family": "openai.gpt-oss-safeguard",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-20b-1:0": {
      "id": "openai.gpt-oss-20b-1:0",
      "provider": "aws_bedrock",
      "name": "gpt-oss-20b",
      "family": "openai.gpt-oss",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.0003,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/meta.llama3-2-3b-instruct-v1:0": {
      "id": "meta.llama3-2-3b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3.2 3B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.00015,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2023-12",
      "release_date": "2024-09-25",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-instant-v1": {
      "id": "anthropic.claude-instant-v1",
      "provider": "aws_bedrock",
      "name": "Claude Instant",
      "family": "claude",
      "mode": "chat",
      "max_input_tokens": 100000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.0024,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2023-03-01"
    },
    "aws_bedrock/amazon.nova-premier-v1:0": {
      "id": "amazon.nova-premier-v1:0",
      "provider": "aws_bedrock",
      "name": "Nova Premier",
      "family": "nova",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0025,
      "output_cost_per_1k": 0.0125,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/mistral.mistral-7b-instruct-v0:2": {
      "id": "mistral.mistral-7b-instruct-v0:2",
      "provider": "aws_bedrock",
      "name": "Mistral-7B-Instruct-v0.3",
      "family": "mistral-7b",
      "mode": "chat",
      "max_input_tokens": 127000,
      "max_output_tokens": 127000,
      "input_cost_per_1k": 0.00011,
      "output_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "aws_bedrock/mistral.mixtral-8x7b-instruct-v0:1": {
      "id": "mistral.mixtral-8x7b-instruct-v0:1",
      "provider": "aws_bedrock",
      "name": "Mixtral-8x7B-Instruct-v0.1",
      "family": "mixtral-8x7b",
      "mode": "chat",
      "max_input_tokens": 32000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0007,
      "output_cost_per_1k": 0.0007,
      "capabilities": [
        "json_mode",
        "temperature"
      ],
      "release_date": "2025-04-01",
      "open_weights": true
    },
    "aws_bedrock/anthropic.claude-opus-4-1-20250805-v1:0": {
      "id": "anthropic.claude-opus-4-1-20250805-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.015,
      "output_cost_per_1k": 0.075,
      "cache_read_cost_per_1k": 0.0015,
      "cache_write_cost_per_1k": 0.01875,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2025-03-31",
      "release_date": "2025-08-05"
    },
    "aws_bedrock/meta.llama4-scout-17b-instruct-v1:0": {
      "id": "meta.llama4-scout-17b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 4 Scout 17B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 3500000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00017,
      "output_cost_per_1k": 0.00066,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "aws_bedrock/ai21.jamba-1-5-mini-v1:0": {
      "id": "ai21.jamba-1-5-mini-v1:0",
      "provider": "aws_bedrock",
      "name": "Jamba 1.5 Mini",
      "family": "jamba-1.5-mini",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0004,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2024-08-15",
      "open_weights": true
    },
    "aws_bedrock/meta.llama3-8b-instruct-v1:0": {
      "id": "meta.llama3-8b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 3 8B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "temperature"
      ],
      "knowledge_cutoff": "2023-03",
      "release_date": "2024-07-23",
      "open_weights": true
    },
    "aws_bedrock/amazon.titan-text-express-v1:0:8k": {
      "id": "amazon.titan-text-express-v1:0:8k",
      "provider": "aws_bedrock",
      "name": "Titan Text G1 - Express",
      "family": "titan-text-express",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/anthropic.claude-3-sonnet-20240229-v1:0": {
      "id": "anthropic.claude-3-sonnet-20240229-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Sonnet 3",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2023-08",
      "release_date": "2024-03-04"
    },
    "aws_bedrock/nvidia.nemotron-nano-9b-v2": {
      "id": "nvidia.nemotron-nano-9b-v2",
      "provider": "aws_bedrock",
      "name": "NVIDIA Nemotron Nano 9B v2",
      "family": "nemotron",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00023,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/amazon.titan-text-express-v1": {
      "id": "amazon.titan-text-express-v1",
      "provider": "aws_bedrock",
      "name": "Titan Text G1 - Express",
      "family": "titan-text-express",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/meta.llama4-maverick-17b-instruct-v1:0": {
      "id": "meta.llama4-maverick-17b-instruct-v1:0",
      "provider": "aws_bedrock",
      "name": "Llama 4 Maverick 17B Instruct",
      "family": "llama",
      "mode": "chat",
      "max_input_tokens": 1000000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.00024,
      "output_cost_per_1k": 0.00097,
      "capabilities": [
        "function_calling",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-08",
      "release_date": "2025-04-05",
      "open_weights": true
    },
    "aws_bedrock/mistral.ministral-3-14b-instruct": {
      "id": "mistral.ministral-3-14b-instruct",
      "provider": "aws_bedrock",
      "name": "Ministral 14B 3.0",
      "family": "ministral",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0002,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/openai.gpt-oss-safeguard-120b": {
      "id": "openai.gpt-oss-safeguard-120b",
      "provider": "aws_bedrock",
      "name": "GPT OSS Safeguard 120B",
      "family": "openai.gpt-oss-safeguard",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00015,
      "output_cost_per_1k": 0.0006,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2024-12-01"
    },
    "aws_bedrock/qwen.qwen3-235b-a22b-2507-v1:0": {
      "id": "qwen.qwen3-235b-a22b-2507-v1:0",
      "provider": "aws_bedrock",
      "name": "Qwen3 235B A22B 2507",
      "family": "qwen3",
      "mode": "chat",
      "max_input_tokens": 262144,
      "max_output_tokens": 131072,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.00088,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2024-04",
      "release_date": "2025-09-18",
      "open_weights": true
    },
    "aws_bedrock/amazon.nova-lite-v1:0": {
      "id": "amazon.nova-lite-v1:0",
      "provider": "aws_bedrock",
      "name": "Nova Lite",
      "family": "nova-lite",
      "mode": "chat",
      "max_input_tokens": 300000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 6e-05,
      "output_cost_per_1k": 0.00024,
      "cache_read_cost_per_1k": 1.5e-05,
      "capabilities": [
        "function_calling",
        "temperature",
        "video_input",
        "vision"
      ],
      "knowledge_cutoff": "2024-10",
      "release_date": "2024-12-03"
    },
    "aws_bedrock/anthropic.claude-3-5-haiku-20241022-v1:0": {
      "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
      "provider": "aws_bedrock",
      "name": "Claude Haiku 3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0008,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 8e-05,
      "cache_write_cost_per_1k": 0.001,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "temperature",
        "vision"
      ],
      "knowledge_cutoff": "2024-07",
      "release_date": "2024-10-22"
    },
    "aws_bedrock/moonshot.kimi-k2-thinking": {
      "id": "moonshot.kimi-k2-thinking",
      "provider": "aws_bedrock",
      "name": "Kimi K2 Thinking",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 256000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-12-02",
      "open_weights": true
    },
    "poe/xai/grok-4-fast-non-reasoning": {
      "id": "xai/grok-4-fast-non-reasoning",
      "provider": "poe",
      "name": "Grok-4-Fast-Non-Reasoning",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-09-16"
    },
    "poe/xai/grok-4-fast-reasoning": {
      "id": "xai/grok-4-fast-reasoning",
      "provider": "poe",
      "name": "Grok 4 Fast Reasoning",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-09-16"
    },
    "poe/xai/grok-4.1-fast-reasoning": {
      "id": "xai/grok-4.1-fast-reasoning",
      "provider": "poe",
      "name": "Grok-4.1-Fast-Reasoning",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-19"
    },
    "poe/xai/grok-4": {
      "id": "xai/grok-4",
      "provider": "poe",
      "name": "Grok 4",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-07-10"
    },
    "poe/xai/grok-code-fast-1": {
      "id": "xai/grok-code-fast-1",
      "provider": "poe",
      "name": "Grok Code Fast 1",
      "family": "grok",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0002,
      "output_cost_per_1k": 0.0015,
      "cache_read_cost_per_1k": 2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-08-22"
    },
    "poe/xai/grok-4.1-fast-non-reasoning": {
      "id": "xai/grok-4.1-fast-non-reasoning",
      "provider": "poe",
      "name": "Grok-4.1-Fast-Non-Reasoning",
      "family": "grok-4",
      "mode": "chat",
      "max_input_tokens": 2000000,
      "max_output_tokens": 30000,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-11-19"
    },
    "poe/xai/grok-3": {
      "id": "xai/grok-3",
      "provider": "poe",
      "name": "Grok 3",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.003,
      "output_cost_per_1k": 0.015,
      "cache_read_cost_per_1k": 0.00075,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-04-11"
    },
    "poe/xai/grok-3-mini": {
      "id": "xai/grok-3-mini",
      "provider": "poe",
      "name": "Grok 3 Mini",
      "family": "grok-3",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0003,
      "output_cost_per_1k": 0.0005,
      "cache_read_cost_per_1k": 7.5e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-04-11"
    },
    "poe/ideogramai/ideogram": {
      "id": "ideogramai/ideogram",
      "provider": "poe",
      "name": "Ideogram",
      "family": "ideogram",
      "mode": "image",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2024-04-03"
    },
    "poe/ideogramai/ideogram-v2a": {
      "id": "ideogramai/ideogram-v2a",
      "provider": "poe",
      "name": "Ideogram-v2a",
      "family": "ideogram",
      "mode": "image",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-02-27"
    },
    "poe/ideogramai/ideogram-v2a-turbo": {
      "id": "ideogramai/ideogram-v2a-turbo",
      "provider": "poe",
      "name": "Ideogram-v2a-Turbo",
      "family": "ideogram",
      "mode": "image",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-02-27"
    },
    "poe/ideogramai/ideogram-v2": {
      "id": "ideogramai/ideogram-v2",
      "provider": "poe",
      "name": "Ideogram-v2",
      "family": "ideogram",
      "mode": "image",
      "max_input_tokens": 150,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2024-08-21"
    },
    "poe/runwayml/runway": {
      "id": "runwayml/runway",
      "provider": "poe",
      "name": "Runway",
      "family": "runway",
      "mode": "chat",
      "max_input_tokens": 256,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-10-11"
    },
    "poe/runwayml/runway-gen-4-turbo": {
      "id": "runwayml/runway-gen-4-turbo",
      "provider": "poe",
      "name": "Runway-Gen-4-Turbo",
      "family": "runway-gen-4-turbo",
      "mode": "chat",
      "max_input_tokens": 256,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-05-09"
    },
    "poe/poetools/claude-code": {
      "id": "poetools/claude-code",
      "provider": "poe",
      "name": "claude-code",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-27"
    },
    "poe/elevenlabs/elevenlabs-v3": {
      "id": "elevenlabs/elevenlabs-v3",
      "provider": "poe",
      "name": "ElevenLabs-v3",
      "family": "elevenlabs",
      "mode": "audio_speech",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "release_date": "2025-06-05"
    },
    "poe/elevenlabs/elevenlabs-music": {
      "id": "elevenlabs/elevenlabs-music",
      "provider": "poe",
      "name": "ElevenLabs-Music",
      "family": "elevenlabs-music",
      "mode": "audio_speech",
      "max_input_tokens": 2000,
      "max_output_tokens": 0,
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "release_date": "2025-08-29"
    },
    "poe/elevenlabs/elevenlabs-v2.5-turbo": {
      "id": "elevenlabs/elevenlabs-v2.5-turbo",
      "provider": "poe",
      "name": "ElevenLabs-v2.5-Turbo",
      "family": "elevenlabs-v2.5-turbo",
      "mode": "audio_speech",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "release_date": "2024-10-28"
    },
    "poe/google/gemini-deep-research": {
      "id": "google/gemini-deep-research",
      "provider": "poe",
      "name": "gemini-deep-research",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.0096,
      "capabilities": [
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-12-11"
    },
    "poe/google/nano-banana": {
      "id": "google/nano-banana",
      "provider": "poe",
      "name": "Nano-Banana",
      "family": "nano-banana",
      "mode": "image",
      "max_input_tokens": 32768,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.0018,
      "cache_read_cost_per_1k": 2.1e-05,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-08-21"
    },
    "poe/google/imagen-4": {
      "id": "google/imagen-4",
      "provider": "poe",
      "name": "Imagen-4",
      "family": "imagen",
      "mode": "image",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-05-22"
    },
    "poe/google/imagen-3": {
      "id": "google/imagen-3",
      "provider": "poe",
      "name": "Imagen-3",
      "family": "imagen",
      "mode": "image",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2024-10-15"
    },
    "poe/google/imagen-4-ultra": {
      "id": "google/imagen-4-ultra",
      "provider": "poe",
      "name": "Imagen-4-Ultra",
      "family": "imagen-4-ultra",
      "mode": "image",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-05-24"
    },
    "poe/google/gemini-2.5-flash": {
      "id": "google/gemini-2.5-flash",
      "provider": "poe",
      "name": "Gemini 2.5 Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 1065535,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.0018,
      "cache_read_cost_per_1k": 2.1e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-04-26"
    },
    "poe/google/gemini-2.0-flash-lite": {
      "id": "google/gemini-2.0-flash-lite",
      "provider": "poe",
      "name": "Gemini-2.0-Flash-Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 990000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 5.2e-05,
      "output_cost_per_1k": 0.00021,
      "capabilities": [
        "audio_input",
        "function_calling",
        "video_input",
        "vision"
      ],
      "release_date": "2025-02-05"
    },
    "poe/google/gemini-3-pro": {
      "id": "google/gemini-3-pro",
      "provider": "poe",
      "name": "Gemini-3-Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.0096,
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-10-22"
    },
    "poe/google/veo-3.1": {
      "id": "google/veo-3.1",
      "provider": "poe",
      "name": "Veo-3.1",
      "family": "veo",
      "mode": "chat",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "poe/google/imagen-3-fast": {
      "id": "google/imagen-3-fast",
      "provider": "poe",
      "name": "Imagen-3-Fast",
      "family": "imagen-3-fast",
      "mode": "image",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2024-10-17"
    },
    "poe/google/lyria": {
      "id": "google/lyria",
      "provider": "poe",
      "name": "Lyria",
      "family": "lyria",
      "mode": "audio_speech",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "audio_output",
        "function_calling",
        "vision"
      ],
      "release_date": "2025-06-04"
    },
    "poe/google/gemini-2.0-flash": {
      "id": "google/gemini-2.0-flash",
      "provider": "poe",
      "name": "Gemini-2.0-Flash",
      "family": "gemini-flash",
      "mode": "chat",
      "max_input_tokens": 990000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0001,
      "output_cost_per_1k": 0.00042,
      "capabilities": [
        "audio_input",
        "function_calling",
        "video_input",
        "vision"
      ],
      "release_date": "2024-12-11"
    },
    "poe/google/gemini-2.5-flash-lite": {
      "id": "google/gemini-2.5-flash-lite",
      "provider": "poe",
      "name": "Gemini 2.5 Flash Lite",
      "family": "gemini-flash-lite",
      "mode": "chat",
      "max_input_tokens": 1024000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 7e-05,
      "output_cost_per_1k": 0.00028,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-06-19"
    },
    "poe/google/veo-3": {
      "id": "google/veo-3",
      "provider": "poe",
      "name": "Veo-3",
      "family": "veo",
      "mode": "chat",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-05-21"
    },
    "poe/google/veo-3-fast": {
      "id": "google/veo-3-fast",
      "provider": "poe",
      "name": "Veo-3-Fast",
      "family": "veo-3-fast",
      "mode": "chat",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-10-13"
    },
    "poe/google/imagen-4-fast": {
      "id": "google/imagen-4-fast",
      "provider": "poe",
      "name": "Imagen-4-Fast",
      "family": "imagen-4-fast",
      "mode": "image",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-06-25"
    },
    "poe/google/veo-2": {
      "id": "google/veo-2",
      "provider": "poe",
      "name": "Veo-2",
      "family": "veo",
      "mode": "chat",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-12-02"
    },
    "poe/google/gemini-3-flash": {
      "id": "google/gemini-3-flash",
      "provider": "poe",
      "name": "gemini-3-flash",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 1048576,
      "max_output_tokens": 65536,
      "input_cost_per_1k": 0.0004,
      "output_cost_per_1k": 0.0024,
      "cache_read_cost_per_1k": 4e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-10-07"
    },
    "poe/google/nano-banana-pro": {
      "id": "google/nano-banana-pro",
      "provider": "poe",
      "name": "Nano-Banana-Pro",
      "family": "nano-banana-pro",
      "mode": "image",
      "max_input_tokens": 65536,
      "max_output_tokens": 0,
      "input_cost_per_1k": 0.0017,
      "output_cost_per_1k": 0.01,
      "cache_read_cost_per_1k": 0.00017,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-11-19"
    },
    "poe/google/gemini-2.5-pro": {
      "id": "google/gemini-2.5-pro",
      "provider": "poe",
      "name": "Gemini 2.5 Pro",
      "family": "gemini-pro",
      "mode": "chat",
      "max_input_tokens": 1065535,
      "max_output_tokens": 65535,
      "input_cost_per_1k": 0.00087,
      "output_cost_per_1k": 0.007,
      "cache_read_cost_per_1k": 8.7e-05,
      "capabilities": [
        "audio_input",
        "function_calling",
        "reasoning",
        "video_input",
        "vision"
      ],
      "release_date": "2025-02-05"
    },
    "poe/google/veo-3.1-fast": {
      "id": "google/veo-3.1-fast",
      "provider": "poe",
      "name": "Veo-3.1-Fast",
      "family": "veo-3.1-fast",
      "mode": "chat",
      "max_input_tokens": 480,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "poe/openai/gpt-4.1-nano": {
      "id": "openai/gpt-4.1-nano",
      "provider": "poe",
      "name": "GPT-4.1-nano",
      "family": "gpt-4.1-nano",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 9e-05,
      "output_cost_per_1k": 0.00036,
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-04-15"
    },
    "poe/openai/gpt-5.2-instant": {
      "id": "openai/gpt-5.2-instant",
      "provider": "poe",
      "name": "gpt-5.2-instant",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-12-11"
    },
    "poe/openai/sora-2": {
      "id": "openai/sora-2",
      "provider": "poe",
      "name": "Sora-2",
      "family": "sora",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-10-06"
    },
    "poe/openai/o1-pro": {
      "id": "openai/o1-pro",
      "provider": "poe",
      "name": "o1-pro",
      "family": "o1-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.14,
      "output_cost_per_1k": 0.54,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-03-19"
    },
    "poe/openai/gpt-5.1-codex": {
      "id": "openai/gpt-5.1-codex",
      "provider": "poe",
      "name": "GPT-5.1-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-3.5-turbo-raw": {
      "id": "openai/gpt-3.5-turbo-raw",
      "provider": "poe",
      "name": "GPT-3.5-Turbo-Raw",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 4524,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2023-09-27"
    },
    "poe/openai/gpt-4-classic": {
      "id": "openai/gpt-4-classic",
      "provider": "poe",
      "name": "GPT-4-Classic",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.027,
      "output_cost_per_1k": 0.054,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-03-25"
    },
    "poe/openai/gpt-4.1-mini": {
      "id": "openai/gpt-4.1-mini",
      "provider": "poe",
      "name": "GPT-4.1-mini",
      "family": "gpt-4.1-mini",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00036,
      "output_cost_per_1k": 0.0014,
      "cache_read_cost_per_1k": 9e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-04-15"
    },
    "poe/openai/gpt-5-chat": {
      "id": "openai/gpt-5-chat",
      "provider": "poe",
      "name": "GPT-5-Chat",
      "family": "gpt-5-chat",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-08-07"
    },
    "poe/openai/o3-deep-research": {
      "id": "openai/o3-deep-research",
      "provider": "poe",
      "name": "o3-deep-research",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.009,
      "output_cost_per_1k": 0.036,
      "cache_read_cost_per_1k": 0.0022,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-27"
    },
    "poe/openai/gpt-4o-search": {
      "id": "openai/gpt-4o-search",
      "provider": "poe",
      "name": "GPT-4o-Search",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0022,
      "output_cost_per_1k": 0.009,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-03-11"
    },
    "poe/openai/gpt-image-1.5": {
      "id": "openai/gpt-image-1.5",
      "provider": "poe",
      "name": "gpt-image-1.5",
      "family": null,
      "mode": "image",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-12-16"
    },
    "poe/openai/gpt-image-1-mini": {
      "id": "openai/gpt-image-1-mini",
      "provider": "poe",
      "name": "GPT-Image-1-Mini",
      "family": "gpt-image",
      "mode": "image",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-08-26"
    },
    "poe/openai/gpt-3.5-turbo": {
      "id": "openai/gpt-3.5-turbo",
      "provider": "poe",
      "name": "GPT-3.5-Turbo",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 16384,
      "max_output_tokens": 2048,
      "input_cost_per_1k": 0.00045,
      "output_cost_per_1k": 0.0014,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2023-09-13"
    },
    "poe/openai/gpt-5.2-pro": {
      "id": "openai/gpt-5.2-pro",
      "provider": "poe",
      "name": "gpt-5.2-pro",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.019,
      "output_cost_per_1k": 0.15,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-12-11"
    },
    "poe/openai/o3-mini-high": {
      "id": "openai/o3-mini-high",
      "provider": "poe",
      "name": "o3-mini-high",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-01-31"
    },
    "poe/openai/chatgpt-4o-latest": {
      "id": "openai/chatgpt-4o-latest",
      "provider": "poe",
      "name": "ChatGPT-4o-Latest",
      "family": "chatgpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0045,
      "output_cost_per_1k": 0.014,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-08-14"
    },
    "poe/openai/gpt-4-turbo": {
      "id": "openai/gpt-4-turbo",
      "provider": "poe",
      "name": "GPT-4-Turbo",
      "family": "gpt-4-turbo",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.009,
      "output_cost_per_1k": 0.027,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2023-09-13"
    },
    "poe/openai/gpt-5.1-codex-mini": {
      "id": "openai/gpt-5.1-codex-mini",
      "provider": "poe",
      "name": "GPT-5.1-Codex-Mini",
      "family": "gpt-5-codex-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.0018,
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5.1-instant": {
      "id": "openai/gpt-5.1-instant",
      "provider": "poe",
      "name": "GPT-5.1-Instant",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 16384,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-11-12"
    },
    "poe/openai/o3-mini": {
      "id": "openai/o3-mini",
      "provider": "poe",
      "name": "o3-mini",
      "family": "o3-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.004,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-01-31"
    },
    "poe/openai/gpt-5.1": {
      "id": "openai/gpt-5.1",
      "provider": "poe",
      "name": "GPT-5.1",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-12"
    },
    "poe/openai/gpt-5-nano": {
      "id": "openai/gpt-5-nano",
      "provider": "poe",
      "name": "GPT-5-nano",
      "family": "gpt-5-nano",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 4.5e-05,
      "output_cost_per_1k": 0.00036,
      "cache_read_cost_per_1k": 4.5e-06,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-08-05"
    },
    "poe/openai/gpt-5-codex": {
      "id": "openai/gpt-5-codex",
      "provider": "poe",
      "name": "GPT-5-Codex",
      "family": "gpt-5-codex",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-09-23"
    },
    "poe/openai/gpt-4o": {
      "id": "openai/gpt-4o",
      "provider": "poe",
      "name": "GPT-4o",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-05-13"
    },
    "poe/openai/gpt-4.1": {
      "id": "openai/gpt-4.1",
      "provider": "poe",
      "name": "GPT-4.1",
      "family": "gpt-4.1",
      "mode": "chat",
      "max_input_tokens": 1047576,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0018,
      "output_cost_per_1k": 0.0072,
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-04-14"
    },
    "poe/openai/o4-mini": {
      "id": "openai/o4-mini",
      "provider": "poe",
      "name": "o4-mini",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.00099,
      "output_cost_per_1k": 0.004,
      "cache_read_cost_per_1k": 0.00025,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-04-16"
    },
    "poe/openai/o1": {
      "id": "openai/o1",
      "provider": "poe",
      "name": "o1",
      "family": "o1",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.014,
      "output_cost_per_1k": 0.054,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2024-12-18"
    },
    "poe/openai/gpt-5-mini": {
      "id": "openai/gpt-5-mini",
      "provider": "poe",
      "name": "GPT-5-mini",
      "family": "gpt-5-mini",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.00022,
      "output_cost_per_1k": 0.0018,
      "cache_read_cost_per_1k": 2.2e-05,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-25"
    },
    "poe/openai/gpt-4o-aug": {
      "id": "openai/gpt-4o-aug",
      "provider": "poe",
      "name": "GPT-4o-Aug",
      "family": "gpt-4o",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0022,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-11-21"
    },
    "poe/openai/o3-pro": {
      "id": "openai/o3-pro",
      "provider": "poe",
      "name": "o3-pro",
      "family": "o3-pro",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.018,
      "output_cost_per_1k": 0.072,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-10"
    },
    "poe/openai/gpt-image-1": {
      "id": "openai/gpt-image-1",
      "provider": "poe",
      "name": "GPT-Image-1",
      "family": "gpt-image",
      "mode": "image",
      "max_input_tokens": 128000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2025-03-31"
    },
    "poe/openai/gpt-5.1-codex-max": {
      "id": "openai/gpt-5.1-codex-max",
      "provider": "poe",
      "name": "gpt-5.1-codex-max",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-12-08"
    },
    "poe/openai/gpt-3.5-turbo-instruct": {
      "id": "openai/gpt-3.5-turbo-instruct",
      "provider": "poe",
      "name": "GPT-3.5-Turbo-Instruct",
      "family": "gpt-3.5-turbo",
      "mode": "chat",
      "max_input_tokens": 3500,
      "max_output_tokens": 1024,
      "input_cost_per_1k": 0.0014,
      "output_cost_per_1k": 0.0018,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2023-09-20"
    },
    "poe/openai/o3": {
      "id": "openai/o3",
      "provider": "poe",
      "name": "o3",
      "family": "o3",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0018,
      "output_cost_per_1k": 0.0072,
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-04-16"
    },
    "poe/openai/o4-mini-deep-research": {
      "id": "openai/o4-mini-deep-research",
      "provider": "poe",
      "name": "o4-mini-deep-research",
      "family": "o4-mini",
      "mode": "chat",
      "max_input_tokens": 200000,
      "max_output_tokens": 100000,
      "input_cost_per_1k": 0.0018,
      "output_cost_per_1k": 0.0072,
      "cache_read_cost_per_1k": 0.00045,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-27"
    },
    "poe/openai/gpt-4-classic-0314": {
      "id": "openai/gpt-4-classic-0314",
      "provider": "poe",
      "name": "GPT-4-Classic-0314",
      "family": "gpt-4",
      "mode": "chat",
      "max_input_tokens": 8192,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.027,
      "output_cost_per_1k": 0.054,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-08-26"
    },
    "poe/openai/gpt-4o-mini": {
      "id": "openai/gpt-4o-mini",
      "provider": "poe",
      "name": "GPT-4o-mini",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 4096,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00054,
      "cache_read_cost_per_1k": 6.8e-05,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-07-18"
    },
    "poe/openai/gpt-5": {
      "id": "openai/gpt-5",
      "provider": "poe",
      "name": "GPT-5",
      "family": "gpt-5",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0011,
      "output_cost_per_1k": 0.009,
      "cache_read_cost_per_1k": 0.00011,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-08-05"
    },
    "poe/openai/dall-e-3": {
      "id": "openai/dall-e-3",
      "provider": "poe",
      "name": "DALL-E-3",
      "family": "dall-e-3",
      "mode": "image",
      "max_input_tokens": 800,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2023-11-06"
    },
    "poe/openai/sora-2-pro": {
      "id": "openai/sora-2-pro",
      "provider": "poe",
      "name": "Sora-2-Pro",
      "family": "sora-2-pro",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-10-06"
    },
    "poe/openai/gpt-5-pro": {
      "id": "openai/gpt-5-pro",
      "provider": "poe",
      "name": "GPT-5-Pro",
      "family": "gpt-5-pro",
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.014,
      "output_cost_per_1k": 0.11,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-10-06"
    },
    "poe/openai/gpt-5.2": {
      "id": "openai/gpt-5.2",
      "provider": "poe",
      "name": "gpt-5.2",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 400000,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0016,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00016,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-12-08"
    },
    "poe/openai/gpt-4o-mini-search": {
      "id": "openai/gpt-4o-mini-search",
      "provider": "poe",
      "name": "GPT-4o-mini-Search",
      "family": "gpt-4o-mini",
      "mode": "chat",
      "max_input_tokens": 128000,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00014,
      "output_cost_per_1k": 0.00054,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-03-11"
    },
    "poe/stabilityai/stablediffusionxl": {
      "id": "stabilityai/stablediffusionxl",
      "provider": "poe",
      "name": "StableDiffusionXL",
      "family": "stablediffusionxl",
      "mode": "image",
      "max_input_tokens": 200,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2023-07-09"
    },
    "poe/topazlabs-co/topazlabs": {
      "id": "topazlabs-co/topazlabs",
      "provider": "poe",
      "name": "TopazLabs",
      "family": "topazlabs",
      "mode": "image",
      "max_input_tokens": 204,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "image_output",
        "vision"
      ],
      "release_date": "2024-12-03"
    },
    "poe/lumalabs/ray2": {
      "id": "lumalabs/ray2",
      "provider": "poe",
      "name": "Ray2",
      "family": "ray2",
      "mode": "chat",
      "max_input_tokens": 5000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-02-20"
    },
    "poe/lumalabs/dream-machine": {
      "id": "lumalabs/dream-machine",
      "provider": "poe",
      "name": "Dream-Machine",
      "family": "dream-machine",
      "mode": "chat",
      "max_input_tokens": 5000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-09-18"
    },
    "poe/anthropic/claude-opus-3": {
      "id": "anthropic/claude-opus-3",
      "provider": "poe",
      "name": "Claude-Opus-3",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.013,
      "output_cost_per_1k": 0.064,
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2024-03-04"
    },
    "poe/anthropic/claude-opus-4": {
      "id": "anthropic/claude-opus-4",
      "provider": "poe",
      "name": "Claude Opus 4",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 192512,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.013,
      "output_cost_per_1k": 0.064,
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-sonnet-3.7-reasoning": {
      "id": "anthropic/claude-sonnet-3.7-reasoning",
      "provider": "poe",
      "name": "Claude Sonnet 3.7 Reasoning",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-02-19"
    },
    "poe/anthropic/claude-opus-4-search": {
      "id": "anthropic/claude-opus-4-search",
      "provider": "poe",
      "name": "Claude Opus 4 Search",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.013,
      "output_cost_per_1k": 0.064,
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-20"
    },
    "poe/anthropic/claude-sonnet-3.7": {
      "id": "anthropic/claude-sonnet-3.7",
      "provider": "poe",
      "name": "Claude Sonnet 3.7",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-02-19"
    },
    "poe/anthropic/claude-haiku-3.5-search": {
      "id": "anthropic/claude-haiku-3.5-search",
      "provider": "poe",
      "name": "Claude-Haiku-3.5-Search",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00068,
      "output_cost_per_1k": 0.0034,
      "cache_read_cost_per_1k": 6.8e-05,
      "cache_write_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2025-05-15"
    },
    "poe/anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "provider": "poe",
      "name": "Claude Haiku 4.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 192000,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.00085,
      "output_cost_per_1k": 0.0043,
      "cache_read_cost_per_1k": 8.5e-05,
      "cache_write_cost_per_1k": 0.0011,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-10-15"
    },
    "poe/anthropic/claude-sonnet-4-reasoning": {
      "id": "anthropic/claude-sonnet-4-reasoning",
      "provider": "poe",
      "name": "Claude Sonnet 4 Reasoning",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 983040,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-haiku-3": {
      "id": "anthropic/claude-haiku-3",
      "provider": "poe",
      "name": "Claude-Haiku-3",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00021,
      "output_cost_per_1k": 0.0011,
      "cache_read_cost_per_1k": 2.1e-05,
      "cache_write_cost_per_1k": 0.00026,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2024-03-09"
    },
    "poe/anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "provider": "poe",
      "name": "Claude Opus 4.1",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.013,
      "output_cost_per_1k": 0.064,
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-08-05"
    },
    "poe/anthropic/claude-sonnet-3.7-search": {
      "id": "anthropic/claude-sonnet-3.7-search",
      "provider": "poe",
      "name": "Claude Sonnet 3.7 Search",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-05-15"
    },
    "poe/anthropic/claude-opus-4-reasoning": {
      "id": "anthropic/claude-opus-4-reasoning",
      "provider": "poe",
      "name": "Claude Opus 4 Reasoning",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.013,
      "output_cost_per_1k": 0.064,
      "cache_read_cost_per_1k": 0.0013,
      "cache_write_cost_per_1k": 0.016,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-sonnet-3.5": {
      "id": "anthropic/claude-sonnet-3.5",
      "provider": "poe",
      "name": "Claude-Sonnet-3.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2024-06-05"
    },
    "poe/anthropic/claude-sonnet-4": {
      "id": "anthropic/claude-sonnet-4",
      "provider": "poe",
      "name": "Claude Sonnet 4",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 983040,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-05-21"
    },
    "poe/anthropic/claude-opus-4.5": {
      "id": "anthropic/claude-opus-4.5",
      "provider": "poe",
      "name": "claude-opus-4.5",
      "family": "claude-opus",
      "mode": "chat",
      "max_input_tokens": 196608,
      "max_output_tokens": 64000,
      "input_cost_per_1k": 0.0043,
      "output_cost_per_1k": 0.021,
      "cache_read_cost_per_1k": 0.00043,
      "cache_write_cost_per_1k": 0.0053,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-21"
    },
    "poe/anthropic/claude-haiku-3.5": {
      "id": "anthropic/claude-haiku-3.5",
      "provider": "poe",
      "name": "Claude-Haiku-3.5",
      "family": "claude-haiku",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.00068,
      "output_cost_per_1k": 0.0034,
      "cache_read_cost_per_1k": 6.8e-05,
      "cache_write_cost_per_1k": 0.00085,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2024-10-01"
    },
    "poe/anthropic/claude-sonnet-3.5-june": {
      "id": "anthropic/claude-sonnet-3.5-june",
      "provider": "poe",
      "name": "Claude-Sonnet-3.5-June",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 189096,
      "max_output_tokens": 8192,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "vision"
      ],
      "release_date": "2024-11-18"
    },
    "poe/anthropic/claude-sonnet-4.5": {
      "id": "anthropic/claude-sonnet-4.5",
      "provider": "poe",
      "name": "Claude Sonnet 4.5",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 983040,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-09-26"
    },
    "poe/anthropic/claude-sonnet-4-search": {
      "id": "anthropic/claude-sonnet-4-search",
      "provider": "poe",
      "name": "Claude Sonnet 4 Search",
      "family": "claude-sonnet",
      "mode": "chat",
      "max_input_tokens": 983040,
      "max_output_tokens": 128000,
      "input_cost_per_1k": 0.0026,
      "output_cost_per_1k": 0.013,
      "cache_read_cost_per_1k": 0.00026,
      "cache_write_cost_per_1k": 0.0032,
      "capabilities": [
        "function_calling",
        "pdf_input",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-06-20"
    },
    "poe/trytako/tako": {
      "id": "trytako/tako",
      "provider": "poe",
      "name": "Tako",
      "family": "tako",
      "mode": "chat",
      "max_input_tokens": 2048,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2024-08-15"
    },
    "poe/novita/glm-4.7": {
      "id": "novita/glm-4.7",
      "provider": "poe",
      "name": "glm-4.7",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 205000,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature",
        "vision"
      ],
      "release_date": "2025-12-22"
    },
    "poe/novita/kimi-k2-thinking": {
      "id": "novita/kimi-k2-thinking",
      "provider": "poe",
      "name": "kimi-k2-thinking",
      "family": "kimi-k2",
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-07"
    },
    "poe/novita/kat-coder-pro": {
      "id": "novita/kat-coder-pro",
      "provider": "poe",
      "name": "kat-coder-pro",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 256000,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-12-16"
    },
    "poe/novita/glm-4.6": {
      "id": "novita/glm-4.6",
      "provider": "poe",
      "name": "GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "vision"
      ],
      "release_date": "2025-09-30"
    },
    "poe/novita/minimax-m2.1": {
      "id": "novita/minimax-m2.1",
      "provider": "poe",
      "name": "minimax-m2.1",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 205000,
      "max_output_tokens": 131072,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-12-26"
    },
    "poe/novita/glm-4.6v": {
      "id": "novita/glm-4.6v",
      "provider": "poe",
      "name": "glm-4.6v",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 32768,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-12-09"
    },
    "poe/cerebras/gpt-oss-120b-cs": {
      "id": "cerebras/gpt-oss-120b-cs",
      "provider": "poe",
      "name": "gpt-oss-120b-cs",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 0,
      "max_output_tokens": 0,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-08-06"
    },
    "poe/cerebras/zai-glm-4.6-cs": {
      "id": "cerebras/zai-glm-4.6-cs",
      "provider": "poe",
      "name": "zai-glm-4.6-cs",
      "family": null,
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 40000,
      "capabilities": [
        "function_calling",
        "reasoning",
        "vision"
      ],
      "release_date": "2025-11-11"
    },
    "cerebras/qwen-3-235b-a22b-instruct-2507": {
      "id": "qwen-3-235b-a22b-instruct-2507",
      "provider": "cerebras",
      "name": "Qwen 3 235B Instruct",
      "family": "qwen",
      "mode": "chat",
      "max_input_tokens": 131000,
      "max_output_tokens": 32000,
      "input_cost_per_1k": 0.0006,
      "output_cost_per_1k": 0.0012,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "knowledge_cutoff": "2025-04",
      "release_date": "2025-07-22",
      "open_weights": true
    },
    "cerebras/zai-glm-4.6": {
      "id": "zai-glm-4.6",
      "provider": "cerebras",
      "name": "Z.AI GLM-4.6",
      "family": "glm-4.6",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 40960,
      "input_cost_per_1k": 0.0,
      "output_cost_per_1k": 0.0,
      "cache_read_cost_per_1k": 0.0,
      "cache_write_cost_per_1k": 0.0,
      "capabilities": [
        "function_calling",
        "temperature"
      ],
      "release_date": "2025-11-05",
      "open_weights": true
    },
    "cerebras/gpt-oss-120b": {
      "id": "gpt-oss-120b",
      "provider": "cerebras",
      "name": "GPT OSS 120B",
      "family": "gpt-oss",
      "mode": "chat",
      "max_input_tokens": 131072,
      "max_output_tokens": 32768,
      "input_cost_per_1k": 0.00025,
      "output_cost_per_1k": 0.00069,
      "capabilities": [
        "function_calling",
        "reasoning",
        "temperature"
      ],
      "release_date": "2025-08-05",
      "open_weights": true
    }
  },
  "parsers": {
    "openai": {
      "request": {
        "model": "$.model",
        "messages": "$.messages",
        "stream": "$.stream",
        "max_tokens": "$.max_tokens",
        "temperature": "$.temperature",
        "tools": "$.tools",
        "tool_choice": "$.tool_choice"
      },
      "response": {
        "model": "$.model",
        "usage": {
          "prompt_tokens": "$.usage.prompt_tokens",
          "completion_tokens": "$.usage.completion_tokens",
          "total_tokens": "$.usage.total_tokens"
        },
        "finish_reason": "$.choices[0].finish_reason",
        "content": "$.choices[0].message.content"
      },
      "streaming": {
        "format": "sse",
        "done_signal": "[DONE]",
        "delta_path": "$.choices[0].delta"
      }
    },
    "anthropic": {
      "request": {
        "model": "$.model",
        "messages": "$.messages",
        "system": "$.system",
        "max_tokens": "$.max_tokens",
        "temperature": "$.temperature",
        "stream": "$.stream",
        "tools": "$.tools",
        "tool_choice": "$.tool_choice"
      },
      "response": {
        "model": "$.model",
        "usage": {
          "input_tokens": "$.usage.input_tokens",
          "output_tokens": "$.usage.output_tokens",
          "cache_creation_input_tokens": "$.usage.cache_creation_input_tokens",
          "cache_read_input_tokens": "$.usage.cache_read_input_tokens"
        },
        "stop_reason": "$.stop_reason",
        "content": "$.content"
      },
      "streaming": {
        "format": "sse",
        "done_signal": "message_stop",
        "delta_path": "$.delta"
      }
    },
    "google": {
      "request": {
        "model": "{url_path}",
        "contents": "$.contents",
        "system_instruction": "$.systemInstruction",
        "generation_config": {
          "temperature": "$.generationConfig.temperature",
          "max_output_tokens": "$.generationConfig.maxOutputTokens",
          "top_p": "$.generationConfig.topP",
          "top_k": "$.generationConfig.topK"
        },
        "tools": "$.tools"
      },
      "response": {
        "usage": {
          "prompt_tokens": "$.usageMetadata.promptTokenCount",
          "completion_tokens": "$.usageMetadata.candidatesTokenCount",
          "total_tokens": "$.usageMetadata.totalTokenCount"
        },
        "finish_reason": "$.candidates[0].finishReason",
        "content": "$.candidates[0].content"
      },
      "streaming": {
        "format": "sse",
        "done_signal": null
      }
    },
    "bedrock": {
      "request": {
        "model": "$.modelId",
        "messages": "$.messages",
        "system": "$.system",
        "max_tokens": "$.max_tokens",
        "temperature": "$.temperature"
      },
      "response": {
        "model": "$.modelId",
        "usage": {
          "input_tokens": "$.usage.inputTokens",
          "output_tokens": "$.usage.outputTokens",
          "total_tokens": "$.usage.totalTokens"
        },
        "stop_reason": "$.stopReason",
        "content": "$.output.message.content"
      },
      "streaming": {
        "format": "sse",
        "done_signal": null
      }
    },
    "cohere": {
      "request": {
        "model": "$.model",
        "message": "$.message",
        "chat_history": "$.chat_history",
        "temperature": "$.temperature",
        "max_tokens": "$.max_tokens",
        "stream": "$.stream"
      },
      "response": {
        "usage": {
          "input_tokens": "$.meta.tokens.input_tokens",
          "output_tokens": "$.meta.tokens.output_tokens"
        },
        "finish_reason": "$.finish_reason",
        "content": "$.text"
      },
      "streaming": {
        "format": "sse",
        "done_signal": null
      }
    }
  },
  "domain_lookup": {
    "api.moonshot.cn": "moonshotai_cn",
    "lucidquery.com": "lucidquery",
    "api.moonshot.ai": "moonshotai",
    "api.z.ai": "zai",
    "ollama.com": "ollama",
    "api.xiaomimimo.com": "xiaomi",
    "dashscope-intl.aliyuncs.com": "alibaba",
    "api.x.ai": "xai",
    "api.vultrinference.com": "vultr",
    "integrate.api.nvidia.com": "nvidia",
    "api.cohere.ai": "cohere",
    "api.upstage.ai": "upstage",
    "api.groq.com": "groq",
    "api.tbox.cn": "bailing",
    "api.githubcopilot.com": "github_copilot",
    "api.mistral.ai": "mistral",
    "routellm.abacus.ai": "abacus",
    "api.tokenfactory.nebius.com": "nebius",
    "api.deepseek.com": "deepseek",
    "dashscope.aliyuncs.com": "alibaba_cn",
    "api.venice.ai": "venice",
    "api.siliconflow.cn": "siliconflow_cn",
    "llm.chutes.ai": "chutes",
    "api.kimi.com": "kimi_for_coding",
    "api.cortecs.ai": "cortecs",
    "models.github.ai": "github_models",
    "inference.baseten.co": "baseten",
    "api.siliconflow.com": "siliconflow",
    "ai-gateway.helicone.ai": "helicone",
    "router.huggingface.co": "huggingface",
    "opencode.ai": "opencode",
    "go.fastrouter.ai": "fastrouter",
    "api.minimax.io": "minimax",
    "generativelanguage.googleapis.com": "google",
    "us-central1-aiplatform.googleapis.com": "google_vertex",
    "api.inceptionlabs.ai": "inception",
    "api.inference.wandb.ai": "wandb",
    "gateway.ai.cloudflare.com": "cloudflare_ai_gateway",
    "api.openai.com": "openai",
    "open.bigmodel.cn": "zhipuai",
    "api.minimaxi.com": "minimax_cn",
    "api.perplexity.ai": "perplexity",
    "openrouter.ai": "openrouter",
    "zenmux.ai": "zenmux",
    "oai.endpoints.kepler.ai.cloud.ovh.net": "ovhcloud",
    "apis.iflow.cn": "iflowcn",
    "api.synthetic.new": "synthetic",
    "llm.submodel.ai": "submodel",
    "nano-gpt.com": "nano_gpt",
    "inference.net": "inference",
    "router.requesty.ai": "requesty",
    "api.morphllm.com": "morph",
    "127.0.0.1:1234": "lmstudio",
    "api.friendli.ai": "friendli",
    "api.anthropic.com": "anthropic",
    "api.fireworks.ai": "fireworks",
    "api.intelligence.io.solutions": "io_net",
    "api-inference.modelscope.cn": "modelscope",
    "api.llama.com": "llama",
    "api.scaleway.ai": "scaleway",
    "api.poe.com": "poe",
    "api.cerebras.ai": "cerebras"
  },
  "domain_patterns": [
    {
      "pattern": ".*\\.openai\\.azure\\.com$",
      "provider": "azure_openai"
    },
    {
      "pattern": "bedrock-runtime\\..*\\.amazonaws\\.com$",
      "provider": "aws_bedrock"
    },
    {
      "pattern": "bedrock\\..*\\.amazonaws\\.com$",
      "provider": "aws_bedrock"
    }
  ]
}
